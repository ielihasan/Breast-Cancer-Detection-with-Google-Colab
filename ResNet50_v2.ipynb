{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_HVjA_5RDe8"
      },
      "source": [
        "# **Cancer Histology Image Classification UsingResNet50 - Deep Learning Model Overview**  \n",
        "***\n",
        "ResNet50 (Residual Network with 50 layers) is a deep convolutional neural network (CNN) widely used for **image classification, object detection, and feature extraction**. It was introduced by Microsoft researchers in 2015 in the paper **\"Deep Residual Learning for Image Recognition\"**, significantly improving deep network training by addressing the **vanishing gradient problem**.  \n",
        "\n",
        "## **Key Features of ResNet50:**  \n",
        "**Residual Learning:** Uses **skip connections** to bypass layers, improving gradient flow and training stability.  \n",
        "**Deep Architecture:** Consists of **50 layers**, allowing for better feature extraction than shallow networks.  \n",
        "**Pre-trained Weights:** Can use **ImageNet weights**, enhancing transfer learning capabilities.  \n",
        "**Improved Training:** Residual connections mitigate **vanishing gradients**, making deep networks trainable.  \n",
        "\n",
        "## **Why Use ResNet50 Instead of VGG16?**  \n",
        "**Better Performance:** ResNet50 **outperforms VGG16** in accuracy while using fewer parameters (~25M vs. ~138M).  \n",
        "**Deeper Yet Efficient:** ResNet50 achieves better results **without excessive computational cost**.  \n",
        "**Faster Convergence:** Residual connections enable **better backpropagation**, allowing deeper architectures.  \n",
        "\n",
        "## **ResNet50 in Our Project**  \n",
        "**Replacing VGG16 with ResNet50** while maintaining the dataset split (60% training, 10% validation, 30% testing).  \n",
        "Using **pre-trained ResNet50 as a feature extractor**, freezing convolutional layers, and adding a custom classifier.  \n",
        "Performing **binary classification** (Benign vs. Malignant) on histopathology images.  \n",
        "Evaluating performance using **Accuracy, F1-Score, G-Mean, and Informedness (IBA).**  \n",
        "\n",
        "This implementation ensures a **more efficient and accurate classification** of histopathology images while leveraging deep residual learning. 🚀\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1X9qAgV_FBZ",
        "outputId": "72b00a7b-6bb9-4dce-acd9-65dc3e43c6a0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFJ-1K-7R3Qw"
      },
      "source": [
        "***\n",
        "**Magnification Factor: 40X**\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMRX61p9CJD6",
        "outputId": "a0d4d33b-7062-45c7-8dfb-b77e86bb4a5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Benign Images: 626\n",
            "Total Malignant Images: 1370\n",
            "Training samples: 1197\n",
            "Validation samples: 200\n",
            "Testing samples: 599\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
            "Epoch 1/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 6s/step - accuracy: 0.5879 - loss: 0.6837 - val_accuracy: 0.6850 - val_loss: 0.6601\n",
            "Epoch 2/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 612ms/step - accuracy: 0.6917 - loss: 0.6639 - val_accuracy: 0.5900 - val_loss: 0.6733\n",
            "Epoch 3/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 667ms/step - accuracy: 0.6288 - loss: 0.6448 - val_accuracy: 0.6850 - val_loss: 0.6092\n",
            "Epoch 4/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 655ms/step - accuracy: 0.6783 - loss: 0.6272 - val_accuracy: 0.6850 - val_loss: 0.6100\n",
            "Epoch 5/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 590ms/step - accuracy: 0.6967 - loss: 0.5998 - val_accuracy: 0.6850 - val_loss: 0.6052\n",
            "Epoch 6/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 551ms/step - accuracy: 0.6823 - loss: 0.6118 - val_accuracy: 0.6850 - val_loss: 0.6050\n",
            "Epoch 7/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 675ms/step - accuracy: 0.6727 - loss: 0.6205 - val_accuracy: 0.6850 - val_loss: 0.6133\n",
            "Epoch 8/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 609ms/step - accuracy: 0.6856 - loss: 0.6117 - val_accuracy: 0.6850 - val_loss: 0.6032\n",
            "Epoch 9/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 695ms/step - accuracy: 0.7025 - loss: 0.5992 - val_accuracy: 0.7050 - val_loss: 0.6177\n",
            "Epoch 10/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 611ms/step - accuracy: 0.7070 - loss: 0.6167 - val_accuracy: 0.7100 - val_loss: 0.6172\n",
            "Epoch 11/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 549ms/step - accuracy: 0.6888 - loss: 0.6270 - val_accuracy: 0.6850 - val_loss: 0.5981\n",
            "Epoch 12/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 610ms/step - accuracy: 0.6893 - loss: 0.6273 - val_accuracy: 0.6850 - val_loss: 0.5988\n",
            "Epoch 13/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 542ms/step - accuracy: 0.7174 - loss: 0.5935 - val_accuracy: 0.6900 - val_loss: 0.5950\n",
            "Epoch 14/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 883ms/step - accuracy: 0.7140 - loss: 0.5874 - val_accuracy: 0.6900 - val_loss: 0.5931\n",
            "Epoch 15/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 547ms/step - accuracy: 0.6908 - loss: 0.6060 - val_accuracy: 0.6850 - val_loss: 0.6014\n",
            "Epoch 16/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 595ms/step - accuracy: 0.6866 - loss: 0.6160 - val_accuracy: 0.6850 - val_loss: 0.6168\n",
            "Epoch 17/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 666ms/step - accuracy: 0.7035 - loss: 0.6011 - val_accuracy: 0.6850 - val_loss: 0.6154\n",
            "Epoch 18/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 542ms/step - accuracy: 0.6926 - loss: 0.6202 - val_accuracy: 0.6900 - val_loss: 0.5966\n",
            "Epoch 19/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 616ms/step - accuracy: 0.7251 - loss: 0.5823 - val_accuracy: 0.6950 - val_loss: 0.5885\n",
            "Epoch 20/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 603ms/step - accuracy: 0.7128 - loss: 0.5937 - val_accuracy: 0.6950 - val_loss: 0.5887\n",
            "Epoch 21/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 650ms/step - accuracy: 0.7232 - loss: 0.5822 - val_accuracy: 0.7050 - val_loss: 0.5886\n",
            "Epoch 22/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 599ms/step - accuracy: 0.6972 - loss: 0.6081 - val_accuracy: 0.6950 - val_loss: 0.5936\n",
            "Epoch 23/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 607ms/step - accuracy: 0.6996 - loss: 0.6045 - val_accuracy: 0.6950 - val_loss: 0.5938\n",
            "Epoch 24/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 608ms/step - accuracy: 0.7040 - loss: 0.5983 - val_accuracy: 0.6900 - val_loss: 0.6004\n",
            "Epoch 25/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 607ms/step - accuracy: 0.7112 - loss: 0.5924 - val_accuracy: 0.6950 - val_loss: 0.5860\n",
            "Epoch 26/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 675ms/step - accuracy: 0.7072 - loss: 0.5926 - val_accuracy: 0.7050 - val_loss: 0.5818\n",
            "Epoch 27/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 598ms/step - accuracy: 0.7300 - loss: 0.5774 - val_accuracy: 0.7200 - val_loss: 0.5934\n",
            "Epoch 28/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 763ms/step - accuracy: 0.6886 - loss: 0.6105 - val_accuracy: 0.7050 - val_loss: 0.5797\n",
            "Epoch 29/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 569ms/step - accuracy: 0.7020 - loss: 0.6008 - val_accuracy: 0.7000 - val_loss: 0.5819\n",
            "Epoch 30/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 707ms/step - accuracy: 0.7253 - loss: 0.5764 - val_accuracy: 0.7100 - val_loss: 0.5800\n",
            "Epoch 31/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 667ms/step - accuracy: 0.7040 - loss: 0.5950 - val_accuracy: 0.6950 - val_loss: 0.5903\n",
            "Epoch 32/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 559ms/step - accuracy: 0.7062 - loss: 0.5942 - val_accuracy: 0.6950 - val_loss: 0.5976\n",
            "Epoch 33/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 885ms/step - accuracy: 0.7141 - loss: 0.5920 - val_accuracy: 0.6950 - val_loss: 0.5897\n",
            "Epoch 34/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 600ms/step - accuracy: 0.7209 - loss: 0.5793 - val_accuracy: 0.7100 - val_loss: 0.5743\n",
            "Epoch 35/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 621ms/step - accuracy: 0.7207 - loss: 0.5756 - val_accuracy: 0.7050 - val_loss: 0.5740\n",
            "Epoch 36/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 611ms/step - accuracy: 0.7157 - loss: 0.5830 - val_accuracy: 0.7150 - val_loss: 0.5764\n",
            "Epoch 37/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 888ms/step - accuracy: 0.6961 - loss: 0.5918 - val_accuracy: 0.7050 - val_loss: 0.5730\n",
            "Epoch 38/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 608ms/step - accuracy: 0.7177 - loss: 0.5850 - val_accuracy: 0.7100 - val_loss: 0.5727\n",
            "Epoch 39/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 704ms/step - accuracy: 0.7058 - loss: 0.5957 - val_accuracy: 0.7100 - val_loss: 0.5714\n",
            "Epoch 40/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 541ms/step - accuracy: 0.7137 - loss: 0.5817 - val_accuracy: 0.6950 - val_loss: 0.5987\n",
            "Epoch 41/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 601ms/step - accuracy: 0.7188 - loss: 0.5918 - val_accuracy: 0.7050 - val_loss: 0.5712\n",
            "Epoch 42/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 659ms/step - accuracy: 0.7037 - loss: 0.5888 - val_accuracy: 0.6950 - val_loss: 0.5787\n",
            "Epoch 43/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 597ms/step - accuracy: 0.7092 - loss: 0.5801 - val_accuracy: 0.6900 - val_loss: 0.6127\n",
            "Epoch 44/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 615ms/step - accuracy: 0.6746 - loss: 0.6230 - val_accuracy: 0.6900 - val_loss: 0.6324\n",
            "Epoch 45/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 566ms/step - accuracy: 0.7060 - loss: 0.6098 - val_accuracy: 0.6950 - val_loss: 0.5784\n",
            "Epoch 46/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 647ms/step - accuracy: 0.7216 - loss: 0.5780 - val_accuracy: 0.7050 - val_loss: 0.5684\n",
            "Epoch 47/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 612ms/step - accuracy: 0.7182 - loss: 0.5782 - val_accuracy: 0.7100 - val_loss: 0.5664\n",
            "Epoch 48/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 886ms/step - accuracy: 0.7017 - loss: 0.5845 - val_accuracy: 0.6950 - val_loss: 0.5830\n",
            "Epoch 49/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 600ms/step - accuracy: 0.7430 - loss: 0.5506 - val_accuracy: 0.7050 - val_loss: 0.5689\n",
            "Epoch 50/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 882ms/step - accuracy: 0.7126 - loss: 0.5837 - val_accuracy: 0.7000 - val_loss: 0.5714\n",
            "Epoch 51/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 628ms/step - accuracy: 0.7111 - loss: 0.5810 - val_accuracy: 0.6950 - val_loss: 0.5837\n",
            "Epoch 52/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 877ms/step - accuracy: 0.6991 - loss: 0.6041 - val_accuracy: 0.6950 - val_loss: 0.6187\n",
            "Epoch 53/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 537ms/step - accuracy: 0.7107 - loss: 0.5976 - val_accuracy: 0.6950 - val_loss: 0.5915\n",
            "Epoch 54/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 887ms/step - accuracy: 0.7149 - loss: 0.5781 - val_accuracy: 0.6950 - val_loss: 0.5944\n",
            "Epoch 55/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 599ms/step - accuracy: 0.6957 - loss: 0.6145 - val_accuracy: 0.6950 - val_loss: 0.5925\n",
            "Epoch 56/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 891ms/step - accuracy: 0.7273 - loss: 0.5622 - val_accuracy: 0.7050 - val_loss: 0.5671\n",
            "Epoch 57/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 603ms/step - accuracy: 0.7100 - loss: 0.5907 - val_accuracy: 0.6950 - val_loss: 0.5895\n",
            "Epoch 58/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 648ms/step - accuracy: 0.7077 - loss: 0.6038 - val_accuracy: 0.7050 - val_loss: 0.5653\n",
            "Epoch 59/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 604ms/step - accuracy: 0.7382 - loss: 0.5515 - val_accuracy: 0.7300 - val_loss: 0.5695\n",
            "Epoch 60/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 888ms/step - accuracy: 0.7005 - loss: 0.5905 - val_accuracy: 0.7250 - val_loss: 0.5611\n",
            "Epoch 61/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 596ms/step - accuracy: 0.6669 - loss: 0.6114 - val_accuracy: 0.7350 - val_loss: 0.5754\n",
            "Epoch 62/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 754ms/step - accuracy: 0.6873 - loss: 0.6059 - val_accuracy: 0.7250 - val_loss: 0.5607\n",
            "Epoch 63/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 605ms/step - accuracy: 0.7016 - loss: 0.5945 - val_accuracy: 0.7250 - val_loss: 0.5629\n",
            "Epoch 64/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 899ms/step - accuracy: 0.7212 - loss: 0.5786 - val_accuracy: 0.7200 - val_loss: 0.5582\n",
            "Epoch 65/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 676ms/step - accuracy: 0.7129 - loss: 0.5773 - val_accuracy: 0.7000 - val_loss: 0.5636\n",
            "Epoch 66/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 566ms/step - accuracy: 0.7128 - loss: 0.5794 - val_accuracy: 0.7200 - val_loss: 0.5571\n",
            "Epoch 67/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 629ms/step - accuracy: 0.7204 - loss: 0.5692 - val_accuracy: 0.7250 - val_loss: 0.5660\n",
            "Epoch 68/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 602ms/step - accuracy: 0.6954 - loss: 0.5823 - val_accuracy: 0.7200 - val_loss: 0.5572\n",
            "Epoch 69/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 891ms/step - accuracy: 0.7139 - loss: 0.5735 - val_accuracy: 0.7200 - val_loss: 0.5558\n",
            "Epoch 70/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 906ms/step - accuracy: 0.7333 - loss: 0.5542 - val_accuracy: 0.7300 - val_loss: 0.5659\n",
            "Epoch 71/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 564ms/step - accuracy: 0.7186 - loss: 0.5756 - val_accuracy: 0.7250 - val_loss: 0.5573\n",
            "Epoch 72/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 612ms/step - accuracy: 0.7133 - loss: 0.5737 - val_accuracy: 0.7200 - val_loss: 0.5536\n",
            "Epoch 73/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 571ms/step - accuracy: 0.7141 - loss: 0.5762 - val_accuracy: 0.7050 - val_loss: 0.5581\n",
            "Epoch 74/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 892ms/step - accuracy: 0.7189 - loss: 0.5674 - val_accuracy: 0.6950 - val_loss: 0.5709\n",
            "Epoch 75/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 632ms/step - accuracy: 0.7017 - loss: 0.5907 - val_accuracy: 0.7050 - val_loss: 0.5615\n",
            "Epoch 76/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 562ms/step - accuracy: 0.7307 - loss: 0.5533 - val_accuracy: 0.7200 - val_loss: 0.5505\n",
            "Epoch 77/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 705ms/step - accuracy: 0.7289 - loss: 0.5587 - val_accuracy: 0.7200 - val_loss: 0.5495\n",
            "Epoch 78/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 599ms/step - accuracy: 0.7206 - loss: 0.5648 - val_accuracy: 0.7150 - val_loss: 0.5511\n",
            "Epoch 79/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 605ms/step - accuracy: 0.7218 - loss: 0.5695 - val_accuracy: 0.7250 - val_loss: 0.5578\n",
            "Epoch 80/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 607ms/step - accuracy: 0.7105 - loss: 0.5649 - val_accuracy: 0.7250 - val_loss: 0.5570\n",
            "Epoch 81/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 601ms/step - accuracy: 0.7116 - loss: 0.5697 - val_accuracy: 0.7200 - val_loss: 0.5495\n",
            "Epoch 82/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 672ms/step - accuracy: 0.7193 - loss: 0.5649 - val_accuracy: 0.7200 - val_loss: 0.5473\n",
            "Epoch 83/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 896ms/step - accuracy: 0.7180 - loss: 0.5566 - val_accuracy: 0.7300 - val_loss: 0.5531\n",
            "Epoch 84/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 568ms/step - accuracy: 0.7188 - loss: 0.5715 - val_accuracy: 0.7200 - val_loss: 0.5470\n",
            "Epoch 85/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 562ms/step - accuracy: 0.7088 - loss: 0.5721 - val_accuracy: 0.7000 - val_loss: 0.5684\n",
            "Epoch 86/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 644ms/step - accuracy: 0.7307 - loss: 0.5549 - val_accuracy: 0.7100 - val_loss: 0.5555\n",
            "Epoch 87/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 605ms/step - accuracy: 0.7125 - loss: 0.5696 - val_accuracy: 0.7050 - val_loss: 0.5583\n",
            "Epoch 88/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 900ms/step - accuracy: 0.7339 - loss: 0.5443 - val_accuracy: 0.7200 - val_loss: 0.5443\n",
            "Epoch 89/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 904ms/step - accuracy: 0.7140 - loss: 0.5757 - val_accuracy: 0.7000 - val_loss: 0.5654\n",
            "Epoch 90/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 628ms/step - accuracy: 0.7326 - loss: 0.5500 - val_accuracy: 0.7350 - val_loss: 0.5574\n",
            "Epoch 91/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 552ms/step - accuracy: 0.7084 - loss: 0.5741 - val_accuracy: 0.6750 - val_loss: 0.5937\n",
            "Epoch 92/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 729ms/step - accuracy: 0.6787 - loss: 0.6055 - val_accuracy: 0.7300 - val_loss: 0.5462\n",
            "Epoch 93/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 616ms/step - accuracy: 0.7216 - loss: 0.5543 - val_accuracy: 0.7350 - val_loss: 0.5547\n",
            "Epoch 94/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 602ms/step - accuracy: 0.7179 - loss: 0.5637 - val_accuracy: 0.7200 - val_loss: 0.5421\n",
            "Epoch 95/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 628ms/step - accuracy: 0.7140 - loss: 0.5618 - val_accuracy: 0.7200 - val_loss: 0.5407\n",
            "Epoch 96/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 664ms/step - accuracy: 0.7050 - loss: 0.5657 - val_accuracy: 0.7100 - val_loss: 0.5531\n",
            "Epoch 97/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 666ms/step - accuracy: 0.7107 - loss: 0.5778 - val_accuracy: 0.7150 - val_loss: 0.5402\n",
            "Epoch 98/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 885ms/step - accuracy: 0.7072 - loss: 0.5754 - val_accuracy: 0.7150 - val_loss: 0.5400\n",
            "Epoch 99/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 888ms/step - accuracy: 0.7108 - loss: 0.5656 - val_accuracy: 0.7200 - val_loss: 0.5399\n",
            "Epoch 100/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 660ms/step - accuracy: 0.7222 - loss: 0.5512 - val_accuracy: 0.7200 - val_loss: 0.5390\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 12s/step\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2s/step - accuracy: 0.7264 - loss: 0.5614\n",
            "Test Accuracy: 0.7095\n",
            "F1 Score: 0.8214\n",
            "G-Mean: 0.3597\n",
            "Informedness (IBA): 0.1062\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "\n",
        "# Define dataset paths\n",
        "benign_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/benign/40X\"\n",
        "malignant_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/malignant/40X\"\n",
        "\n",
        "# Function to load image paths\n",
        "def load_image_paths(dir_path):\n",
        "    return [os.path.join(dir_path, img) for img in os.listdir(dir_path) if img.endswith('.png')]\n",
        "\n",
        "benign_images = load_image_paths(benign_dir)\n",
        "malignant_images = load_image_paths(malignant_dir)\n",
        "\n",
        "print(f\"Total Benign Images: {len(benign_images)}\")\n",
        "print(f\"Total Malignant Images: {len(malignant_images)}\")\n",
        "\n",
        "# Create labels (0 = Benign, 1 = Malignant)\n",
        "benign_labels = [0] * len(benign_images)\n",
        "malignant_labels = [1] * len(malignant_images)\n",
        "\n",
        "# Combine images and labels\n",
        "all_images = np.array(benign_images + malignant_images)\n",
        "all_labels = np.array(benign_labels + malignant_labels)\n",
        "\n",
        "# Split into training (70%) and testing (30%)\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(\n",
        "    all_images, all_labels, test_size=0.3, stratify=all_labels, random_state=42\n",
        ")\n",
        "\n",
        "# Further split training set into 60% training and 10% validation\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(\n",
        "    train_images, train_labels, test_size=0.1429, stratify=train_labels, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {len(train_images)}\")\n",
        "print(f\"Validation samples: {len(val_images)}\")\n",
        "print(f\"Testing samples: {len(test_images)}\")\n",
        "\n",
        "# Function to preprocess images\n",
        "def process_path(file_path, label):\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_png(img, channels=3)  # Decode PNG images\n",
        "    img = tf.image.resize(img, [224, 224])  # Resize to 224x224\n",
        "    img = img / 255.0  # Normalize pixel values\n",
        "    return img, label\n",
        "\n",
        "# Create TensorFlow datasets\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "train_dataset = train_dataset.map(process_path).shuffle(1000).batch(BATCH_SIZE)\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
        "val_dataset = val_dataset.map(process_path).batch(BATCH_SIZE)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
        "test_dataset = test_dataset.map(process_path).batch(BATCH_SIZE)\n",
        "\n",
        "# Load ResNet50 without the top classification layer\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the pre-trained layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom classifier on top\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dense(1, activation='sigmoid')(x)  # Binary classification\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "EPOCHS = 100\n",
        "history = model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS)\n",
        "\n",
        "# Evaluate model\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Predict on test data\n",
        "test_preds = model.predict(test_dataset)\n",
        "test_preds = (test_preds > 0.5).astype(int).flatten()\n",
        "\n",
        "# Get confusion matrix values\n",
        "tn, fp, fn, tp = confusion_matrix(test_labels, test_preds).ravel()\n",
        "\n",
        "# Calculate IBA\n",
        "iba = (tp / (tp + fn)) + (tn / (tn + fp)) - 1\n",
        "\n",
        "# Output results\n",
        "f1 = f1_score(test_labels, test_preds)\n",
        "gmean = geometric_mean_score(test_labels, test_preds)\n",
        "\n",
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"G-Mean: {gmean:.4f}\")\n",
        "print(f\"Informedness (IBA): {iba:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CmGrKsuR-ny"
      },
      "source": [
        "***\n",
        "**Magnification Factor: 100X**\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fDBUvU9FRlK",
        "outputId": "13747c42-415d-4b0d-b4be-5ef6af14ddb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Benign Images: 649\n",
            "Total Malignant Images: 1437\n",
            "Training samples: 1251\n",
            "Validation samples: 209\n",
            "Testing samples: 626\n",
            "Epoch 1/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 7s/step - accuracy: 0.6070 - loss: 0.6994 - val_accuracy: 0.6890 - val_loss: 0.6653\n",
            "Epoch 2/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 677ms/step - accuracy: 0.7026 - loss: 0.6189 - val_accuracy: 0.6890 - val_loss: 0.6514\n",
            "Epoch 3/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 975ms/step - accuracy: 0.6961 - loss: 0.6377 - val_accuracy: 0.6890 - val_loss: 0.6128\n",
            "Epoch 4/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 973ms/step - accuracy: 0.6866 - loss: 0.6136 - val_accuracy: 0.6890 - val_loss: 0.6063\n",
            "Epoch 5/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 738ms/step - accuracy: 0.7077 - loss: 0.5942 - val_accuracy: 0.6938 - val_loss: 0.6030\n",
            "Epoch 6/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 687ms/step - accuracy: 0.6929 - loss: 0.6142 - val_accuracy: 0.6890 - val_loss: 0.6050\n",
            "Epoch 7/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 725ms/step - accuracy: 0.7200 - loss: 0.5891 - val_accuracy: 0.7225 - val_loss: 0.6120\n",
            "Epoch 8/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 658ms/step - accuracy: 0.7216 - loss: 0.6053 - val_accuracy: 0.7033 - val_loss: 0.5971\n",
            "Epoch 9/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 728ms/step - accuracy: 0.7132 - loss: 0.5926 - val_accuracy: 0.7129 - val_loss: 0.5941\n",
            "Epoch 10/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 643ms/step - accuracy: 0.7139 - loss: 0.5973 - val_accuracy: 0.7177 - val_loss: 0.5964\n",
            "Epoch 11/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 747ms/step - accuracy: 0.7167 - loss: 0.5940 - val_accuracy: 0.7129 - val_loss: 0.5888\n",
            "Epoch 12/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 692ms/step - accuracy: 0.7043 - loss: 0.5976 - val_accuracy: 0.7225 - val_loss: 0.5885\n",
            "Epoch 13/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 971ms/step - accuracy: 0.7334 - loss: 0.5800 - val_accuracy: 0.7177 - val_loss: 0.5948\n",
            "Epoch 14/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 704ms/step - accuracy: 0.6946 - loss: 0.6099 - val_accuracy: 0.7177 - val_loss: 0.5907\n",
            "Epoch 15/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 666ms/step - accuracy: 0.7090 - loss: 0.6034 - val_accuracy: 0.7177 - val_loss: 0.5876\n",
            "Epoch 16/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 968ms/step - accuracy: 0.7163 - loss: 0.5886 - val_accuracy: 0.7177 - val_loss: 0.5849\n",
            "Epoch 17/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 654ms/step - accuracy: 0.7423 - loss: 0.5623 - val_accuracy: 0.6842 - val_loss: 0.6122\n",
            "Epoch 18/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - accuracy: 0.7144 - loss: 0.5986 - val_accuracy: 0.7129 - val_loss: 0.5849\n",
            "Epoch 19/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 664ms/step - accuracy: 0.7021 - loss: 0.6071 - val_accuracy: 0.7033 - val_loss: 0.5999\n",
            "Epoch 20/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 972ms/step - accuracy: 0.7171 - loss: 0.5880 - val_accuracy: 0.7129 - val_loss: 0.5816\n",
            "Epoch 21/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 715ms/step - accuracy: 0.7266 - loss: 0.5683 - val_accuracy: 0.7033 - val_loss: 0.5929\n",
            "Epoch 22/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 680ms/step - accuracy: 0.7287 - loss: 0.5697 - val_accuracy: 0.7081 - val_loss: 0.5848\n",
            "Epoch 23/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 768ms/step - accuracy: 0.7169 - loss: 0.5789 - val_accuracy: 0.7081 - val_loss: 0.5821\n",
            "Epoch 24/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 648ms/step - accuracy: 0.7064 - loss: 0.5949 - val_accuracy: 0.7129 - val_loss: 0.5841\n",
            "Epoch 25/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 971ms/step - accuracy: 0.7162 - loss: 0.6055 - val_accuracy: 0.7129 - val_loss: 0.5797\n",
            "Epoch 26/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 637ms/step - accuracy: 0.7104 - loss: 0.5827 - val_accuracy: 0.6986 - val_loss: 0.5886\n",
            "Epoch 27/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 761ms/step - accuracy: 0.7082 - loss: 0.5749 - val_accuracy: 0.7129 - val_loss: 0.5778\n",
            "Epoch 28/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 664ms/step - accuracy: 0.7307 - loss: 0.5607 - val_accuracy: 0.6986 - val_loss: 0.5877\n",
            "Epoch 29/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 698ms/step - accuracy: 0.7162 - loss: 0.5730 - val_accuracy: 0.7129 - val_loss: 0.5832\n",
            "Epoch 30/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 961ms/step - accuracy: 0.7300 - loss: 0.5674 - val_accuracy: 0.6651 - val_loss: 0.6052\n",
            "Epoch 31/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 646ms/step - accuracy: 0.7150 - loss: 0.5826 - val_accuracy: 0.6842 - val_loss: 0.5960\n",
            "Epoch 32/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 964ms/step - accuracy: 0.7033 - loss: 0.5986 - val_accuracy: 0.7081 - val_loss: 0.5829\n",
            "Epoch 33/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 665ms/step - accuracy: 0.7168 - loss: 0.5822 - val_accuracy: 0.7081 - val_loss: 0.5767\n",
            "Epoch 34/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 740ms/step - accuracy: 0.7222 - loss: 0.5680 - val_accuracy: 0.7177 - val_loss: 0.5755\n",
            "Epoch 35/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 647ms/step - accuracy: 0.7267 - loss: 0.5656 - val_accuracy: 0.7129 - val_loss: 0.5713\n",
            "Epoch 36/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 774ms/step - accuracy: 0.7379 - loss: 0.5510 - val_accuracy: 0.6603 - val_loss: 0.6156\n",
            "Epoch 37/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 654ms/step - accuracy: 0.7033 - loss: 0.5917 - val_accuracy: 0.7129 - val_loss: 0.5772\n",
            "Epoch 38/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 966ms/step - accuracy: 0.7379 - loss: 0.5588 - val_accuracy: 0.6986 - val_loss: 0.5847\n",
            "Epoch 39/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 666ms/step - accuracy: 0.7187 - loss: 0.5739 - val_accuracy: 0.7177 - val_loss: 0.5704\n",
            "Epoch 40/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 827ms/step - accuracy: 0.7068 - loss: 0.5776 - val_accuracy: 0.7081 - val_loss: 0.5969\n",
            "Epoch 41/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 650ms/step - accuracy: 0.6937 - loss: 0.6093 - val_accuracy: 0.6986 - val_loss: 0.6150\n",
            "Epoch 42/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 764ms/step - accuracy: 0.7328 - loss: 0.5722 - val_accuracy: 0.7129 - val_loss: 0.5696\n",
            "Epoch 43/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 655ms/step - accuracy: 0.7214 - loss: 0.5594 - val_accuracy: 0.7177 - val_loss: 0.5703\n",
            "Epoch 44/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 779ms/step - accuracy: 0.7247 - loss: 0.5586 - val_accuracy: 0.7081 - val_loss: 0.5763\n",
            "Epoch 45/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 681ms/step - accuracy: 0.7235 - loss: 0.5632 - val_accuracy: 0.7177 - val_loss: 0.5702\n",
            "Epoch 46/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 962ms/step - accuracy: 0.7199 - loss: 0.5633 - val_accuracy: 0.6699 - val_loss: 0.5892\n",
            "Epoch 47/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 755ms/step - accuracy: 0.7252 - loss: 0.5681 - val_accuracy: 0.6938 - val_loss: 0.5784\n",
            "Epoch 48/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 646ms/step - accuracy: 0.7207 - loss: 0.5711 - val_accuracy: 0.6938 - val_loss: 0.5814\n",
            "Epoch 49/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 968ms/step - accuracy: 0.7176 - loss: 0.5652 - val_accuracy: 0.6986 - val_loss: 0.5768\n",
            "Epoch 50/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 0.7063 - loss: 0.5617 - val_accuracy: 0.7129 - val_loss: 0.5657\n",
            "Epoch 51/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 649ms/step - accuracy: 0.7138 - loss: 0.5601 - val_accuracy: 0.6890 - val_loss: 0.5841\n",
            "Epoch 52/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 705ms/step - accuracy: 0.7096 - loss: 0.5714 - val_accuracy: 0.7177 - val_loss: 0.5664\n",
            "Epoch 53/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 649ms/step - accuracy: 0.7004 - loss: 0.5745 - val_accuracy: 0.7129 - val_loss: 0.5659\n",
            "Epoch 54/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 959ms/step - accuracy: 0.7102 - loss: 0.5632 - val_accuracy: 0.7129 - val_loss: 0.5744\n",
            "Epoch 55/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 737ms/step - accuracy: 0.7005 - loss: 0.5805 - val_accuracy: 0.7081 - val_loss: 0.6062\n",
            "Epoch 56/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 679ms/step - accuracy: 0.7299 - loss: 0.5557 - val_accuracy: 0.7129 - val_loss: 0.5646\n",
            "Epoch 57/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 977ms/step - accuracy: 0.7281 - loss: 0.5399 - val_accuracy: 0.7177 - val_loss: 0.5648\n",
            "Epoch 58/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 680ms/step - accuracy: 0.7236 - loss: 0.5606 - val_accuracy: 0.7177 - val_loss: 0.5669\n",
            "Epoch 59/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 977ms/step - accuracy: 0.7195 - loss: 0.5530 - val_accuracy: 0.7129 - val_loss: 0.5689\n",
            "Epoch 60/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 655ms/step - accuracy: 0.7204 - loss: 0.5549 - val_accuracy: 0.7177 - val_loss: 0.5629\n",
            "Epoch 61/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 830ms/step - accuracy: 0.7214 - loss: 0.5683 - val_accuracy: 0.5885 - val_loss: 0.6403\n",
            "Epoch 62/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 680ms/step - accuracy: 0.6704 - loss: 0.6010 - val_accuracy: 0.6651 - val_loss: 0.6162\n",
            "Epoch 63/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 978ms/step - accuracy: 0.7088 - loss: 0.5852 - val_accuracy: 0.6890 - val_loss: 0.5760\n",
            "Epoch 64/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 775ms/step - accuracy: 0.7182 - loss: 0.5550 - val_accuracy: 0.6794 - val_loss: 0.5960\n",
            "Epoch 65/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 653ms/step - accuracy: 0.7397 - loss: 0.5638 - val_accuracy: 0.6986 - val_loss: 0.5700\n",
            "Epoch 66/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 718ms/step - accuracy: 0.7211 - loss: 0.5554 - val_accuracy: 0.7177 - val_loss: 0.5619\n",
            "Epoch 67/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 651ms/step - accuracy: 0.7194 - loss: 0.5506 - val_accuracy: 0.6794 - val_loss: 0.5799\n",
            "Epoch 68/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 768ms/step - accuracy: 0.7247 - loss: 0.5554 - val_accuracy: 0.7177 - val_loss: 0.5619\n",
            "Epoch 69/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 679ms/step - accuracy: 0.7298 - loss: 0.5402 - val_accuracy: 0.7177 - val_loss: 0.5610\n",
            "Epoch 70/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 961ms/step - accuracy: 0.7193 - loss: 0.5540 - val_accuracy: 0.7033 - val_loss: 0.5648\n",
            "Epoch 71/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 758ms/step - accuracy: 0.7200 - loss: 0.5566 - val_accuracy: 0.7033 - val_loss: 0.5693\n",
            "Epoch 72/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 675ms/step - accuracy: 0.7299 - loss: 0.5445 - val_accuracy: 0.7129 - val_loss: 0.5603\n",
            "Epoch 73/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 642ms/step - accuracy: 0.7280 - loss: 0.5453 - val_accuracy: 0.6890 - val_loss: 0.5991\n",
            "Epoch 74/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 976ms/step - accuracy: 0.7248 - loss: 0.5637 - val_accuracy: 0.6794 - val_loss: 0.5750\n",
            "Epoch 75/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 768ms/step - accuracy: 0.7309 - loss: 0.5418 - val_accuracy: 0.6794 - val_loss: 0.5819\n",
            "Epoch 76/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 678ms/step - accuracy: 0.7275 - loss: 0.5586 - val_accuracy: 0.7081 - val_loss: 0.5629\n",
            "Epoch 77/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 802ms/step - accuracy: 0.7125 - loss: 0.5517 - val_accuracy: 0.7177 - val_loss: 0.5599\n",
            "Epoch 78/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 964ms/step - accuracy: 0.7121 - loss: 0.5456 - val_accuracy: 0.7129 - val_loss: 0.5780\n",
            "Epoch 79/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 683ms/step - accuracy: 0.7262 - loss: 0.5482 - val_accuracy: 0.6890 - val_loss: 0.5705\n",
            "Epoch 80/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 815ms/step - accuracy: 0.7172 - loss: 0.5508 - val_accuracy: 0.7081 - val_loss: 0.5611\n",
            "Epoch 81/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 743ms/step - accuracy: 0.7274 - loss: 0.5453 - val_accuracy: 0.7129 - val_loss: 0.5583\n",
            "Epoch 82/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 703ms/step - accuracy: 0.7159 - loss: 0.5469 - val_accuracy: 0.7129 - val_loss: 0.5583\n",
            "Epoch 83/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 652ms/step - accuracy: 0.7319 - loss: 0.5395 - val_accuracy: 0.7081 - val_loss: 0.5588\n",
            "Epoch 84/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 798ms/step - accuracy: 0.7289 - loss: 0.5433 - val_accuracy: 0.7129 - val_loss: 0.5571\n",
            "Epoch 85/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 665ms/step - accuracy: 0.7213 - loss: 0.5423 - val_accuracy: 0.7081 - val_loss: 0.5577\n",
            "Epoch 86/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 829ms/step - accuracy: 0.7382 - loss: 0.5269 - val_accuracy: 0.7129 - val_loss: 0.5567\n",
            "Epoch 87/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 736ms/step - accuracy: 0.7290 - loss: 0.5402 - val_accuracy: 0.7129 - val_loss: 0.5565\n",
            "Epoch 88/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 793ms/step - accuracy: 0.7261 - loss: 0.5336 - val_accuracy: 0.7033 - val_loss: 0.5594\n",
            "Epoch 89/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 748ms/step - accuracy: 0.7263 - loss: 0.5338 - val_accuracy: 0.7129 - val_loss: 0.5557\n",
            "Epoch 90/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 968ms/step - accuracy: 0.7263 - loss: 0.5438 - val_accuracy: 0.7129 - val_loss: 0.5742\n",
            "Epoch 91/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 779ms/step - accuracy: 0.7313 - loss: 0.5474 - val_accuracy: 0.7081 - val_loss: 0.5559\n",
            "Epoch 92/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 679ms/step - accuracy: 0.7205 - loss: 0.5533 - val_accuracy: 0.6794 - val_loss: 0.5944\n",
            "Epoch 93/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 965ms/step - accuracy: 0.7485 - loss: 0.5544 - val_accuracy: 0.7033 - val_loss: 0.5594\n",
            "Epoch 94/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 717ms/step - accuracy: 0.7192 - loss: 0.5451 - val_accuracy: 0.7129 - val_loss: 0.5689\n",
            "Epoch 95/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 675ms/step - accuracy: 0.7258 - loss: 0.5596 - val_accuracy: 0.7177 - val_loss: 0.5636\n",
            "Epoch 96/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 975ms/step - accuracy: 0.7378 - loss: 0.5386 - val_accuracy: 0.7081 - val_loss: 0.5699\n",
            "Epoch 97/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 652ms/step - accuracy: 0.7510 - loss: 0.5426 - val_accuracy: 0.7081 - val_loss: 0.5547\n",
            "Epoch 98/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 705ms/step - accuracy: 0.7348 - loss: 0.5324 - val_accuracy: 0.7129 - val_loss: 0.5550\n",
            "Epoch 99/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 682ms/step - accuracy: 0.7387 - loss: 0.5339 - val_accuracy: 0.7129 - val_loss: 0.5550\n",
            "Epoch 100/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 756ms/step - accuracy: 0.7286 - loss: 0.5263 - val_accuracy: 0.7081 - val_loss: 0.5551\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 12s/step\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.7139 - loss: 0.5553\n",
            "Test Accuracy: 0.7125\n",
            "F1 Score: 0.8189\n",
            "G-Mean: 0.4346\n",
            "Informedness (IBA): 0.1443\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "\n",
        "# Define dataset paths\n",
        "benign_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/benign/100X\"\n",
        "malignant_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/malignant/100X\"\n",
        "\n",
        "# Function to load image paths\n",
        "def load_image_paths(dir_path):\n",
        "    return [os.path.join(dir_path, img) for img in os.listdir(dir_path) if img.endswith('.png')]\n",
        "\n",
        "benign_images = load_image_paths(benign_dir)\n",
        "malignant_images = load_image_paths(malignant_dir)\n",
        "\n",
        "print(f\"Total Benign Images: {len(benign_images)}\")\n",
        "print(f\"Total Malignant Images: {len(malignant_images)}\")\n",
        "\n",
        "# Create labels (0 = Benign, 1 = Malignant)\n",
        "benign_labels = [0] * len(benign_images)\n",
        "malignant_labels = [1] * len(malignant_images)\n",
        "\n",
        "# Combine images and labels\n",
        "all_images = np.array(benign_images + malignant_images)\n",
        "all_labels = np.array(benign_labels + malignant_labels)\n",
        "\n",
        "# Split into training (70%) and testing (30%)\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(\n",
        "    all_images, all_labels, test_size=0.3, stratify=all_labels, random_state=42\n",
        ")\n",
        "\n",
        "# Further split training set into 60% training and 10% validation\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(\n",
        "    train_images, train_labels, test_size=0.1429, stratify=train_labels, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {len(train_images)}\")\n",
        "print(f\"Validation samples: {len(val_images)}\")\n",
        "print(f\"Testing samples: {len(test_images)}\")\n",
        "\n",
        "# Function to preprocess images\n",
        "def process_path(file_path, label):\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_png(img, channels=3)  # Decode PNG images\n",
        "    img = tf.image.resize(img, [224, 224])  # Resize to 224x224\n",
        "    img = img / 255.0  # Normalize pixel values\n",
        "    return img, label\n",
        "\n",
        "# Create TensorFlow datasets\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "train_dataset = train_dataset.map(process_path).shuffle(1000).batch(BATCH_SIZE)\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
        "val_dataset = val_dataset.map(process_path).batch(BATCH_SIZE)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
        "test_dataset = test_dataset.map(process_path).batch(BATCH_SIZE)\n",
        "\n",
        "# Load ResNet50 without the top classification layer\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the pre-trained layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom classifier on top\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dense(1, activation='sigmoid')(x)  # Binary classification\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "EPOCHS = 100\n",
        "history = model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS)\n",
        "\n",
        "# Evaluate model\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Predict on test data\n",
        "test_preds = model.predict(test_dataset)\n",
        "test_preds = (test_preds > 0.5).astype(int).flatten()\n",
        "\n",
        "# Get confusion matrix values\n",
        "tn, fp, fn, tp = confusion_matrix(test_labels, test_preds).ravel()\n",
        "\n",
        "# Calculate IBA\n",
        "iba = (tp / (tp + fn)) + (tn / (tn + fp)) - 1\n",
        "\n",
        "# Output results\n",
        "f1 = f1_score(test_labels, test_preds)\n",
        "gmean = geometric_mean_score(test_labels, test_preds)\n",
        "\n",
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"G-Mean: {gmean:.4f}\")\n",
        "print(f\"Informedness (IBA): {iba:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOxx6NZKSCQH"
      },
      "source": [
        "***\n",
        "**Magnification Factor: 200X**\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDB6iMF-IFoC",
        "outputId": "579219b1-ce32-474c-f879-cc8675390a35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Benign Images: 623\n",
            "Total Malignant Images: 1390\n",
            "Training samples: 1207\n",
            "Validation samples: 202\n",
            "Testing samples: 604\n",
            "Epoch 1/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 5s/step - accuracy: 0.6090 - loss: 0.6762 - val_accuracy: 0.6881 - val_loss: 0.6446\n",
            "Epoch 2/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 573ms/step - accuracy: 0.6986 - loss: 0.6174 - val_accuracy: 0.6881 - val_loss: 0.6131\n",
            "Epoch 3/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 910ms/step - accuracy: 0.6909 - loss: 0.6075 - val_accuracy: 0.6881 - val_loss: 0.6270\n",
            "Epoch 4/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 907ms/step - accuracy: 0.6831 - loss: 0.6320 - val_accuracy: 0.6881 - val_loss: 0.6097\n",
            "Epoch 5/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 590ms/step - accuracy: 0.6963 - loss: 0.6009 - val_accuracy: 0.6881 - val_loss: 0.6073\n",
            "Epoch 6/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 720ms/step - accuracy: 0.6879 - loss: 0.6118 - val_accuracy: 0.6881 - val_loss: 0.6045\n",
            "Epoch 7/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 661ms/step - accuracy: 0.6917 - loss: 0.6052 - val_accuracy: 0.6881 - val_loss: 0.6058\n",
            "Epoch 8/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 590ms/step - accuracy: 0.6841 - loss: 0.6130 - val_accuracy: 0.6881 - val_loss: 0.6053\n",
            "Epoch 9/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 919ms/step - accuracy: 0.6995 - loss: 0.6069 - val_accuracy: 0.6881 - val_loss: 0.6117\n",
            "Epoch 10/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 587ms/step - accuracy: 0.6932 - loss: 0.6090 - val_accuracy: 0.6881 - val_loss: 0.6013\n",
            "Epoch 11/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 753ms/step - accuracy: 0.6903 - loss: 0.6003 - val_accuracy: 0.6881 - val_loss: 0.6065\n",
            "Epoch 12/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 974ms/step - accuracy: 0.7002 - loss: 0.5939 - val_accuracy: 0.6881 - val_loss: 0.6016\n",
            "Epoch 13/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 657ms/step - accuracy: 0.7008 - loss: 0.5911 - val_accuracy: 0.6931 - val_loss: 0.6047\n",
            "Epoch 14/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 706ms/step - accuracy: 0.6667 - loss: 0.6276 - val_accuracy: 0.6881 - val_loss: 0.5990\n",
            "Epoch 15/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 617ms/step - accuracy: 0.6803 - loss: 0.6092 - val_accuracy: 0.6881 - val_loss: 0.5997\n",
            "Epoch 16/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 612ms/step - accuracy: 0.6805 - loss: 0.6106 - val_accuracy: 0.6881 - val_loss: 0.6006\n",
            "Epoch 17/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 651ms/step - accuracy: 0.6802 - loss: 0.6083 - val_accuracy: 0.6881 - val_loss: 0.6206\n",
            "Epoch 18/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 623ms/step - accuracy: 0.6932 - loss: 0.6123 - val_accuracy: 0.6881 - val_loss: 0.5983\n",
            "Epoch 19/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 726ms/step - accuracy: 0.7196 - loss: 0.5651 - val_accuracy: 0.6931 - val_loss: 0.5992\n",
            "Epoch 20/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 581ms/step - accuracy: 0.6818 - loss: 0.6007 - val_accuracy: 0.6881 - val_loss: 0.5966\n",
            "Epoch 21/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 619ms/step - accuracy: 0.6984 - loss: 0.5838 - val_accuracy: 0.6881 - val_loss: 0.5976\n",
            "Epoch 22/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 649ms/step - accuracy: 0.6934 - loss: 0.5820 - val_accuracy: 0.6881 - val_loss: 0.5967\n",
            "Epoch 23/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 625ms/step - accuracy: 0.6805 - loss: 0.5936 - val_accuracy: 0.6881 - val_loss: 0.6194\n",
            "Epoch 24/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 684ms/step - accuracy: 0.6925 - loss: 0.6132 - val_accuracy: 0.6931 - val_loss: 0.5956\n",
            "Epoch 25/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 621ms/step - accuracy: 0.7089 - loss: 0.5725 - val_accuracy: 0.7030 - val_loss: 0.6086\n",
            "Epoch 26/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 813ms/step - accuracy: 0.6852 - loss: 0.5923 - val_accuracy: 0.6980 - val_loss: 0.5966\n",
            "Epoch 27/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 897ms/step - accuracy: 0.7032 - loss: 0.5844 - val_accuracy: 0.6931 - val_loss: 0.5927\n",
            "Epoch 28/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 718ms/step - accuracy: 0.7009 - loss: 0.5764 - val_accuracy: 0.7030 - val_loss: 0.5990\n",
            "Epoch 29/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 686ms/step - accuracy: 0.6884 - loss: 0.5875 - val_accuracy: 0.6931 - val_loss: 0.5920\n",
            "Epoch 30/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 902ms/step - accuracy: 0.6876 - loss: 0.5937 - val_accuracy: 0.6931 - val_loss: 0.6009\n",
            "Epoch 31/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 590ms/step - accuracy: 0.6889 - loss: 0.5935 - val_accuracy: 0.6881 - val_loss: 0.6051\n",
            "Epoch 32/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 904ms/step - accuracy: 0.6945 - loss: 0.5867 - val_accuracy: 0.6931 - val_loss: 0.5916\n",
            "Epoch 33/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 616ms/step - accuracy: 0.6984 - loss: 0.5739 - val_accuracy: 0.6931 - val_loss: 0.5904\n",
            "Epoch 34/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 620ms/step - accuracy: 0.7118 - loss: 0.5703 - val_accuracy: 0.6931 - val_loss: 0.5905\n",
            "Epoch 35/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 654ms/step - accuracy: 0.7047 - loss: 0.5723 - val_accuracy: 0.7079 - val_loss: 0.6246\n",
            "Epoch 36/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 578ms/step - accuracy: 0.7052 - loss: 0.6012 - val_accuracy: 0.6931 - val_loss: 0.5926\n",
            "Epoch 37/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 983ms/step - accuracy: 0.6836 - loss: 0.5958 - val_accuracy: 0.6931 - val_loss: 0.5893\n",
            "Epoch 38/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 581ms/step - accuracy: 0.6984 - loss: 0.5757 - val_accuracy: 0.7030 - val_loss: 0.5900\n",
            "Epoch 39/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 907ms/step - accuracy: 0.7129 - loss: 0.5661 - val_accuracy: 0.6931 - val_loss: 0.5893\n",
            "Epoch 40/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 572ms/step - accuracy: 0.6953 - loss: 0.5831 - val_accuracy: 0.6881 - val_loss: 0.6283\n",
            "Epoch 41/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 617ms/step - accuracy: 0.6724 - loss: 0.6353 - val_accuracy: 0.6881 - val_loss: 0.6520\n",
            "Epoch 42/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 637ms/step - accuracy: 0.6954 - loss: 0.6197 - val_accuracy: 0.6881 - val_loss: 0.6261\n",
            "Epoch 43/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 675ms/step - accuracy: 0.6806 - loss: 0.6266 - val_accuracy: 0.6931 - val_loss: 0.6033\n",
            "Epoch 44/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 656ms/step - accuracy: 0.7157 - loss: 0.5753 - val_accuracy: 0.6931 - val_loss: 0.5895\n",
            "Epoch 45/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 595ms/step - accuracy: 0.6801 - loss: 0.5932 - val_accuracy: 0.6931 - val_loss: 0.6047\n",
            "Epoch 46/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 634ms/step - accuracy: 0.7144 - loss: 0.5765 - val_accuracy: 0.6931 - val_loss: 0.5916\n",
            "Epoch 47/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 624ms/step - accuracy: 0.7064 - loss: 0.5687 - val_accuracy: 0.7030 - val_loss: 0.5924\n",
            "Epoch 48/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 905ms/step - accuracy: 0.7036 - loss: 0.5752 - val_accuracy: 0.7030 - val_loss: 0.5961\n",
            "Epoch 49/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 705ms/step - accuracy: 0.7025 - loss: 0.5714 - val_accuracy: 0.6980 - val_loss: 0.6207\n",
            "Epoch 50/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 590ms/step - accuracy: 0.7122 - loss: 0.5882 - val_accuracy: 0.6980 - val_loss: 0.6204\n",
            "Epoch 51/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 913ms/step - accuracy: 0.7047 - loss: 0.5889 - val_accuracy: 0.7030 - val_loss: 0.6109\n",
            "Epoch 52/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 913ms/step - accuracy: 0.7218 - loss: 0.5911 - val_accuracy: 0.7079 - val_loss: 0.6114\n",
            "Epoch 53/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 701ms/step - accuracy: 0.7073 - loss: 0.5845 - val_accuracy: 0.6980 - val_loss: 0.5860\n",
            "Epoch 54/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 618ms/step - accuracy: 0.7180 - loss: 0.5623 - val_accuracy: 0.7030 - val_loss: 0.5856\n",
            "Epoch 55/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 627ms/step - accuracy: 0.7058 - loss: 0.5745 - val_accuracy: 0.7030 - val_loss: 0.5859\n",
            "Epoch 56/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 562ms/step - accuracy: 0.7012 - loss: 0.5775 - val_accuracy: 0.6980 - val_loss: 0.5851\n",
            "Epoch 57/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 634ms/step - accuracy: 0.7149 - loss: 0.5740 - val_accuracy: 0.7030 - val_loss: 0.5852\n",
            "Epoch 58/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 617ms/step - accuracy: 0.7171 - loss: 0.5612 - val_accuracy: 0.6980 - val_loss: 0.5847\n",
            "Epoch 59/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 897ms/step - accuracy: 0.7090 - loss: 0.5803 - val_accuracy: 0.6980 - val_loss: 0.5844\n",
            "Epoch 60/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 628ms/step - accuracy: 0.6952 - loss: 0.5809 - val_accuracy: 0.7030 - val_loss: 0.5841\n",
            "Epoch 61/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 571ms/step - accuracy: 0.7013 - loss: 0.5674 - val_accuracy: 0.7030 - val_loss: 0.5852\n",
            "Epoch 62/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 902ms/step - accuracy: 0.7175 - loss: 0.5649 - val_accuracy: 0.6980 - val_loss: 0.5836\n",
            "Epoch 63/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 911ms/step - accuracy: 0.6886 - loss: 0.5805 - val_accuracy: 0.6931 - val_loss: 0.5879\n",
            "Epoch 64/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 656ms/step - accuracy: 0.7139 - loss: 0.5500 - val_accuracy: 0.7030 - val_loss: 0.5835\n",
            "Epoch 65/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 584ms/step - accuracy: 0.6957 - loss: 0.5738 - val_accuracy: 0.6931 - val_loss: 0.5872\n",
            "Epoch 66/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 635ms/step - accuracy: 0.6984 - loss: 0.5743 - val_accuracy: 0.7030 - val_loss: 0.5821\n",
            "Epoch 67/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 682ms/step - accuracy: 0.7038 - loss: 0.5693 - val_accuracy: 0.6980 - val_loss: 0.5827\n",
            "Epoch 68/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 898ms/step - accuracy: 0.7033 - loss: 0.5749 - val_accuracy: 0.7030 - val_loss: 0.5911\n",
            "Epoch 69/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 646ms/step - accuracy: 0.7245 - loss: 0.5610 - val_accuracy: 0.6980 - val_loss: 0.5810\n",
            "Epoch 70/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 576ms/step - accuracy: 0.7134 - loss: 0.5515 - val_accuracy: 0.6980 - val_loss: 0.5806\n",
            "Epoch 71/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 700ms/step - accuracy: 0.7035 - loss: 0.5640 - val_accuracy: 0.6980 - val_loss: 0.5802\n",
            "Epoch 72/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 689ms/step - accuracy: 0.7030 - loss: 0.5664 - val_accuracy: 0.6980 - val_loss: 0.5800\n",
            "Epoch 73/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 683ms/step - accuracy: 0.6974 - loss: 0.5765 - val_accuracy: 0.7079 - val_loss: 0.5835\n",
            "Epoch 74/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 670ms/step - accuracy: 0.7145 - loss: 0.5656 - val_accuracy: 0.7129 - val_loss: 0.5821\n",
            "Epoch 75/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 905ms/step - accuracy: 0.7096 - loss: 0.5596 - val_accuracy: 0.7079 - val_loss: 0.5926\n",
            "Epoch 76/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 619ms/step - accuracy: 0.7258 - loss: 0.5627 - val_accuracy: 0.7079 - val_loss: 0.5839\n",
            "Epoch 77/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 899ms/step - accuracy: 0.7210 - loss: 0.5573 - val_accuracy: 0.6931 - val_loss: 0.6082\n",
            "Epoch 78/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 643ms/step - accuracy: 0.7222 - loss: 0.5624 - val_accuracy: 0.7030 - val_loss: 0.5916\n",
            "Epoch 79/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 626ms/step - accuracy: 0.7269 - loss: 0.5600 - val_accuracy: 0.7129 - val_loss: 0.5779\n",
            "Epoch 80/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 689ms/step - accuracy: 0.7143 - loss: 0.5491 - val_accuracy: 0.7079 - val_loss: 0.5797\n",
            "Epoch 81/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 610ms/step - accuracy: 0.7195 - loss: 0.5530 - val_accuracy: 0.6980 - val_loss: 0.5827\n",
            "Epoch 82/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 710ms/step - accuracy: 0.7031 - loss: 0.5648 - val_accuracy: 0.6832 - val_loss: 0.5973\n",
            "Epoch 83/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 621ms/step - accuracy: 0.7045 - loss: 0.5700 - val_accuracy: 0.6980 - val_loss: 0.5819\n",
            "Epoch 84/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 657ms/step - accuracy: 0.7232 - loss: 0.5562 - val_accuracy: 0.6980 - val_loss: 0.5865\n",
            "Epoch 85/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 580ms/step - accuracy: 0.7360 - loss: 0.5538 - val_accuracy: 0.7030 - val_loss: 0.5796\n",
            "Epoch 86/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 705ms/step - accuracy: 0.7043 - loss: 0.5572 - val_accuracy: 0.6980 - val_loss: 0.5745\n",
            "Epoch 87/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 619ms/step - accuracy: 0.7105 - loss: 0.5600 - val_accuracy: 0.6980 - val_loss: 0.5857\n",
            "Epoch 88/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 914ms/step - accuracy: 0.7116 - loss: 0.5678 - val_accuracy: 0.6931 - val_loss: 0.6112\n",
            "Epoch 89/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 727ms/step - accuracy: 0.7114 - loss: 0.5821 - val_accuracy: 0.6980 - val_loss: 0.5819\n",
            "Epoch 90/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 635ms/step - accuracy: 0.7150 - loss: 0.5557 - val_accuracy: 0.6980 - val_loss: 0.5737\n",
            "Epoch 91/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 620ms/step - accuracy: 0.7084 - loss: 0.5573 - val_accuracy: 0.7030 - val_loss: 0.5850\n",
            "Epoch 92/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 642ms/step - accuracy: 0.7271 - loss: 0.5499 - val_accuracy: 0.7129 - val_loss: 0.5731\n",
            "Epoch 93/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 618ms/step - accuracy: 0.7167 - loss: 0.5559 - val_accuracy: 0.6980 - val_loss: 0.5724\n",
            "Epoch 94/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 771ms/step - accuracy: 0.7228 - loss: 0.5523 - val_accuracy: 0.6931 - val_loss: 0.5840\n",
            "Epoch 95/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 692ms/step - accuracy: 0.7422 - loss: 0.5518 - val_accuracy: 0.7079 - val_loss: 0.5731\n",
            "Epoch 96/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 572ms/step - accuracy: 0.7204 - loss: 0.5570 - val_accuracy: 0.6980 - val_loss: 0.5750\n",
            "Epoch 97/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 908ms/step - accuracy: 0.7279 - loss: 0.5575 - val_accuracy: 0.7030 - val_loss: 0.5714\n",
            "Epoch 98/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 572ms/step - accuracy: 0.7186 - loss: 0.5414 - val_accuracy: 0.7079 - val_loss: 0.5708\n",
            "Epoch 99/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 900ms/step - accuracy: 0.7141 - loss: 0.5650 - val_accuracy: 0.7079 - val_loss: 0.6034\n",
            "Epoch 100/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 579ms/step - accuracy: 0.7211 - loss: 0.5554 - val_accuracy: 0.6980 - val_loss: 0.5809\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7ce29a8fe5c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m9s\u001b[0m 10s/step "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7ce29a8fe5c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 12s/step\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.7125 - loss: 0.5534\n",
            "Test Accuracy: 0.7053\n",
            "F1 Score: 0.8231\n",
            "G-Mean: 0.2524\n",
            "Informedness (IBA): 0.0570\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "\n",
        "# Define dataset paths\n",
        "benign_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/benign/200X\"\n",
        "malignant_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/malignant/200X\"\n",
        "\n",
        "# Function to load image paths\n",
        "def load_image_paths(dir_path):\n",
        "    return [os.path.join(dir_path, img) for img in os.listdir(dir_path) if img.endswith('.png')]\n",
        "\n",
        "benign_images = load_image_paths(benign_dir)\n",
        "malignant_images = load_image_paths(malignant_dir)\n",
        "\n",
        "print(f\"Total Benign Images: {len(benign_images)}\")\n",
        "print(f\"Total Malignant Images: {len(malignant_images)}\")\n",
        "\n",
        "# Create labels (0 = Benign, 1 = Malignant)\n",
        "benign_labels = [0] * len(benign_images)\n",
        "malignant_labels = [1] * len(malignant_images)\n",
        "\n",
        "# Combine images and labels\n",
        "all_images = np.array(benign_images + malignant_images)\n",
        "all_labels = np.array(benign_labels + malignant_labels)\n",
        "\n",
        "# Split into training (70%) and testing (30%)\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(\n",
        "    all_images, all_labels, test_size=0.3, stratify=all_labels, random_state=42\n",
        ")\n",
        "\n",
        "# Further split training set into 60% training and 10% validation\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(\n",
        "    train_images, train_labels, test_size=0.1429, stratify=train_labels, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {len(train_images)}\")\n",
        "print(f\"Validation samples: {len(val_images)}\")\n",
        "print(f\"Testing samples: {len(test_images)}\")\n",
        "\n",
        "# Function to preprocess images\n",
        "def process_path(file_path, label):\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_png(img, channels=3)  # Decode PNG images\n",
        "    img = tf.image.resize(img, [224, 224])  # Resize to 224x224\n",
        "    img = img / 255.0  # Normalize pixel values\n",
        "    return img, label\n",
        "\n",
        "# Create TensorFlow datasets\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "train_dataset = train_dataset.map(process_path).shuffle(1000).batch(BATCH_SIZE)\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
        "val_dataset = val_dataset.map(process_path).batch(BATCH_SIZE)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
        "test_dataset = test_dataset.map(process_path).batch(BATCH_SIZE)\n",
        "\n",
        "# Load ResNet50 without the top classification layer\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the pre-trained layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom classifier on top\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dense(1, activation='sigmoid')(x)  # Binary classification\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "EPOCHS = 100\n",
        "history = model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS)\n",
        "\n",
        "# Evaluate model\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Predict on test data\n",
        "test_preds = model.predict(test_dataset)\n",
        "test_preds = (test_preds > 0.5).astype(int).flatten()\n",
        "\n",
        "# Get confusion matrix values\n",
        "tn, fp, fn, tp = confusion_matrix(test_labels, test_preds).ravel()\n",
        "\n",
        "# Calculate IBA\n",
        "iba = (tp / (tp + fn)) + (tn / (tn + fp)) - 1\n",
        "\n",
        "# Output results\n",
        "f1 = f1_score(test_labels, test_preds)\n",
        "gmean = geometric_mean_score(test_labels, test_preds)\n",
        "\n",
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"G-Mean: {gmean:.4f}\")\n",
        "print(f\"Informedness (IBA): {iba:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84POaEC3SGen"
      },
      "source": [
        "***\n",
        "**Magnification Factor: 400X**\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "M59TlvEGJB4g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14e6c7f7-3a9b-47b4-f8f2-4a10fbe38039"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Benign Images: 588\n",
            "Total Malignant Images: 1232\n",
            "Training samples: 1091\n",
            "Validation samples: 183\n",
            "Testing samples: 546\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 6s/step - accuracy: 0.5677 - loss: 0.7285 - val_accuracy: 0.6776 - val_loss: 0.6366\n",
            "Epoch 2/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 516ms/step - accuracy: 0.6768 - loss: 0.6431 - val_accuracy: 0.6776 - val_loss: 0.6256\n",
            "Epoch 3/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 600ms/step - accuracy: 0.6802 - loss: 0.6252 - val_accuracy: 0.6776 - val_loss: 0.6408\n",
            "Epoch 4/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 492ms/step - accuracy: 0.6870 - loss: 0.6242 - val_accuracy: 0.6776 - val_loss: 0.6253\n",
            "Epoch 5/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 642ms/step - accuracy: 0.6826 - loss: 0.6194 - val_accuracy: 0.6776 - val_loss: 0.6192\n",
            "Epoch 6/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 491ms/step - accuracy: 0.6687 - loss: 0.6251 - val_accuracy: 0.6776 - val_loss: 0.6204\n",
            "Epoch 7/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 603ms/step - accuracy: 0.6859 - loss: 0.6121 - val_accuracy: 0.6776 - val_loss: 0.6173\n",
            "Epoch 8/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 505ms/step - accuracy: 0.6775 - loss: 0.6137 - val_accuracy: 0.6776 - val_loss: 0.6189\n",
            "Epoch 9/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 604ms/step - accuracy: 0.6805 - loss: 0.6191 - val_accuracy: 0.6776 - val_loss: 0.6137\n",
            "Epoch 10/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 494ms/step - accuracy: 0.6706 - loss: 0.6171 - val_accuracy: 0.6776 - val_loss: 0.6126\n",
            "Epoch 11/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 934ms/step - accuracy: 0.6942 - loss: 0.5969 - val_accuracy: 0.6776 - val_loss: 0.6336\n",
            "Epoch 12/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 598ms/step - accuracy: 0.6801 - loss: 0.6123 - val_accuracy: 0.6776 - val_loss: 0.6243\n",
            "Epoch 13/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 607ms/step - accuracy: 0.6721 - loss: 0.6166 - val_accuracy: 0.6776 - val_loss: 0.6113\n",
            "Epoch 14/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 607ms/step - accuracy: 0.6741 - loss: 0.6281 - val_accuracy: 0.6776 - val_loss: 0.6063\n",
            "Epoch 15/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 601ms/step - accuracy: 0.6286 - loss: 0.6463 - val_accuracy: 0.6776 - val_loss: 0.6101\n",
            "Epoch 16/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 607ms/step - accuracy: 0.6761 - loss: 0.6090 - val_accuracy: 0.6776 - val_loss: 0.6060\n",
            "Epoch 17/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 599ms/step - accuracy: 0.6879 - loss: 0.5977 - val_accuracy: 0.6776 - val_loss: 0.6033\n",
            "Epoch 18/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 601ms/step - accuracy: 0.6653 - loss: 0.6208 - val_accuracy: 0.6776 - val_loss: 0.6020\n",
            "Epoch 19/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 504ms/step - accuracy: 0.6818 - loss: 0.6104 - val_accuracy: 0.6776 - val_loss: 0.6022\n",
            "Epoch 20/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 615ms/step - accuracy: 0.6659 - loss: 0.6231 - val_accuracy: 0.6776 - val_loss: 0.6303\n",
            "Epoch 21/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 604ms/step - accuracy: 0.6861 - loss: 0.6222 - val_accuracy: 0.6776 - val_loss: 0.5993\n",
            "Epoch 22/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 497ms/step - accuracy: 0.6862 - loss: 0.5965 - val_accuracy: 0.6776 - val_loss: 0.5994\n",
            "Epoch 23/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 505ms/step - accuracy: 0.6625 - loss: 0.6227 - val_accuracy: 0.6776 - val_loss: 0.6007\n",
            "Epoch 24/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 922ms/step - accuracy: 0.6919 - loss: 0.6095 - val_accuracy: 0.6776 - val_loss: 0.6717\n",
            "Epoch 25/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 503ms/step - accuracy: 0.6701 - loss: 0.6428 - val_accuracy: 0.6776 - val_loss: 0.6079\n",
            "Epoch 26/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 582ms/step - accuracy: 0.6647 - loss: 0.6258 - val_accuracy: 0.6776 - val_loss: 0.6058\n",
            "Epoch 27/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 614ms/step - accuracy: 0.6774 - loss: 0.6017 - val_accuracy: 0.6776 - val_loss: 0.5984\n",
            "Epoch 28/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 506ms/step - accuracy: 0.6697 - loss: 0.6093 - val_accuracy: 0.6776 - val_loss: 0.5958\n",
            "Epoch 29/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 933ms/step - accuracy: 0.6797 - loss: 0.5971 - val_accuracy: 0.6776 - val_loss: 0.5952\n",
            "Epoch 30/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 503ms/step - accuracy: 0.6625 - loss: 0.6115 - val_accuracy: 0.6776 - val_loss: 0.6063\n",
            "Epoch 31/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 617ms/step - accuracy: 0.6797 - loss: 0.6062 - val_accuracy: 0.6776 - val_loss: 0.5925\n",
            "Epoch 32/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 617ms/step - accuracy: 0.6740 - loss: 0.5981 - val_accuracy: 0.6776 - val_loss: 0.5978\n",
            "Epoch 33/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 592ms/step - accuracy: 0.6695 - loss: 0.6125 - val_accuracy: 0.6776 - val_loss: 0.6215\n",
            "Epoch 34/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 530ms/step - accuracy: 0.6923 - loss: 0.5977 - val_accuracy: 0.6885 - val_loss: 0.5936\n",
            "Epoch 35/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 624ms/step - accuracy: 0.6791 - loss: 0.5882 - val_accuracy: 0.6885 - val_loss: 0.5918\n",
            "Epoch 36/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 622ms/step - accuracy: 0.6701 - loss: 0.5947 - val_accuracy: 0.6776 - val_loss: 0.5916\n",
            "Epoch 37/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 944ms/step - accuracy: 0.6759 - loss: 0.5954 - val_accuracy: 0.6776 - val_loss: 0.5889\n",
            "Epoch 38/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 626ms/step - accuracy: 0.6691 - loss: 0.6002 - val_accuracy: 0.6776 - val_loss: 0.6476\n",
            "Epoch 39/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 633ms/step - accuracy: 0.6629 - loss: 0.6494 - val_accuracy: 0.6776 - val_loss: 0.6036\n",
            "Epoch 40/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 630ms/step - accuracy: 0.6708 - loss: 0.6388 - val_accuracy: 0.6776 - val_loss: 0.5894\n",
            "Epoch 41/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 574ms/step - accuracy: 0.7019 - loss: 0.5900 - val_accuracy: 0.6995 - val_loss: 0.6089\n",
            "Epoch 42/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 619ms/step - accuracy: 0.6905 - loss: 0.6081 - val_accuracy: 0.6940 - val_loss: 0.6029\n",
            "Epoch 43/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 523ms/step - accuracy: 0.6654 - loss: 0.5994 - val_accuracy: 0.6885 - val_loss: 0.5873\n",
            "Epoch 44/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 532ms/step - accuracy: 0.6801 - loss: 0.5908 - val_accuracy: 0.6776 - val_loss: 0.5909\n",
            "Epoch 45/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 514ms/step - accuracy: 0.6924 - loss: 0.5835 - val_accuracy: 0.6776 - val_loss: 0.5886\n",
            "Epoch 46/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 522ms/step - accuracy: 0.6767 - loss: 0.5874 - val_accuracy: 0.6776 - val_loss: 0.5885\n",
            "Epoch 47/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 628ms/step - accuracy: 0.6872 - loss: 0.5896 - val_accuracy: 0.6776 - val_loss: 0.5857\n",
            "Epoch 48/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 621ms/step - accuracy: 0.6693 - loss: 0.5994 - val_accuracy: 0.6831 - val_loss: 0.5845\n",
            "Epoch 49/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 636ms/step - accuracy: 0.6812 - loss: 0.5765 - val_accuracy: 0.6885 - val_loss: 0.6025\n",
            "Epoch 50/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 625ms/step - accuracy: 0.7103 - loss: 0.5896 - val_accuracy: 0.7104 - val_loss: 0.5863\n",
            "Epoch 51/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 522ms/step - accuracy: 0.6800 - loss: 0.5901 - val_accuracy: 0.6831 - val_loss: 0.5849\n",
            "Epoch 52/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 580ms/step - accuracy: 0.6698 - loss: 0.5918 - val_accuracy: 0.6776 - val_loss: 0.5858\n",
            "Epoch 53/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 615ms/step - accuracy: 0.6912 - loss: 0.5773 - val_accuracy: 0.6885 - val_loss: 0.5817\n",
            "Epoch 54/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 527ms/step - accuracy: 0.6729 - loss: 0.6072 - val_accuracy: 0.6776 - val_loss: 0.5992\n",
            "Epoch 55/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 624ms/step - accuracy: 0.6747 - loss: 0.6165 - val_accuracy: 0.6776 - val_loss: 0.5922\n",
            "Epoch 56/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 631ms/step - accuracy: 0.6764 - loss: 0.5857 - val_accuracy: 0.6831 - val_loss: 0.5819\n",
            "Epoch 57/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 534ms/step - accuracy: 0.6813 - loss: 0.5958 - val_accuracy: 0.6885 - val_loss: 0.5802\n",
            "Epoch 58/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 634ms/step - accuracy: 0.6897 - loss: 0.5874 - val_accuracy: 0.7104 - val_loss: 0.5810\n",
            "Epoch 59/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 626ms/step - accuracy: 0.6864 - loss: 0.5871 - val_accuracy: 0.6831 - val_loss: 0.6130\n",
            "Epoch 60/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 626ms/step - accuracy: 0.6917 - loss: 0.6070 - val_accuracy: 0.6776 - val_loss: 0.5910\n",
            "Epoch 61/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 522ms/step - accuracy: 0.6607 - loss: 0.6076 - val_accuracy: 0.6776 - val_loss: 0.5957\n",
            "Epoch 62/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 530ms/step - accuracy: 0.7158 - loss: 0.5544 - val_accuracy: 0.6940 - val_loss: 0.5780\n",
            "Epoch 63/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 525ms/step - accuracy: 0.7044 - loss: 0.5672 - val_accuracy: 0.6885 - val_loss: 0.5820\n",
            "Epoch 64/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 526ms/step - accuracy: 0.6926 - loss: 0.5737 - val_accuracy: 0.6885 - val_loss: 0.5817\n",
            "Epoch 65/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 532ms/step - accuracy: 0.7038 - loss: 0.5660 - val_accuracy: 0.6995 - val_loss: 0.5960\n",
            "Epoch 66/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 524ms/step - accuracy: 0.6954 - loss: 0.5949 - val_accuracy: 0.6940 - val_loss: 0.5763\n",
            "Epoch 67/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 636ms/step - accuracy: 0.6914 - loss: 0.5863 - val_accuracy: 0.6995 - val_loss: 0.5774\n",
            "Epoch 68/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 623ms/step - accuracy: 0.7097 - loss: 0.5897 - val_accuracy: 0.7049 - val_loss: 0.5967\n",
            "Epoch 69/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 522ms/step - accuracy: 0.7252 - loss: 0.5849 - val_accuracy: 0.7049 - val_loss: 0.5760\n",
            "Epoch 70/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 523ms/step - accuracy: 0.6996 - loss: 0.5724 - val_accuracy: 0.6995 - val_loss: 0.5759\n",
            "Epoch 71/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 534ms/step - accuracy: 0.6871 - loss: 0.5764 - val_accuracy: 0.6885 - val_loss: 0.5769\n",
            "Epoch 72/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 942ms/step - accuracy: 0.6803 - loss: 0.5869 - val_accuracy: 0.6776 - val_loss: 0.6356\n",
            "Epoch 73/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 518ms/step - accuracy: 0.6448 - loss: 0.6571 - val_accuracy: 0.6776 - val_loss: 0.6004\n",
            "Epoch 74/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 630ms/step - accuracy: 0.6993 - loss: 0.5771 - val_accuracy: 0.6885 - val_loss: 0.5774\n",
            "Epoch 75/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 625ms/step - accuracy: 0.6972 - loss: 0.5753 - val_accuracy: 0.6831 - val_loss: 0.5836\n",
            "Epoch 76/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 511ms/step - accuracy: 0.7001 - loss: 0.5676 - val_accuracy: 0.6940 - val_loss: 0.5778\n",
            "Epoch 77/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 949ms/step - accuracy: 0.6921 - loss: 0.5783 - val_accuracy: 0.6940 - val_loss: 0.5743\n",
            "Epoch 78/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 630ms/step - accuracy: 0.7039 - loss: 0.5714 - val_accuracy: 0.6940 - val_loss: 0.5733\n",
            "Epoch 79/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 633ms/step - accuracy: 0.6990 - loss: 0.5693 - val_accuracy: 0.6831 - val_loss: 0.5815\n",
            "Epoch 80/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 521ms/step - accuracy: 0.6962 - loss: 0.5680 - val_accuracy: 0.6831 - val_loss: 0.5823\n",
            "Epoch 81/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 947ms/step - accuracy: 0.6729 - loss: 0.5931 - val_accuracy: 0.6776 - val_loss: 0.6119\n",
            "Epoch 82/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 517ms/step - accuracy: 0.6815 - loss: 0.6001 - val_accuracy: 0.6776 - val_loss: 0.6107\n",
            "Epoch 83/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 627ms/step - accuracy: 0.6620 - loss: 0.6354 - val_accuracy: 0.6776 - val_loss: 0.6493\n",
            "Epoch 84/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 631ms/step - accuracy: 0.6959 - loss: 0.6048 - val_accuracy: 0.6885 - val_loss: 0.5745\n",
            "Epoch 85/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 629ms/step - accuracy: 0.6997 - loss: 0.5717 - val_accuracy: 0.6885 - val_loss: 0.5747\n",
            "Epoch 86/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 624ms/step - accuracy: 0.6911 - loss: 0.5731 - val_accuracy: 0.6995 - val_loss: 0.5708\n",
            "Epoch 87/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 621ms/step - accuracy: 0.6823 - loss: 0.5766 - val_accuracy: 0.6940 - val_loss: 0.5735\n",
            "Epoch 88/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 679ms/step - accuracy: 0.7079 - loss: 0.5630 - val_accuracy: 0.7049 - val_loss: 0.5701\n",
            "Epoch 89/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 567ms/step - accuracy: 0.7009 - loss: 0.5648 - val_accuracy: 0.6831 - val_loss: 0.5812\n",
            "Epoch 90/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 635ms/step - accuracy: 0.6745 - loss: 0.5926 - val_accuracy: 0.6831 - val_loss: 0.5913\n",
            "Epoch 91/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 624ms/step - accuracy: 0.6876 - loss: 0.5943 - val_accuracy: 0.6831 - val_loss: 0.5964\n",
            "Epoch 92/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 633ms/step - accuracy: 0.7117 - loss: 0.5746 - val_accuracy: 0.6995 - val_loss: 0.5686\n",
            "Epoch 93/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 526ms/step - accuracy: 0.6999 - loss: 0.5645 - val_accuracy: 0.6885 - val_loss: 0.5710\n",
            "Epoch 94/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 627ms/step - accuracy: 0.7023 - loss: 0.5776 - val_accuracy: 0.6995 - val_loss: 0.5791\n",
            "Epoch 95/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 527ms/step - accuracy: 0.7070 - loss: 0.5733 - val_accuracy: 0.6885 - val_loss: 0.5772\n",
            "Epoch 96/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 603ms/step - accuracy: 0.7129 - loss: 0.5531 - val_accuracy: 0.6831 - val_loss: 0.5704\n",
            "Epoch 97/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 966ms/step - accuracy: 0.7116 - loss: 0.5637 - val_accuracy: 0.6885 - val_loss: 0.5746\n",
            "Epoch 98/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 626ms/step - accuracy: 0.7014 - loss: 0.5677 - val_accuracy: 0.6940 - val_loss: 0.5698\n",
            "Epoch 99/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 631ms/step - accuracy: 0.6969 - loss: 0.5602 - val_accuracy: 0.6885 - val_loss: 0.5692\n",
            "Epoch 100/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 623ms/step - accuracy: 0.7294 - loss: 0.5473 - val_accuracy: 0.7104 - val_loss: 0.5674\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 18s/step\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.7008 - loss: 0.5677\n",
            "Test Accuracy: 0.6905\n",
            "F1 Score: 0.8124\n",
            "G-Mean: 0.2486\n",
            "Informedness (IBA): 0.0517\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "\n",
        "# Define dataset paths\n",
        "benign_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/benign/400X\"\n",
        "malignant_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/malignant/400X\"\n",
        "\n",
        "# Function to load image paths\n",
        "def load_image_paths(dir_path):\n",
        "    return [os.path.join(dir_path, img) for img in os.listdir(dir_path) if img.endswith('.png')]\n",
        "\n",
        "benign_images = load_image_paths(benign_dir)\n",
        "malignant_images = load_image_paths(malignant_dir)\n",
        "\n",
        "print(f\"Total Benign Images: {len(benign_images)}\")\n",
        "print(f\"Total Malignant Images: {len(malignant_images)}\")\n",
        "\n",
        "# Create labels (0 = Benign, 1 = Malignant)\n",
        "benign_labels = [0] * len(benign_images)\n",
        "malignant_labels = [1] * len(malignant_images)\n",
        "\n",
        "# Combine images and labels\n",
        "all_images = np.array(benign_images + malignant_images)\n",
        "all_labels = np.array(benign_labels + malignant_labels)\n",
        "\n",
        "# Split into training (70%) and testing (30%)\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(\n",
        "    all_images, all_labels, test_size=0.3, stratify=all_labels, random_state=42\n",
        ")\n",
        "\n",
        "# Further split training set into 60% training and 10% validation\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(\n",
        "    train_images, train_labels, test_size=0.1429, stratify=train_labels, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {len(train_images)}\")\n",
        "print(f\"Validation samples: {len(val_images)}\")\n",
        "print(f\"Testing samples: {len(test_images)}\")\n",
        "\n",
        "# Function to preprocess images\n",
        "def process_path(file_path, label):\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_png(img, channels=3)  # Decode PNG images\n",
        "    img = tf.image.resize(img, [224, 224])  # Resize to 224x224\n",
        "    img = img / 255.0  # Normalize pixel values\n",
        "    return img, label\n",
        "\n",
        "# Create TensorFlow datasets\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "train_dataset = train_dataset.map(process_path).shuffle(1000).batch(BATCH_SIZE)\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
        "val_dataset = val_dataset.map(process_path).batch(BATCH_SIZE)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
        "test_dataset = test_dataset.map(process_path).batch(BATCH_SIZE)\n",
        "\n",
        "# Load ResNet50 without the top classification layer\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the pre-trained layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom classifier on top\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dense(1, activation='sigmoid')(x)  # Binary classification\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "EPOCHS = 100\n",
        "history = model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS)\n",
        "\n",
        "# Evaluate model\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Predict on test data\n",
        "test_preds = model.predict(test_dataset)\n",
        "test_preds = (test_preds > 0.5).astype(int).flatten()\n",
        "\n",
        "# Get confusion matrix values\n",
        "tn, fp, fn, tp = confusion_matrix(test_labels, test_preds).ravel()\n",
        "\n",
        "# Calculate IBA\n",
        "iba = (tp / (tp + fn)) + (tn / (tn + fp)) - 1\n",
        "\n",
        "# Output results\n",
        "f1 = f1_score(test_labels, test_preds)\n",
        "gmean = geometric_mean_score(test_labels, test_preds)\n",
        "\n",
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"G-Mean: {gmean:.4f}\")\n",
        "print(f\"Informedness (IBA): {iba:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDW4hPXtSP-b"
      },
      "source": [
        "# Here is a table summarizing the performance metrics for all magnification factors (40X, 100X, 200X, 400X) from notebook:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "hmMYY48YOrT7",
        "outputId": "0c22c300-732f-4caf-b2da-3041a5800d7b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7cc902bebad0>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_352b7 th {\n",
              "  background-color: #000000;\n",
              "  font-weight: bold;\n",
              "  color: white;\n",
              "}\n",
              "#T_352b7_row0_col0, #T_352b7_row0_col1, #T_352b7_row0_col2, #T_352b7_row0_col3, #T_352b7_row0_col4, #T_352b7_row1_col0, #T_352b7_row1_col1, #T_352b7_row1_col2, #T_352b7_row1_col3, #T_352b7_row1_col4, #T_352b7_row2_col0, #T_352b7_row2_col1, #T_352b7_row2_col2, #T_352b7_row2_col3, #T_352b7_row2_col4, #T_352b7_row3_col0, #T_352b7_row3_col1, #T_352b7_row3_col2, #T_352b7_row3_col3, #T_352b7_row3_col4 {\n",
              "  text-align: center;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_352b7\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th id=\"T_352b7_level0_col0\" class=\"col_heading level0 col0\" >Magnification</th>\n",
              "      <th id=\"T_352b7_level0_col1\" class=\"col_heading level0 col1\" >Test Accuracy</th>\n",
              "      <th id=\"T_352b7_level0_col2\" class=\"col_heading level0 col2\" >F1 Score</th>\n",
              "      <th id=\"T_352b7_level0_col3\" class=\"col_heading level0 col3\" >G-Mean</th>\n",
              "      <th id=\"T_352b7_level0_col4\" class=\"col_heading level0 col4\" >Informedness (IBA)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td id=\"T_352b7_row0_col0\" class=\"data row0 col0\" >40X</td>\n",
              "      <td id=\"T_352b7_row0_col1\" class=\"data row0 col1\" >0.7095</td>\n",
              "      <td id=\"T_352b7_row0_col2\" class=\"data row0 col2\" >0.8214</td>\n",
              "      <td id=\"T_352b7_row0_col3\" class=\"data row0 col3\" >0.3597</td>\n",
              "      <td id=\"T_352b7_row0_col4\" class=\"data row0 col4\" >0.1062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_352b7_row1_col0\" class=\"data row1 col0\" >100X</td>\n",
              "      <td id=\"T_352b7_row1_col1\" class=\"data row1 col1\" >0.7125</td>\n",
              "      <td id=\"T_352b7_row1_col2\" class=\"data row1 col2\" >0.8189</td>\n",
              "      <td id=\"T_352b7_row1_col3\" class=\"data row1 col3\" >0.4346</td>\n",
              "      <td id=\"T_352b7_row1_col4\" class=\"data row1 col4\" >0.1443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_352b7_row2_col0\" class=\"data row2 col0\" >200X</td>\n",
              "      <td id=\"T_352b7_row2_col1\" class=\"data row2 col1\" >0.7053</td>\n",
              "      <td id=\"T_352b7_row2_col2\" class=\"data row2 col2\" >0.8231</td>\n",
              "      <td id=\"T_352b7_row2_col3\" class=\"data row2 col3\" >0.2524</td>\n",
              "      <td id=\"T_352b7_row2_col4\" class=\"data row2 col4\" >0.0570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_352b7_row3_col0\" class=\"data row3 col0\" >400X</td>\n",
              "      <td id=\"T_352b7_row3_col1\" class=\"data row3 col1\" >0.6905</td>\n",
              "      <td id=\"T_352b7_row3_col2\" class=\"data row3 col2\" >0.8124</td>\n",
              "      <td id=\"T_352b7_row3_col3\" class=\"data row3 col3\" >0.2486</td>\n",
              "      <td id=\"T_352b7_row3_col4\" class=\"data row3 col4\" >0.0517</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame with the provided values\n",
        "data = {\n",
        "    'Magnification': ['40X', '100X', '200X', '400X'],\n",
        "    'Test Accuracy': [0.7095, 0.7125, 0.7053, 0.6905],\n",
        "    'F1 Score': [0.8214, 0.8189, 0.8231, 0.8124],\n",
        "    'G-Mean': [0.3597, 0.4346, 0.2524, 0.2486],\n",
        "    'Informedness (IBA)': [0.1062, 0.1443, 0.0570, 0.0517]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display the table with formatting\n",
        "styled_df = df.style \\\n",
        "    .format({\n",
        "        'Test Accuracy': '{:.4f}',\n",
        "        'F1 Score': '{:.4f}',\n",
        "        'G-Mean': '{:.4f}',\n",
        "        'Informedness (IBA)': '{:.4f}'\n",
        "    }) \\\n",
        "    .set_properties(**{'text-align': 'center'}) \\\n",
        "    .set_table_styles([\n",
        "        {'selector': 'th', 'props': [('background-color', '#000000'), ('font-weight', 'bold'), ('color', 'white')]}\n",
        "    ]) \\\n",
        "    .hide(axis='index')\n",
        "\n",
        "styled_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mHI2BO2Pslk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}