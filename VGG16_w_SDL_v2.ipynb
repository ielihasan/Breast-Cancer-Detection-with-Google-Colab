{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SG7nZHT7gipl"
      },
      "source": [
        "#**Modified VGG16 Model Description**\n",
        "***\n",
        "This model is based on the **VGG16 architecture**, pre-trained on ImageNet, with modifications for binary classification.\n",
        "\n",
        "### **Dataset Details**\n",
        "- **Source:** BreaKHis dataset (40X, 100X, 200X, 400X magnification)\n",
        "- **Classes:** Benign (0) and Malignant (1)\n",
        "- **Split Ratio:**\n",
        "  - **Training:** 60%\n",
        "  - **Validation:** 10%\n",
        "  - **Testing:** 30%\n",
        "\n",
        "### **Model Architecture**\n",
        "1. **Base Model:** VGG16 (pre-trained on ImageNet, with `include_top=False`)\n",
        "2. **Frozen Layers:** All pre-trained layers are frozen to retain learned features.\n",
        "3. **Custom Classifier:**\n",
        "   - **Flatten Layer:** Converts feature maps to a 1D vector.\n",
        "   - **Single Dense Layer (1 neuron, sigmoid activation):** Predicts the probability of malignancy.\n",
        "\n",
        "### **Training Details**\n",
        "- **Batch Size:** 16\n",
        "- **Optimizer:** Adam\n",
        "- **Loss Function:** Binary Cross-Entropy\n",
        "- **Evaluation Metrics:** Accuracy, F1-Score, Geometric Mean Score (G-Mean), Informedness (IBA)\n",
        "- **Epochs:** 10\n",
        "\n",
        "### **Performance Evaluation**\n",
        "- Model is trained on the training set and validated on the validation set.\n",
        "- After training, the model is tested on the test set.\n",
        "- Performance is measured using **accuracy, F1-score, G-Mean, and IBA**.\n",
        "\n",
        "This model is designed for binary classification of histology slide images, leveraging the robust feature extraction capabilities of VGG16 with a minimal classification head to reduce overfitting.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MmSq1iSg7I4"
      },
      "source": [
        "***\n",
        "**Magnification Factor: 40X**\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIibHNa-e9fQ",
        "outputId": "dabeae88-2213-4cc4-8235-6cd2ec40e878"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Benign Images: 626\n",
            "Total Malignant Images: 1370\n",
            "Training samples: 1197\n",
            "Validation samples: 200\n",
            "Testing samples: 599\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 7s/step - accuracy: 0.5759 - loss: 0.7906 - val_accuracy: 0.6850 - val_loss: 0.5747\n",
            "Epoch 2/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 888ms/step - accuracy: 0.7561 - loss: 0.5309 - val_accuracy: 0.7450 - val_loss: 0.4707\n",
            "Epoch 3/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 917ms/step - accuracy: 0.8033 - loss: 0.4386 - val_accuracy: 0.8300 - val_loss: 0.4279\n",
            "Epoch 4/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 892ms/step - accuracy: 0.8550 - loss: 0.3874 - val_accuracy: 0.8450 - val_loss: 0.4128\n",
            "Epoch 5/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 917ms/step - accuracy: 0.8910 - loss: 0.3500 - val_accuracy: 0.8550 - val_loss: 0.3946\n",
            "Epoch 6/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 892ms/step - accuracy: 0.9058 - loss: 0.3089 - val_accuracy: 0.8350 - val_loss: 0.3841\n",
            "Epoch 7/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - accuracy: 0.9080 - loss: 0.2709 - val_accuracy: 0.8600 - val_loss: 0.3759\n",
            "Epoch 8/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 843ms/step - accuracy: 0.9259 - loss: 0.2737 - val_accuracy: 0.8550 - val_loss: 0.3673\n",
            "Epoch 9/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 809ms/step - accuracy: 0.9340 - loss: 0.2526 - val_accuracy: 0.8500 - val_loss: 0.3578\n",
            "Epoch 10/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 840ms/step - accuracy: 0.9366 - loss: 0.2276 - val_accuracy: 0.8550 - val_loss: 0.3482\n",
            "Epoch 11/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.9315 - loss: 0.2116 - val_accuracy: 0.8650 - val_loss: 0.3448\n",
            "Epoch 12/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 834ms/step - accuracy: 0.9431 - loss: 0.2098 - val_accuracy: 0.8500 - val_loss: 0.3450\n",
            "Epoch 13/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 866ms/step - accuracy: 0.9582 - loss: 0.1888 - val_accuracy: 0.8750 - val_loss: 0.3293\n",
            "Epoch 14/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 801ms/step - accuracy: 0.9555 - loss: 0.1815 - val_accuracy: 0.8900 - val_loss: 0.3279\n",
            "Epoch 15/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 809ms/step - accuracy: 0.9594 - loss: 0.1781 - val_accuracy: 0.8800 - val_loss: 0.3290\n",
            "Epoch 16/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 838ms/step - accuracy: 0.9568 - loss: 0.1702 - val_accuracy: 0.8900 - val_loss: 0.3226\n",
            "Epoch 17/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 842ms/step - accuracy: 0.9747 - loss: 0.1541 - val_accuracy: 0.8650 - val_loss: 0.3291\n",
            "Epoch 18/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 844ms/step - accuracy: 0.9726 - loss: 0.1405 - val_accuracy: 0.8900 - val_loss: 0.3160\n",
            "Epoch 19/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 848ms/step - accuracy: 0.9758 - loss: 0.1321 - val_accuracy: 0.8800 - val_loss: 0.3149\n",
            "Epoch 20/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 829ms/step - accuracy: 0.9799 - loss: 0.1281 - val_accuracy: 0.8850 - val_loss: 0.3175\n",
            "Epoch 21/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - accuracy: 0.9791 - loss: 0.1262 - val_accuracy: 0.8650 - val_loss: 0.3175\n",
            "Epoch 22/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 793ms/step - accuracy: 0.9795 - loss: 0.1208 - val_accuracy: 0.8750 - val_loss: 0.3195\n",
            "Epoch 23/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 844ms/step - accuracy: 0.9836 - loss: 0.1220 - val_accuracy: 0.8650 - val_loss: 0.3086\n",
            "Epoch 24/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 812ms/step - accuracy: 0.9839 - loss: 0.1189 - val_accuracy: 0.8900 - val_loss: 0.3099\n",
            "Epoch 25/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 831ms/step - accuracy: 0.9861 - loss: 0.1083 - val_accuracy: 0.8750 - val_loss: 0.3074\n",
            "Epoch 26/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 835ms/step - accuracy: 0.9884 - loss: 0.1000 - val_accuracy: 0.8750 - val_loss: 0.3122\n",
            "Epoch 27/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 839ms/step - accuracy: 0.9913 - loss: 0.1027 - val_accuracy: 0.8650 - val_loss: 0.3064\n",
            "Epoch 28/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 845ms/step - accuracy: 0.9952 - loss: 0.0878 - val_accuracy: 0.8750 - val_loss: 0.3044\n",
            "Epoch 29/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 788ms/step - accuracy: 0.9927 - loss: 0.0917 - val_accuracy: 0.8750 - val_loss: 0.3017\n",
            "Epoch 30/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 798ms/step - accuracy: 0.9889 - loss: 0.0956 - val_accuracy: 0.8850 - val_loss: 0.3035\n",
            "Epoch 31/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 815ms/step - accuracy: 0.9875 - loss: 0.0890 - val_accuracy: 0.8750 - val_loss: 0.3310\n",
            "Epoch 32/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 843ms/step - accuracy: 0.9920 - loss: 0.0855 - val_accuracy: 0.8750 - val_loss: 0.3333\n",
            "Epoch 33/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 862ms/step - accuracy: 0.9901 - loss: 0.0748 - val_accuracy: 0.8800 - val_loss: 0.3082\n",
            "Epoch 34/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 882ms/step - accuracy: 0.9872 - loss: 0.0788 - val_accuracy: 0.8800 - val_loss: 0.3054\n",
            "Epoch 35/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 883ms/step - accuracy: 0.9942 - loss: 0.0693 - val_accuracy: 0.8850 - val_loss: 0.3144\n",
            "Epoch 36/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 921ms/step - accuracy: 0.9910 - loss: 0.0755 - val_accuracy: 0.8850 - val_loss: 0.3057\n",
            "Epoch 37/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 858ms/step - accuracy: 0.9955 - loss: 0.0666 - val_accuracy: 0.8800 - val_loss: 0.2977\n",
            "Epoch 38/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.9952 - loss: 0.0677 - val_accuracy: 0.8800 - val_loss: 0.2985\n",
            "Epoch 39/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 838ms/step - accuracy: 0.9941 - loss: 0.0624 - val_accuracy: 0.8900 - val_loss: 0.3029\n",
            "Epoch 40/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 880ms/step - accuracy: 0.9930 - loss: 0.0660 - val_accuracy: 0.8900 - val_loss: 0.3025\n",
            "Epoch 41/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 848ms/step - accuracy: 0.9931 - loss: 0.0615 - val_accuracy: 0.8800 - val_loss: 0.2959\n",
            "Epoch 42/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.9958 - loss: 0.0562 - val_accuracy: 0.8800 - val_loss: 0.2972\n",
            "Epoch 43/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 830ms/step - accuracy: 0.9929 - loss: 0.0591 - val_accuracy: 0.8800 - val_loss: 0.2992\n",
            "Epoch 44/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 804ms/step - accuracy: 0.9960 - loss: 0.0537 - val_accuracy: 0.8850 - val_loss: 0.3005\n",
            "Epoch 45/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 852ms/step - accuracy: 0.9911 - loss: 0.0599 - val_accuracy: 0.8850 - val_loss: 0.3097\n",
            "Epoch 46/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 783ms/step - accuracy: 0.9946 - loss: 0.0595 - val_accuracy: 0.8850 - val_loss: 0.3084\n",
            "Epoch 47/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 832ms/step - accuracy: 0.9951 - loss: 0.0515 - val_accuracy: 0.8850 - val_loss: 0.2984\n",
            "Epoch 48/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 834ms/step - accuracy: 0.9982 - loss: 0.0455 - val_accuracy: 0.8850 - val_loss: 0.2958\n",
            "Epoch 49/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 840ms/step - accuracy: 0.9962 - loss: 0.0496 - val_accuracy: 0.8800 - val_loss: 0.3018\n",
            "Epoch 50/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 791ms/step - accuracy: 0.9976 - loss: 0.0451 - val_accuracy: 0.8850 - val_loss: 0.2994\n",
            "Epoch 51/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 798ms/step - accuracy: 0.9976 - loss: 0.0450 - val_accuracy: 0.8850 - val_loss: 0.3004\n",
            "Epoch 52/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.9956 - loss: 0.0449 - val_accuracy: 0.8800 - val_loss: 0.3028\n",
            "Epoch 53/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 887ms/step - accuracy: 0.9979 - loss: 0.0423 - val_accuracy: 0.8850 - val_loss: 0.2998\n",
            "Epoch 54/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 854ms/step - accuracy: 0.9954 - loss: 0.0427 - val_accuracy: 0.8900 - val_loss: 0.2963\n",
            "Epoch 55/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.9985 - loss: 0.0407 - val_accuracy: 0.8900 - val_loss: 0.2958\n",
            "Epoch 56/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 864ms/step - accuracy: 0.9973 - loss: 0.0403 - val_accuracy: 0.8850 - val_loss: 0.2984\n",
            "Epoch 57/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 838ms/step - accuracy: 0.9986 - loss: 0.0396 - val_accuracy: 0.8900 - val_loss: 0.3056\n",
            "Epoch 58/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 795ms/step - accuracy: 0.9985 - loss: 0.0371 - val_accuracy: 0.8950 - val_loss: 0.2980\n",
            "Epoch 59/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.9981 - loss: 0.0390 - val_accuracy: 0.8850 - val_loss: 0.3010\n",
            "Epoch 60/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 794ms/step - accuracy: 0.9977 - loss: 0.0369 - val_accuracy: 0.8850 - val_loss: 0.3001\n",
            "Epoch 61/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 790ms/step - accuracy: 0.9969 - loss: 0.0354 - val_accuracy: 0.8850 - val_loss: 0.3009\n",
            "Epoch 62/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 795ms/step - accuracy: 0.9986 - loss: 0.0346 - val_accuracy: 0.8950 - val_loss: 0.3079\n",
            "Epoch 63/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - accuracy: 0.9972 - loss: 0.0364 - val_accuracy: 0.8900 - val_loss: 0.2994\n",
            "Epoch 64/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 881ms/step - accuracy: 0.9981 - loss: 0.0315 - val_accuracy: 0.8950 - val_loss: 0.2971\n",
            "Epoch 65/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 852ms/step - accuracy: 0.9991 - loss: 0.0322 - val_accuracy: 0.8900 - val_loss: 0.3085\n",
            "Epoch 66/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - accuracy: 0.9991 - loss: 0.0317 - val_accuracy: 0.8900 - val_loss: 0.2984\n",
            "Epoch 67/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 783ms/step - accuracy: 0.9974 - loss: 0.0347 - val_accuracy: 0.8900 - val_loss: 0.3086\n",
            "Epoch 68/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 839ms/step - accuracy: 0.9975 - loss: 0.0323 - val_accuracy: 0.8850 - val_loss: 0.3012\n",
            "Epoch 69/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 805ms/step - accuracy: 0.9985 - loss: 0.0297 - val_accuracy: 0.8900 - val_loss: 0.3099\n",
            "Epoch 70/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 797ms/step - accuracy: 0.9985 - loss: 0.0306 - val_accuracy: 0.8900 - val_loss: 0.3006\n",
            "Epoch 71/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 779ms/step - accuracy: 0.9986 - loss: 0.0283 - val_accuracy: 0.8950 - val_loss: 0.2981\n",
            "Epoch 72/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 787ms/step - accuracy: 0.9995 - loss: 0.0279 - val_accuracy: 0.8950 - val_loss: 0.2985\n",
            "Epoch 73/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 846ms/step - accuracy: 0.9995 - loss: 0.0282 - val_accuracy: 0.8950 - val_loss: 0.3004\n",
            "Epoch 74/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 843ms/step - accuracy: 0.9995 - loss: 0.0273 - val_accuracy: 0.8950 - val_loss: 0.3070\n",
            "Epoch 75/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 837ms/step - accuracy: 0.9992 - loss: 0.0244 - val_accuracy: 0.9050 - val_loss: 0.2975\n",
            "Epoch 76/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 790ms/step - accuracy: 0.9993 - loss: 0.0255 - val_accuracy: 0.8950 - val_loss: 0.3002\n",
            "Epoch 77/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 798ms/step - accuracy: 0.9998 - loss: 0.0258 - val_accuracy: 0.8950 - val_loss: 0.3066\n",
            "Epoch 78/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 837ms/step - accuracy: 1.0000 - loss: 0.0237 - val_accuracy: 0.8900 - val_loss: 0.3055\n",
            "Epoch 79/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 789ms/step - accuracy: 1.0000 - loss: 0.0232 - val_accuracy: 0.9050 - val_loss: 0.3002\n",
            "Epoch 80/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 787ms/step - accuracy: 1.0000 - loss: 0.0241 - val_accuracy: 0.8950 - val_loss: 0.3024\n",
            "Epoch 81/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 867ms/step - accuracy: 1.0000 - loss: 0.0249 - val_accuracy: 0.8950 - val_loss: 0.3104\n",
            "Epoch 82/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 835ms/step - accuracy: 1.0000 - loss: 0.0237 - val_accuracy: 0.9000 - val_loss: 0.3016\n",
            "Epoch 83/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 831ms/step - accuracy: 1.0000 - loss: 0.0220 - val_accuracy: 0.8900 - val_loss: 0.3060\n",
            "Epoch 84/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0227 - val_accuracy: 0.8950 - val_loss: 0.3053\n",
            "Epoch 85/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 793ms/step - accuracy: 1.0000 - loss: 0.0212 - val_accuracy: 0.9000 - val_loss: 0.3034\n",
            "Epoch 86/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 852ms/step - accuracy: 1.0000 - loss: 0.0220 - val_accuracy: 0.9000 - val_loss: 0.3051\n",
            "Epoch 87/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 839ms/step - accuracy: 1.0000 - loss: 0.0216 - val_accuracy: 0.9000 - val_loss: 0.3042\n",
            "Epoch 88/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 840ms/step - accuracy: 1.0000 - loss: 0.0199 - val_accuracy: 0.9050 - val_loss: 0.3039\n",
            "Epoch 89/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 848ms/step - accuracy: 1.0000 - loss: 0.0189 - val_accuracy: 0.9050 - val_loss: 0.3035\n",
            "Epoch 90/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 846ms/step - accuracy: 1.0000 - loss: 0.0197 - val_accuracy: 0.8950 - val_loss: 0.3096\n",
            "Epoch 91/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 793ms/step - accuracy: 1.0000 - loss: 0.0195 - val_accuracy: 0.8950 - val_loss: 0.3052\n",
            "Epoch 92/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 846ms/step - accuracy: 1.0000 - loss: 0.0185 - val_accuracy: 0.9000 - val_loss: 0.3047\n",
            "Epoch 93/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 841ms/step - accuracy: 1.0000 - loss: 0.0175 - val_accuracy: 0.9000 - val_loss: 0.3096\n",
            "Epoch 94/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 846ms/step - accuracy: 1.0000 - loss: 0.0184 - val_accuracy: 0.9100 - val_loss: 0.3057\n",
            "Epoch 95/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 832ms/step - accuracy: 1.0000 - loss: 0.0185 - val_accuracy: 0.9100 - val_loss: 0.3045\n",
            "Epoch 96/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 864ms/step - accuracy: 1.0000 - loss: 0.0175 - val_accuracy: 0.9050 - val_loss: 0.3067\n",
            "Epoch 97/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 926ms/step - accuracy: 1.0000 - loss: 0.0182 - val_accuracy: 0.9000 - val_loss: 0.3133\n",
            "Epoch 98/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 899ms/step - accuracy: 1.0000 - loss: 0.0178 - val_accuracy: 0.8900 - val_loss: 0.3025\n",
            "Epoch 99/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 896ms/step - accuracy: 1.0000 - loss: 0.0188 - val_accuracy: 0.9000 - val_loss: 0.3189\n",
            "Epoch 100/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 862ms/step - accuracy: 1.0000 - loss: 0.0188 - val_accuracy: 0.9100 - val_loss: 0.3079\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 7s/step\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.8667 - loss: 0.3929\n",
            "Test Accuracy: 0.8681\n",
            "F1 Score: 0.9067\n",
            "G-Mean: 0.8221\n",
            "Informedness (IBA): 0.6577\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Define dataset paths\n",
        "benign_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/benign/40X\"\n",
        "malignant_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/malignant/40X\"\n",
        "\n",
        "# Function to load image paths\n",
        "def load_image_paths(dir_path):\n",
        "    return [os.path.join(dir_path, img) for img in os.listdir(dir_path) if img.endswith('.png')]\n",
        "\n",
        "benign_images = load_image_paths(benign_dir)\n",
        "malignant_images = load_image_paths(malignant_dir)\n",
        "\n",
        "print(f\"Total Benign Images: {len(benign_images)}\")\n",
        "print(f\"Total Malignant Images: {len(malignant_images)}\")\n",
        "\n",
        "# Create labels (0 = Benign, 1 = Malignant)\n",
        "benign_labels = [0] * len(benign_images)\n",
        "malignant_labels = [1] * len(malignant_images)\n",
        "\n",
        "# Combine images and labels\n",
        "all_images = np.array(benign_images + malignant_images)\n",
        "all_labels = np.array(benign_labels + malignant_labels)\n",
        "\n",
        "# Split into training (60%), validation (10%), and testing (30%)\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(\n",
        "    all_images, all_labels, test_size=0.3, stratify=all_labels, random_state=42\n",
        ")\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(\n",
        "    train_images, train_labels, test_size=0.1429, stratify=train_labels, random_state=42  # 10% of total (1/7 of 70%)\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {len(train_images)}\")\n",
        "print(f\"Validation samples: {len(val_images)}\")\n",
        "print(f\"Testing samples: {len(test_images)}\")\n",
        "\n",
        "# Function to preprocess images\n",
        "def process_path(file_path, label):\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_png(img, channels=3)\n",
        "    img = tf.image.resize(img, [224, 224])\n",
        "    img = img / 255.0\n",
        "    return img, label\n",
        "\n",
        "# Create TensorFlow datasets\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "train_dataset = train_dataset.map(process_path).shuffle(1000).batch(BATCH_SIZE)\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
        "val_dataset = val_dataset.map(process_path).batch(BATCH_SIZE)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
        "test_dataset = test_dataset.map(process_path).batch(BATCH_SIZE)\n",
        "\n",
        "# Ensure testing dataset is not empty\n",
        "if sum(1 for _ in test_dataset) == 0:\n",
        "    raise ValueError(\"Testing dataset is empty. Adjust your dataset split.\")\n",
        "\n",
        "# Load VGG16 without the top classification layer\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the pre-trained layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add modified classifier (Single Dense Layer)\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(1, activation='sigmoid')(x)  # Single Dense Layer for Binary Classification\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "EPOCHS = 100\n",
        "history = model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS)\n",
        "\n",
        "# Evaluate model\n",
        "test_preds = model.predict(test_dataset)\n",
        "test_preds = (test_preds > 0.5).astype(int).flatten()\n",
        "\n",
        "# Get confusion matrix values\n",
        "tn, fp, fn, tp = confusion_matrix(test_labels, test_preds).ravel()\n",
        "\n",
        "# Calculate IBA\n",
        "iba = (tp / (tp + fn)) + (tn / (tn + fp)) - 1\n",
        "\n",
        "# Output results\n",
        "f1 = f1_score(test_labels, test_preds)\n",
        "gmean = geometric_mean_score(test_labels, test_preds)\n",
        "\n",
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"G-Mean: {gmean:.4f}\")\n",
        "print(f\"Informedness (IBA): {iba:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NzC-Y7pg9Jr"
      },
      "source": [
        "***\n",
        "**Magnification Factor: 100X**\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sk3DsSyqgRsO",
        "outputId": "c4e170de-bf3a-4d51-cb89-c520b4e7285f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Benign Images: 649\n",
            "Total Malignant Images: 1437\n",
            "Training samples: 1251\n",
            "Validation samples: 209\n",
            "Testing samples: 626\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 12s/step - accuracy: 0.6086 - loss: 0.7533 - val_accuracy: 0.8278 - val_loss: 0.5096\n",
            "Epoch 2/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - accuracy: 0.7409 - loss: 0.5188 - val_accuracy: 0.7943 - val_loss: 0.4395\n",
            "Epoch 3/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 853ms/step - accuracy: 0.7973 - loss: 0.4261 - val_accuracy: 0.8469 - val_loss: 0.4002\n",
            "Epoch 4/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 845ms/step - accuracy: 0.8898 - loss: 0.3502 - val_accuracy: 0.8517 - val_loss: 0.3765\n",
            "Epoch 5/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 884ms/step - accuracy: 0.8976 - loss: 0.3182 - val_accuracy: 0.8469 - val_loss: 0.3601\n",
            "Epoch 6/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 882ms/step - accuracy: 0.9092 - loss: 0.2800 - val_accuracy: 0.8373 - val_loss: 0.3546\n",
            "Epoch 7/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 883ms/step - accuracy: 0.9130 - loss: 0.2685 - val_accuracy: 0.8421 - val_loss: 0.3513\n",
            "Epoch 8/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 850ms/step - accuracy: 0.9262 - loss: 0.2445 - val_accuracy: 0.8373 - val_loss: 0.3464\n",
            "Epoch 9/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 894ms/step - accuracy: 0.9384 - loss: 0.2261 - val_accuracy: 0.8421 - val_loss: 0.3362\n",
            "Epoch 10/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 848ms/step - accuracy: 0.9415 - loss: 0.2059 - val_accuracy: 0.8660 - val_loss: 0.3271\n",
            "Epoch 11/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 889ms/step - accuracy: 0.9580 - loss: 0.1844 - val_accuracy: 0.8565 - val_loss: 0.3269\n",
            "Epoch 12/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 852ms/step - accuracy: 0.9729 - loss: 0.1707 - val_accuracy: 0.8660 - val_loss: 0.3216\n",
            "Epoch 13/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 868ms/step - accuracy: 0.9721 - loss: 0.1532 - val_accuracy: 0.8612 - val_loss: 0.3204\n",
            "Epoch 14/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 881ms/step - accuracy: 0.9732 - loss: 0.1540 - val_accuracy: 0.8517 - val_loss: 0.3149\n",
            "Epoch 15/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 857ms/step - accuracy: 0.9810 - loss: 0.1323 - val_accuracy: 0.8565 - val_loss: 0.3183\n",
            "Epoch 16/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 851ms/step - accuracy: 0.9751 - loss: 0.1320 - val_accuracy: 0.8708 - val_loss: 0.3205\n",
            "Epoch 17/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 886ms/step - accuracy: 0.9769 - loss: 0.1286 - val_accuracy: 0.8565 - val_loss: 0.3123\n",
            "Epoch 18/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 858ms/step - accuracy: 0.9832 - loss: 0.1194 - val_accuracy: 0.8565 - val_loss: 0.3130\n",
            "Epoch 19/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 898ms/step - accuracy: 0.9860 - loss: 0.1091 - val_accuracy: 0.8612 - val_loss: 0.3266\n",
            "Epoch 20/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 889ms/step - accuracy: 0.9853 - loss: 0.1116 - val_accuracy: 0.8612 - val_loss: 0.3156\n",
            "Epoch 21/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 897ms/step - accuracy: 0.9895 - loss: 0.1030 - val_accuracy: 0.8612 - val_loss: 0.3131\n",
            "Epoch 22/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 897ms/step - accuracy: 0.9854 - loss: 0.1037 - val_accuracy: 0.8612 - val_loss: 0.3226\n",
            "Epoch 23/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 957ms/step - accuracy: 0.9839 - loss: 0.0981 - val_accuracy: 0.8612 - val_loss: 0.3167\n",
            "Epoch 24/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 924ms/step - accuracy: 0.9918 - loss: 0.0878 - val_accuracy: 0.8612 - val_loss: 0.3122\n",
            "Epoch 25/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 908ms/step - accuracy: 0.9962 - loss: 0.0811 - val_accuracy: 0.8517 - val_loss: 0.3110\n",
            "Epoch 26/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 952ms/step - accuracy: 0.9945 - loss: 0.0822 - val_accuracy: 0.8565 - val_loss: 0.3082\n",
            "Epoch 27/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 949ms/step - accuracy: 0.9941 - loss: 0.0795 - val_accuracy: 0.8612 - val_loss: 0.3117\n",
            "Epoch 28/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 952ms/step - accuracy: 0.9969 - loss: 0.0698 - val_accuracy: 0.8708 - val_loss: 0.3113\n",
            "Epoch 29/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 906ms/step - accuracy: 0.9940 - loss: 0.0714 - val_accuracy: 0.8612 - val_loss: 0.3118\n",
            "Epoch 30/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 900ms/step - accuracy: 0.9957 - loss: 0.0686 - val_accuracy: 0.8612 - val_loss: 0.3122\n",
            "Epoch 31/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 935ms/step - accuracy: 0.9983 - loss: 0.0638 - val_accuracy: 0.8565 - val_loss: 0.3124\n",
            "Epoch 32/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 915ms/step - accuracy: 0.9984 - loss: 0.0580 - val_accuracy: 0.8708 - val_loss: 0.3151\n",
            "Epoch 33/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 940ms/step - accuracy: 0.9945 - loss: 0.0593 - val_accuracy: 0.8565 - val_loss: 0.3144\n",
            "Epoch 34/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 901ms/step - accuracy: 0.9979 - loss: 0.0573 - val_accuracy: 0.8612 - val_loss: 0.3139\n",
            "Epoch 35/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 873ms/step - accuracy: 0.9984 - loss: 0.0565 - val_accuracy: 0.8612 - val_loss: 0.3204\n",
            "Epoch 36/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 898ms/step - accuracy: 0.9939 - loss: 0.0573 - val_accuracy: 0.8708 - val_loss: 0.3159\n",
            "Epoch 37/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 854ms/step - accuracy: 0.9970 - loss: 0.0514 - val_accuracy: 0.8612 - val_loss: 0.3170\n",
            "Epoch 38/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 899ms/step - accuracy: 0.9972 - loss: 0.0497 - val_accuracy: 0.8660 - val_loss: 0.3183\n",
            "Epoch 39/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 911ms/step - accuracy: 0.9991 - loss: 0.0480 - val_accuracy: 0.8612 - val_loss: 0.3191\n",
            "Epoch 40/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 869ms/step - accuracy: 0.9976 - loss: 0.0495 - val_accuracy: 0.8612 - val_loss: 0.3181\n",
            "Epoch 41/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 858ms/step - accuracy: 0.9984 - loss: 0.0442 - val_accuracy: 0.8660 - val_loss: 0.3257\n",
            "Epoch 42/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 867ms/step - accuracy: 0.9983 - loss: 0.0429 - val_accuracy: 0.8612 - val_loss: 0.3200\n",
            "Epoch 43/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 859ms/step - accuracy: 0.9983 - loss: 0.0405 - val_accuracy: 0.8612 - val_loss: 0.3195\n",
            "Epoch 44/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 866ms/step - accuracy: 0.9991 - loss: 0.0419 - val_accuracy: 0.8612 - val_loss: 0.3214\n",
            "Epoch 45/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 896ms/step - accuracy: 0.9995 - loss: 0.0371 - val_accuracy: 0.8565 - val_loss: 0.3236\n",
            "Epoch 46/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 869ms/step - accuracy: 0.9989 - loss: 0.0399 - val_accuracy: 0.8612 - val_loss: 0.3226\n",
            "Epoch 47/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 858ms/step - accuracy: 0.9997 - loss: 0.0400 - val_accuracy: 0.8517 - val_loss: 0.3376\n",
            "Epoch 48/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 928ms/step - accuracy: 0.9978 - loss: 0.0365 - val_accuracy: 0.8612 - val_loss: 0.3241\n",
            "Epoch 49/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 902ms/step - accuracy: 0.9986 - loss: 0.0352 - val_accuracy: 0.8565 - val_loss: 0.3259\n",
            "Epoch 50/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 953ms/step - accuracy: 0.9996 - loss: 0.0327 - val_accuracy: 0.8612 - val_loss: 0.3261\n",
            "Epoch 51/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - accuracy: 0.9998 - loss: 0.0334 - val_accuracy: 0.8612 - val_loss: 0.3256\n",
            "Epoch 52/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 931ms/step - accuracy: 0.9978 - loss: 0.0322 - val_accuracy: 0.8612 - val_loss: 0.3274\n",
            "Epoch 53/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 911ms/step - accuracy: 0.9991 - loss: 0.0335 - val_accuracy: 0.8660 - val_loss: 0.3325\n",
            "Epoch 54/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 895ms/step - accuracy: 0.9995 - loss: 0.0312 - val_accuracy: 0.8612 - val_loss: 0.3292\n",
            "Epoch 55/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 857ms/step - accuracy: 0.9999 - loss: 0.0287 - val_accuracy: 0.8612 - val_loss: 0.3302\n",
            "Epoch 56/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 861ms/step - accuracy: 0.9995 - loss: 0.0274 - val_accuracy: 0.8612 - val_loss: 0.3309\n",
            "Epoch 57/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 866ms/step - accuracy: 0.9997 - loss: 0.0271 - val_accuracy: 0.8612 - val_loss: 0.3317\n",
            "Epoch 58/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 866ms/step - accuracy: 0.9986 - loss: 0.0270 - val_accuracy: 0.8612 - val_loss: 0.3340\n",
            "Epoch 59/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 893ms/step - accuracy: 0.9993 - loss: 0.0251 - val_accuracy: 0.8660 - val_loss: 0.3334\n",
            "Epoch 60/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 886ms/step - accuracy: 0.9991 - loss: 0.0251 - val_accuracy: 0.8612 - val_loss: 0.3377\n",
            "Epoch 61/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 909ms/step - accuracy: 0.9986 - loss: 0.0256 - val_accuracy: 0.8708 - val_loss: 0.3404\n",
            "Epoch 62/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 882ms/step - accuracy: 0.9986 - loss: 0.0260 - val_accuracy: 0.8612 - val_loss: 0.3376\n",
            "Epoch 63/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 999ms/step - accuracy: 0.9989 - loss: 0.0245 - val_accuracy: 0.8660 - val_loss: 0.3367\n",
            "Epoch 64/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 890ms/step - accuracy: 1.0000 - loss: 0.0247 - val_accuracy: 0.8612 - val_loss: 0.3371\n",
            "Epoch 65/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 924ms/step - accuracy: 1.0000 - loss: 0.0230 - val_accuracy: 0.8612 - val_loss: 0.3382\n",
            "Epoch 66/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 890ms/step - accuracy: 1.0000 - loss: 0.0221 - val_accuracy: 0.8612 - val_loss: 0.3387\n",
            "Epoch 67/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 883ms/step - accuracy: 1.0000 - loss: 0.0225 - val_accuracy: 0.8612 - val_loss: 0.3396\n",
            "Epoch 68/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0214 - val_accuracy: 0.8612 - val_loss: 0.3420\n",
            "Epoch 69/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 861ms/step - accuracy: 1.0000 - loss: 0.0204 - val_accuracy: 0.8612 - val_loss: 0.3404\n",
            "Epoch 70/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 891ms/step - accuracy: 1.0000 - loss: 0.0211 - val_accuracy: 0.8612 - val_loss: 0.3410\n",
            "Epoch 71/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 908ms/step - accuracy: 1.0000 - loss: 0.0200 - val_accuracy: 0.8612 - val_loss: 0.3439\n",
            "Epoch 72/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 883ms/step - accuracy: 1.0000 - loss: 0.0191 - val_accuracy: 0.8612 - val_loss: 0.3421\n",
            "Epoch 73/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 909ms/step - accuracy: 1.0000 - loss: 0.0184 - val_accuracy: 0.8612 - val_loss: 0.3432\n",
            "Epoch 74/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0185 - val_accuracy: 0.8612 - val_loss: 0.3454\n",
            "Epoch 75/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 887ms/step - accuracy: 1.0000 - loss: 0.0176 - val_accuracy: 0.8660 - val_loss: 0.3445\n",
            "Epoch 76/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 890ms/step - accuracy: 1.0000 - loss: 0.0185 - val_accuracy: 0.8660 - val_loss: 0.3457\n",
            "Epoch 77/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 890ms/step - accuracy: 1.0000 - loss: 0.0172 - val_accuracy: 0.8612 - val_loss: 0.3476\n",
            "Epoch 78/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 856ms/step - accuracy: 1.0000 - loss: 0.0167 - val_accuracy: 0.8660 - val_loss: 0.3462\n",
            "Epoch 79/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 954ms/step - accuracy: 1.0000 - loss: 0.0167 - val_accuracy: 0.8612 - val_loss: 0.3479\n",
            "Epoch 80/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 883ms/step - accuracy: 1.0000 - loss: 0.0162 - val_accuracy: 0.8660 - val_loss: 0.3483\n",
            "Epoch 81/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 885ms/step - accuracy: 1.0000 - loss: 0.0165 - val_accuracy: 0.8612 - val_loss: 0.3523\n",
            "Epoch 82/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 858ms/step - accuracy: 1.0000 - loss: 0.0167 - val_accuracy: 0.8660 - val_loss: 0.3499\n",
            "Epoch 83/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 849ms/step - accuracy: 1.0000 - loss: 0.0157 - val_accuracy: 0.8660 - val_loss: 0.3512\n",
            "Epoch 84/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0143 - val_accuracy: 0.8612 - val_loss: 0.3541\n",
            "Epoch 85/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 853ms/step - accuracy: 1.0000 - loss: 0.0149 - val_accuracy: 0.8660 - val_loss: 0.3521\n",
            "Epoch 86/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 944ms/step - accuracy: 1.0000 - loss: 0.0153 - val_accuracy: 0.8612 - val_loss: 0.3538\n",
            "Epoch 87/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 890ms/step - accuracy: 1.0000 - loss: 0.0142 - val_accuracy: 0.8612 - val_loss: 0.3540\n",
            "Epoch 88/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 917ms/step - accuracy: 1.0000 - loss: 0.0142 - val_accuracy: 0.8612 - val_loss: 0.3547\n",
            "Epoch 89/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 989ms/step - accuracy: 1.0000 - loss: 0.0133 - val_accuracy: 0.8660 - val_loss: 0.3548\n",
            "Epoch 90/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 902ms/step - accuracy: 1.0000 - loss: 0.0137 - val_accuracy: 0.8612 - val_loss: 0.3561\n",
            "Epoch 91/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 900ms/step - accuracy: 1.0000 - loss: 0.0141 - val_accuracy: 0.8612 - val_loss: 0.3594\n",
            "Epoch 92/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 925ms/step - accuracy: 1.0000 - loss: 0.0124 - val_accuracy: 0.8660 - val_loss: 0.3572\n",
            "Epoch 93/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 896ms/step - accuracy: 1.0000 - loss: 0.0129 - val_accuracy: 0.8612 - val_loss: 0.3608\n",
            "Epoch 94/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 884ms/step - accuracy: 1.0000 - loss: 0.0131 - val_accuracy: 0.8612 - val_loss: 0.3594\n",
            "Epoch 95/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 891ms/step - accuracy: 1.0000 - loss: 0.0120 - val_accuracy: 0.8660 - val_loss: 0.3590\n",
            "Epoch 96/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 870ms/step - accuracy: 1.0000 - loss: 0.0127 - val_accuracy: 0.8612 - val_loss: 0.3614\n",
            "Epoch 97/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 976ms/step - accuracy: 1.0000 - loss: 0.0113 - val_accuracy: 0.8660 - val_loss: 0.3599\n",
            "Epoch 98/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 927ms/step - accuracy: 1.0000 - loss: 0.0118 - val_accuracy: 0.8612 - val_loss: 0.3626\n",
            "Epoch 99/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 956ms/step - accuracy: 1.0000 - loss: 0.0121 - val_accuracy: 0.8660 - val_loss: 0.3617\n",
            "Epoch 100/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0116 - val_accuracy: 0.8660 - val_loss: 0.3618\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 8s/step\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8705 - loss: 0.3404\n",
            "Test Accuracy: 0.8626\n",
            "F1 Score: 0.9029\n",
            "G-Mean: 0.8163\n",
            "Informedness (IBA): 0.6460\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Define dataset paths\n",
        "benign_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/benign/100X\"\n",
        "malignant_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/malignant/100X\"\n",
        "\n",
        "# Function to load image paths\n",
        "def load_image_paths(dir_path):\n",
        "    return [os.path.join(dir_path, img) for img in os.listdir(dir_path) if img.endswith('.png')]\n",
        "\n",
        "benign_images = load_image_paths(benign_dir)\n",
        "malignant_images = load_image_paths(malignant_dir)\n",
        "\n",
        "print(f\"Total Benign Images: {len(benign_images)}\")\n",
        "print(f\"Total Malignant Images: {len(malignant_images)}\")\n",
        "\n",
        "# Create labels (0 = Benign, 1 = Malignant)\n",
        "benign_labels = [0] * len(benign_images)\n",
        "malignant_labels = [1] * len(malignant_images)\n",
        "\n",
        "# Combine images and labels\n",
        "all_images = np.array(benign_images + malignant_images)\n",
        "all_labels = np.array(benign_labels + malignant_labels)\n",
        "\n",
        "# Split into training (60%), validation (10%), and testing (30%)\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(\n",
        "    all_images, all_labels, test_size=0.3, stratify=all_labels, random_state=42\n",
        ")\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(\n",
        "    train_images, train_labels, test_size=0.1429, stratify=train_labels, random_state=42  # 10% of total (1/7 of 70%)\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {len(train_images)}\")\n",
        "print(f\"Validation samples: {len(val_images)}\")\n",
        "print(f\"Testing samples: {len(test_images)}\")\n",
        "\n",
        "# Function to preprocess images\n",
        "def process_path(file_path, label):\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_png(img, channels=3)\n",
        "    img = tf.image.resize(img, [224, 224])\n",
        "    img = img / 255.0\n",
        "    return img, label\n",
        "\n",
        "# Create TensorFlow datasets\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "train_dataset = train_dataset.map(process_path).shuffle(1000).batch(BATCH_SIZE)\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
        "val_dataset = val_dataset.map(process_path).batch(BATCH_SIZE)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
        "test_dataset = test_dataset.map(process_path).batch(BATCH_SIZE)\n",
        "\n",
        "# Ensure testing dataset is not empty\n",
        "if sum(1 for _ in test_dataset) == 0:\n",
        "    raise ValueError(\"Testing dataset is empty. Adjust your dataset split.\")\n",
        "\n",
        "# Load VGG16 without the top classification layer\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the pre-trained layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add modified classifier (Single Dense Layer)\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(1, activation='sigmoid')(x)  # Single Dense Layer for Binary Classification\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "EPOCHS = 100\n",
        "history = model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS)\n",
        "\n",
        "# Evaluate model\n",
        "test_preds = model.predict(test_dataset)\n",
        "test_preds = (test_preds > 0.5).astype(int).flatten()\n",
        "\n",
        "# Get confusion matrix values\n",
        "tn, fp, fn, tp = confusion_matrix(test_labels, test_preds).ravel()\n",
        "\n",
        "# Calculate IBA\n",
        "iba = (tp / (tp + fn)) + (tn / (tn + fp)) - 1\n",
        "\n",
        "# Output results\n",
        "f1 = f1_score(test_labels, test_preds)\n",
        "gmean = geometric_mean_score(test_labels, test_preds)\n",
        "\n",
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"G-Mean: {gmean:.4f}\")\n",
        "print(f\"Informedness (IBA): {iba:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIpITUH7g_1W"
      },
      "source": [
        "***\n",
        "**Magnification Factor: 200X**\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N38TnVXqgSzP",
        "outputId": "9557034b-a15f-4bdb-da1e-faebe6659a38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Benign Images: 623\n",
            "Total Malignant Images: 1390\n",
            "Training samples: 1207\n",
            "Validation samples: 202\n",
            "Testing samples: 604\n",
            "Epoch 1/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 9s/step - accuracy: 0.5819 - loss: 0.7912 - val_accuracy: 0.7030 - val_loss: 0.5336\n",
            "Epoch 2/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 800ms/step - accuracy: 0.7078 - loss: 0.5467 - val_accuracy: 0.7921 - val_loss: 0.4613\n",
            "Epoch 3/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 802ms/step - accuracy: 0.8377 - loss: 0.4115 - val_accuracy: 0.7822 - val_loss: 0.4346\n",
            "Epoch 4/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 812ms/step - accuracy: 0.8605 - loss: 0.3461 - val_accuracy: 0.7970 - val_loss: 0.4111\n",
            "Epoch 5/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 819ms/step - accuracy: 0.8862 - loss: 0.3142 - val_accuracy: 0.8366 - val_loss: 0.3952\n",
            "Epoch 6/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 820ms/step - accuracy: 0.9023 - loss: 0.2840 - val_accuracy: 0.8465 - val_loss: 0.3837\n",
            "Epoch 7/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 880ms/step - accuracy: 0.9178 - loss: 0.2639 - val_accuracy: 0.8267 - val_loss: 0.3815\n",
            "Epoch 8/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 906ms/step - accuracy: 0.9031 - loss: 0.2500 - val_accuracy: 0.8267 - val_loss: 0.3759\n",
            "Epoch 9/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 889ms/step - accuracy: 0.9345 - loss: 0.2164 - val_accuracy: 0.8366 - val_loss: 0.3680\n",
            "Epoch 10/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - accuracy: 0.9339 - loss: 0.2108 - val_accuracy: 0.8168 - val_loss: 0.3815\n",
            "Epoch 11/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 817ms/step - accuracy: 0.9487 - loss: 0.1955 - val_accuracy: 0.8366 - val_loss: 0.3586\n",
            "Epoch 12/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 818ms/step - accuracy: 0.9550 - loss: 0.1852 - val_accuracy: 0.8317 - val_loss: 0.3626\n",
            "Epoch 13/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 823ms/step - accuracy: 0.9645 - loss: 0.1683 - val_accuracy: 0.8317 - val_loss: 0.3746\n",
            "Epoch 14/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 819ms/step - accuracy: 0.9651 - loss: 0.1555 - val_accuracy: 0.8465 - val_loss: 0.3453\n",
            "Epoch 15/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 842ms/step - accuracy: 0.9738 - loss: 0.1472 - val_accuracy: 0.8317 - val_loss: 0.3569\n",
            "Epoch 16/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 816ms/step - accuracy: 0.9753 - loss: 0.1412 - val_accuracy: 0.8465 - val_loss: 0.3447\n",
            "Epoch 17/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 823ms/step - accuracy: 0.9766 - loss: 0.1348 - val_accuracy: 0.8465 - val_loss: 0.3440\n",
            "Epoch 18/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 820ms/step - accuracy: 0.9857 - loss: 0.1204 - val_accuracy: 0.8515 - val_loss: 0.3374\n",
            "Epoch 19/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 813ms/step - accuracy: 0.9808 - loss: 0.1209 - val_accuracy: 0.8713 - val_loss: 0.3306\n",
            "Epoch 20/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 919ms/step - accuracy: 0.9836 - loss: 0.1144 - val_accuracy: 0.8465 - val_loss: 0.3367\n",
            "Epoch 21/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 825ms/step - accuracy: 0.9842 - loss: 0.1092 - val_accuracy: 0.8515 - val_loss: 0.3299\n",
            "Epoch 22/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - accuracy: 0.9880 - loss: 0.1000 - val_accuracy: 0.8515 - val_loss: 0.3305\n",
            "Epoch 23/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 825ms/step - accuracy: 0.9909 - loss: 0.0957 - val_accuracy: 0.8515 - val_loss: 0.3293\n",
            "Epoch 24/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 769ms/step - accuracy: 0.9846 - loss: 0.1025 - val_accuracy: 0.8416 - val_loss: 0.3373\n",
            "Epoch 25/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 778ms/step - accuracy: 0.9932 - loss: 0.0924 - val_accuracy: 0.8564 - val_loss: 0.3320\n",
            "Epoch 26/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 773ms/step - accuracy: 0.9934 - loss: 0.0850 - val_accuracy: 0.8515 - val_loss: 0.3361\n",
            "Epoch 27/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 823ms/step - accuracy: 0.9950 - loss: 0.0853 - val_accuracy: 0.8564 - val_loss: 0.3351\n",
            "Epoch 28/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 777ms/step - accuracy: 0.9942 - loss: 0.0811 - val_accuracy: 0.8515 - val_loss: 0.3419\n",
            "Epoch 29/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 835ms/step - accuracy: 0.9984 - loss: 0.0721 - val_accuracy: 0.8515 - val_loss: 0.3428\n",
            "Epoch 30/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 821ms/step - accuracy: 0.9954 - loss: 0.0724 - val_accuracy: 0.8564 - val_loss: 0.3344\n",
            "Epoch 31/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 771ms/step - accuracy: 0.9976 - loss: 0.0674 - val_accuracy: 0.8564 - val_loss: 0.3311\n",
            "Epoch 32/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 777ms/step - accuracy: 0.9981 - loss: 0.0677 - val_accuracy: 0.8564 - val_loss: 0.3380\n",
            "Epoch 33/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 825ms/step - accuracy: 0.9995 - loss: 0.0593 - val_accuracy: 0.8564 - val_loss: 0.3323\n",
            "Epoch 34/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 819ms/step - accuracy: 0.9992 - loss: 0.0573 - val_accuracy: 0.8614 - val_loss: 0.3356\n",
            "Epoch 35/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 822ms/step - accuracy: 0.9993 - loss: 0.0544 - val_accuracy: 0.8515 - val_loss: 0.3333\n",
            "Epoch 36/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 885ms/step - accuracy: 0.9988 - loss: 0.0541 - val_accuracy: 0.8515 - val_loss: 0.3299\n",
            "Epoch 37/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 829ms/step - accuracy: 0.9997 - loss: 0.0534 - val_accuracy: 0.8564 - val_loss: 0.3366\n",
            "Epoch 38/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 780ms/step - accuracy: 0.9986 - loss: 0.0509 - val_accuracy: 0.8465 - val_loss: 0.3314\n",
            "Epoch 39/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 765ms/step - accuracy: 1.0000 - loss: 0.0509 - val_accuracy: 0.8564 - val_loss: 0.3398\n",
            "Epoch 40/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 804ms/step - accuracy: 1.0000 - loss: 0.0489 - val_accuracy: 0.8515 - val_loss: 0.3470\n",
            "Epoch 41/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 905ms/step - accuracy: 1.0000 - loss: 0.0478 - val_accuracy: 0.8564 - val_loss: 0.3456\n",
            "Epoch 42/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 889ms/step - accuracy: 0.9978 - loss: 0.0486 - val_accuracy: 0.8465 - val_loss: 0.3329\n",
            "Epoch 43/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 821ms/step - accuracy: 1.0000 - loss: 0.0448 - val_accuracy: 0.8515 - val_loss: 0.3335\n",
            "Epoch 44/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 892ms/step - accuracy: 1.0000 - loss: 0.0427 - val_accuracy: 0.8515 - val_loss: 0.3386\n",
            "Epoch 45/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0419 - val_accuracy: 0.8564 - val_loss: 0.3413\n",
            "Epoch 46/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 839ms/step - accuracy: 1.0000 - loss: 0.0386 - val_accuracy: 0.8465 - val_loss: 0.3362\n",
            "Epoch 47/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0407 - val_accuracy: 0.8515 - val_loss: 0.3421\n",
            "Epoch 48/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 826ms/step - accuracy: 1.0000 - loss: 0.0384 - val_accuracy: 0.8515 - val_loss: 0.3415\n",
            "Epoch 49/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 874ms/step - accuracy: 1.0000 - loss: 0.0362 - val_accuracy: 0.8465 - val_loss: 0.3388\n",
            "Epoch 50/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 885ms/step - accuracy: 1.0000 - loss: 0.0381 - val_accuracy: 0.8515 - val_loss: 0.3579\n",
            "Epoch 51/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 826ms/step - accuracy: 1.0000 - loss: 0.0352 - val_accuracy: 0.8614 - val_loss: 0.3512\n",
            "Epoch 52/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 834ms/step - accuracy: 1.0000 - loss: 0.0335 - val_accuracy: 0.8515 - val_loss: 0.3444\n",
            "Epoch 53/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 883ms/step - accuracy: 1.0000 - loss: 0.0339 - val_accuracy: 0.8515 - val_loss: 0.3462\n",
            "Epoch 54/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 847ms/step - accuracy: 1.0000 - loss: 0.0330 - val_accuracy: 0.8465 - val_loss: 0.3436\n",
            "Epoch 55/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0293 - val_accuracy: 0.8465 - val_loss: 0.3443\n",
            "Epoch 56/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 783ms/step - accuracy: 1.0000 - loss: 0.0319 - val_accuracy: 0.8515 - val_loss: 0.3481\n",
            "Epoch 57/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0285 - val_accuracy: 0.8515 - val_loss: 0.3519\n",
            "Epoch 58/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 886ms/step - accuracy: 1.0000 - loss: 0.0290 - val_accuracy: 0.8564 - val_loss: 0.3561\n",
            "Epoch 59/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 824ms/step - accuracy: 1.0000 - loss: 0.0272 - val_accuracy: 0.8515 - val_loss: 0.3503\n",
            "Epoch 60/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 816ms/step - accuracy: 1.0000 - loss: 0.0266 - val_accuracy: 0.8515 - val_loss: 0.3510\n",
            "Epoch 61/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 0.0257 - val_accuracy: 0.8465 - val_loss: 0.3507\n",
            "Epoch 62/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 891ms/step - accuracy: 1.0000 - loss: 0.0252 - val_accuracy: 0.8564 - val_loss: 0.3603\n",
            "Epoch 63/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 884ms/step - accuracy: 1.0000 - loss: 0.0238 - val_accuracy: 0.8515 - val_loss: 0.3496\n",
            "Epoch 64/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0240 - val_accuracy: 0.8465 - val_loss: 0.3503\n",
            "Epoch 65/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 879ms/step - accuracy: 1.0000 - loss: 0.0251 - val_accuracy: 0.8515 - val_loss: 0.3648\n",
            "Epoch 66/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0246 - val_accuracy: 0.8515 - val_loss: 0.3589\n",
            "Epoch 67/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 830ms/step - accuracy: 1.0000 - loss: 0.0230 - val_accuracy: 0.8465 - val_loss: 0.3533\n",
            "Epoch 68/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 766ms/step - accuracy: 1.0000 - loss: 0.0234 - val_accuracy: 0.8515 - val_loss: 0.3597\n",
            "Epoch 69/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 777ms/step - accuracy: 1.0000 - loss: 0.0218 - val_accuracy: 0.8515 - val_loss: 0.3578\n",
            "Epoch 70/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 771ms/step - accuracy: 1.0000 - loss: 0.0223 - val_accuracy: 0.8515 - val_loss: 0.3585\n",
            "Epoch 71/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 815ms/step - accuracy: 1.0000 - loss: 0.0201 - val_accuracy: 0.8515 - val_loss: 0.3658\n",
            "Epoch 72/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 898ms/step - accuracy: 1.0000 - loss: 0.0217 - val_accuracy: 0.8465 - val_loss: 0.3583\n",
            "Epoch 73/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 840ms/step - accuracy: 1.0000 - loss: 0.0212 - val_accuracy: 0.8465 - val_loss: 0.3586\n",
            "Epoch 74/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 821ms/step - accuracy: 1.0000 - loss: 0.0200 - val_accuracy: 0.8515 - val_loss: 0.3780\n",
            "Epoch 75/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 829ms/step - accuracy: 1.0000 - loss: 0.0199 - val_accuracy: 0.8465 - val_loss: 0.3615\n",
            "Epoch 76/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 820ms/step - accuracy: 1.0000 - loss: 0.0205 - val_accuracy: 0.8515 - val_loss: 0.3604\n",
            "Epoch 77/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 0.0194 - val_accuracy: 0.8515 - val_loss: 0.3646\n",
            "Epoch 78/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 956ms/step - accuracy: 1.0000 - loss: 0.0196 - val_accuracy: 0.8465 - val_loss: 0.3659\n",
            "Epoch 79/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 804ms/step - accuracy: 1.0000 - loss: 0.0174 - val_accuracy: 0.8564 - val_loss: 0.3616\n",
            "Epoch 80/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 819ms/step - accuracy: 1.0000 - loss: 0.0172 - val_accuracy: 0.8515 - val_loss: 0.3677\n",
            "Epoch 81/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 836ms/step - accuracy: 1.0000 - loss: 0.0179 - val_accuracy: 0.8515 - val_loss: 0.3685\n",
            "Epoch 82/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 824ms/step - accuracy: 1.0000 - loss: 0.0172 - val_accuracy: 0.8465 - val_loss: 0.3657\n",
            "Epoch 83/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 825ms/step - accuracy: 1.0000 - loss: 0.0159 - val_accuracy: 0.8465 - val_loss: 0.3684\n",
            "Epoch 84/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 820ms/step - accuracy: 1.0000 - loss: 0.0159 - val_accuracy: 0.8515 - val_loss: 0.3729\n",
            "Epoch 85/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 829ms/step - accuracy: 1.0000 - loss: 0.0150 - val_accuracy: 0.8515 - val_loss: 0.3668\n",
            "Epoch 86/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 764ms/step - accuracy: 1.0000 - loss: 0.0150 - val_accuracy: 0.8515 - val_loss: 0.3736\n",
            "Epoch 87/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0162 - val_accuracy: 0.8465 - val_loss: 0.3700\n",
            "Epoch 88/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 781ms/step - accuracy: 1.0000 - loss: 0.0148 - val_accuracy: 0.8515 - val_loss: 0.3686\n",
            "Epoch 89/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 904ms/step - accuracy: 1.0000 - loss: 0.0149 - val_accuracy: 0.8465 - val_loss: 0.3732\n",
            "Epoch 90/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 825ms/step - accuracy: 1.0000 - loss: 0.0138 - val_accuracy: 0.8465 - val_loss: 0.3743\n",
            "Epoch 91/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 764ms/step - accuracy: 1.0000 - loss: 0.0142 - val_accuracy: 0.8515 - val_loss: 0.3715\n",
            "Epoch 92/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 829ms/step - accuracy: 1.0000 - loss: 0.0136 - val_accuracy: 0.8465 - val_loss: 0.3758\n",
            "Epoch 93/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 772ms/step - accuracy: 1.0000 - loss: 0.0138 - val_accuracy: 0.8465 - val_loss: 0.3758\n",
            "Epoch 94/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 833ms/step - accuracy: 1.0000 - loss: 0.0127 - val_accuracy: 0.8515 - val_loss: 0.3748\n",
            "Epoch 95/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 817ms/step - accuracy: 1.0000 - loss: 0.0135 - val_accuracy: 0.8515 - val_loss: 0.3788\n",
            "Epoch 96/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 798ms/step - accuracy: 1.0000 - loss: 0.0131 - val_accuracy: 0.8515 - val_loss: 0.3797\n",
            "Epoch 97/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 822ms/step - accuracy: 1.0000 - loss: 0.0125 - val_accuracy: 0.8515 - val_loss: 0.3759\n",
            "Epoch 98/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 777ms/step - accuracy: 1.0000 - loss: 0.0123 - val_accuracy: 0.8465 - val_loss: 0.3780\n",
            "Epoch 99/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 777ms/step - accuracy: 1.0000 - loss: 0.0121 - val_accuracy: 0.8465 - val_loss: 0.3784\n",
            "Epoch 100/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 836ms/step - accuracy: 1.0000 - loss: 0.0130 - val_accuracy: 0.8515 - val_loss: 0.3839\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 7s/step\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8711 - loss: 0.3506\n",
            "Test Accuracy: 0.8742\n",
            "F1 Score: 0.9112\n",
            "G-Mean: 0.8308\n",
            "Informedness (IBA): 0.6732\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Define dataset paths\n",
        "benign_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/benign/200X\"\n",
        "malignant_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/malignant/200X\"\n",
        "\n",
        "# Function to load image paths\n",
        "def load_image_paths(dir_path):\n",
        "    return [os.path.join(dir_path, img) for img in os.listdir(dir_path) if img.endswith('.png')]\n",
        "\n",
        "benign_images = load_image_paths(benign_dir)\n",
        "malignant_images = load_image_paths(malignant_dir)\n",
        "\n",
        "print(f\"Total Benign Images: {len(benign_images)}\")\n",
        "print(f\"Total Malignant Images: {len(malignant_images)}\")\n",
        "\n",
        "# Create labels (0 = Benign, 1 = Malignant)\n",
        "benign_labels = [0] * len(benign_images)\n",
        "malignant_labels = [1] * len(malignant_images)\n",
        "\n",
        "# Combine images and labels\n",
        "all_images = np.array(benign_images + malignant_images)\n",
        "all_labels = np.array(benign_labels + malignant_labels)\n",
        "\n",
        "# Split into training (60%), validation (10%), and testing (30%)\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(\n",
        "    all_images, all_labels, test_size=0.3, stratify=all_labels, random_state=42\n",
        ")\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(\n",
        "    train_images, train_labels, test_size=0.1429, stratify=train_labels, random_state=42  # 10% of total (1/7 of 70%)\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {len(train_images)}\")\n",
        "print(f\"Validation samples: {len(val_images)}\")\n",
        "print(f\"Testing samples: {len(test_images)}\")\n",
        "\n",
        "# Function to preprocess images\n",
        "def process_path(file_path, label):\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_png(img, channels=3)\n",
        "    img = tf.image.resize(img, [224, 224])\n",
        "    img = img / 255.0\n",
        "    return img, label\n",
        "\n",
        "# Create TensorFlow datasets\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "train_dataset = train_dataset.map(process_path).shuffle(1000).batch(BATCH_SIZE)\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
        "val_dataset = val_dataset.map(process_path).batch(BATCH_SIZE)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
        "test_dataset = test_dataset.map(process_path).batch(BATCH_SIZE)\n",
        "\n",
        "# Ensure testing dataset is not empty\n",
        "if sum(1 for _ in test_dataset) == 0:\n",
        "    raise ValueError(\"Testing dataset is empty. Adjust your dataset split.\")\n",
        "\n",
        "# Load VGG16 without the top classification layer\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the pre-trained layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add modified classifier (Single Dense Layer)\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(1, activation='sigmoid')(x)  # Single Dense Layer for Binary Classification\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "EPOCHS = 100\n",
        "history = model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS)\n",
        "\n",
        "# Evaluate model\n",
        "test_preds = model.predict(test_dataset)\n",
        "test_preds = (test_preds > 0.5).astype(int).flatten()\n",
        "\n",
        "# Get confusion matrix values\n",
        "tn, fp, fn, tp = confusion_matrix(test_labels, test_preds).ravel()\n",
        "\n",
        "# Calculate IBA\n",
        "iba = (tp / (tp + fn)) + (tn / (tn + fp)) - 1\n",
        "\n",
        "# Output results\n",
        "f1 = f1_score(test_labels, test_preds)\n",
        "gmean = geometric_mean_score(test_labels, test_preds)\n",
        "\n",
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"G-Mean: {gmean:.4f}\")\n",
        "print(f\"Informedness (IBA): {iba:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Y7OwMLjpXzq"
      },
      "source": [
        "***\n",
        "**Magnification Factor: 400X**\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOBTti1MgTyC",
        "outputId": "90095656-8102-4dc1-8feb-9751b18906be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Benign Images: 588\n",
            "Total Malignant Images: 1232\n",
            "Training samples: 1091\n",
            "Validation samples: 183\n",
            "Testing samples: 546\n",
            "Epoch 1/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 5s/step - accuracy: 0.5554 - loss: 0.8857 - val_accuracy: 0.6776 - val_loss: 0.8053\n",
            "Epoch 2/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 820ms/step - accuracy: 0.7078 - loss: 0.6406 - val_accuracy: 0.6940 - val_loss: 0.5540\n",
            "Epoch 3/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 833ms/step - accuracy: 0.7185 - loss: 0.5486 - val_accuracy: 0.7432 - val_loss: 0.4810\n",
            "Epoch 4/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - accuracy: 0.7642 - loss: 0.4534 - val_accuracy: 0.7923 - val_loss: 0.4372\n",
            "Epoch 5/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 837ms/step - accuracy: 0.8247 - loss: 0.3789 - val_accuracy: 0.8415 - val_loss: 0.4208\n",
            "Epoch 6/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 828ms/step - accuracy: 0.8783 - loss: 0.3330 - val_accuracy: 0.8470 - val_loss: 0.4160\n",
            "Epoch 7/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 757ms/step - accuracy: 0.8961 - loss: 0.3195 - val_accuracy: 0.8579 - val_loss: 0.4025\n",
            "Epoch 8/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 833ms/step - accuracy: 0.9160 - loss: 0.3076 - val_accuracy: 0.8197 - val_loss: 0.3913\n",
            "Epoch 9/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 840ms/step - accuracy: 0.9283 - loss: 0.2766 - val_accuracy: 0.7869 - val_loss: 0.4061\n",
            "Epoch 10/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 763ms/step - accuracy: 0.9194 - loss: 0.2536 - val_accuracy: 0.8470 - val_loss: 0.3763\n",
            "Epoch 11/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 893ms/step - accuracy: 0.9346 - loss: 0.2308 - val_accuracy: 0.8634 - val_loss: 0.3692\n",
            "Epoch 12/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 845ms/step - accuracy: 0.9349 - loss: 0.2234 - val_accuracy: 0.8634 - val_loss: 0.3639\n",
            "Epoch 13/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - accuracy: 0.9484 - loss: 0.2107 - val_accuracy: 0.8634 - val_loss: 0.3607\n",
            "Epoch 14/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 835ms/step - accuracy: 0.9570 - loss: 0.1923 - val_accuracy: 0.8689 - val_loss: 0.3609\n",
            "Epoch 15/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 873ms/step - accuracy: 0.9644 - loss: 0.1819 - val_accuracy: 0.8743 - val_loss: 0.3695\n",
            "Epoch 16/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 793ms/step - accuracy: 0.9783 - loss: 0.1747 - val_accuracy: 0.8579 - val_loss: 0.3522\n",
            "Epoch 17/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 901ms/step - accuracy: 0.9691 - loss: 0.1651 - val_accuracy: 0.8689 - val_loss: 0.3528\n",
            "Epoch 18/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 764ms/step - accuracy: 0.9811 - loss: 0.1526 - val_accuracy: 0.8525 - val_loss: 0.3528\n",
            "Epoch 19/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 756ms/step - accuracy: 0.9775 - loss: 0.1495 - val_accuracy: 0.8579 - val_loss: 0.3500\n",
            "Epoch 20/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 762ms/step - accuracy: 0.9838 - loss: 0.1382 - val_accuracy: 0.8634 - val_loss: 0.3457\n",
            "Epoch 21/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 793ms/step - accuracy: 0.9838 - loss: 0.1339 - val_accuracy: 0.8634 - val_loss: 0.3433\n",
            "Epoch 22/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 848ms/step - accuracy: 0.9857 - loss: 0.1254 - val_accuracy: 0.8415 - val_loss: 0.3547\n",
            "Epoch 23/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 757ms/step - accuracy: 0.9815 - loss: 0.1243 - val_accuracy: 0.8634 - val_loss: 0.3393\n",
            "Epoch 24/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 825ms/step - accuracy: 0.9898 - loss: 0.1179 - val_accuracy: 0.8798 - val_loss: 0.3405\n",
            "Epoch 25/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 841ms/step - accuracy: 0.9913 - loss: 0.1119 - val_accuracy: 0.8634 - val_loss: 0.3376\n",
            "Epoch 26/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 765ms/step - accuracy: 0.9953 - loss: 0.1009 - val_accuracy: 0.8689 - val_loss: 0.3372\n",
            "Epoch 27/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 757ms/step - accuracy: 0.9953 - loss: 0.1000 - val_accuracy: 0.8689 - val_loss: 0.3406\n",
            "Epoch 28/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 874ms/step - accuracy: 0.9935 - loss: 0.0988 - val_accuracy: 0.8579 - val_loss: 0.3465\n",
            "Epoch 29/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 770ms/step - accuracy: 0.9936 - loss: 0.0928 - val_accuracy: 0.8689 - val_loss: 0.3379\n",
            "Epoch 30/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 0.9913 - loss: 0.0937 - val_accuracy: 0.8689 - val_loss: 0.3368\n",
            "Epoch 31/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 841ms/step - accuracy: 0.9921 - loss: 0.0884 - val_accuracy: 0.8743 - val_loss: 0.3395\n",
            "Epoch 32/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 870ms/step - accuracy: 0.9978 - loss: 0.0818 - val_accuracy: 0.8798 - val_loss: 0.3459\n",
            "Epoch 33/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 771ms/step - accuracy: 0.9975 - loss: 0.0801 - val_accuracy: 0.8579 - val_loss: 0.3452\n",
            "Epoch 34/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 840ms/step - accuracy: 1.0000 - loss: 0.0792 - val_accuracy: 0.8743 - val_loss: 0.3429\n",
            "Epoch 35/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 850ms/step - accuracy: 1.0000 - loss: 0.0726 - val_accuracy: 0.8689 - val_loss: 0.3389\n",
            "Epoch 36/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 856ms/step - accuracy: 0.9998 - loss: 0.0700 - val_accuracy: 0.8689 - val_loss: 0.3392\n",
            "Epoch 37/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 850ms/step - accuracy: 1.0000 - loss: 0.0669 - val_accuracy: 0.8689 - val_loss: 0.3400\n",
            "Epoch 38/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 867ms/step - accuracy: 1.0000 - loss: 0.0651 - val_accuracy: 0.8689 - val_loss: 0.3385\n",
            "Epoch 39/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 770ms/step - accuracy: 0.9997 - loss: 0.0616 - val_accuracy: 0.8743 - val_loss: 0.3421\n",
            "Epoch 40/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 845ms/step - accuracy: 1.0000 - loss: 0.0596 - val_accuracy: 0.8743 - val_loss: 0.3432\n",
            "Epoch 41/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 762ms/step - accuracy: 1.0000 - loss: 0.0603 - val_accuracy: 0.8689 - val_loss: 0.3407\n",
            "Epoch 42/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 764ms/step - accuracy: 1.0000 - loss: 0.0580 - val_accuracy: 0.8689 - val_loss: 0.3397\n",
            "Epoch 43/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 855ms/step - accuracy: 1.0000 - loss: 0.0558 - val_accuracy: 0.8798 - val_loss: 0.3398\n",
            "Epoch 44/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 760ms/step - accuracy: 1.0000 - loss: 0.0532 - val_accuracy: 0.8689 - val_loss: 0.3415\n",
            "Epoch 45/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 802ms/step - accuracy: 1.0000 - loss: 0.0522 - val_accuracy: 0.8689 - val_loss: 0.3411\n",
            "Epoch 46/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 828ms/step - accuracy: 1.0000 - loss: 0.0504 - val_accuracy: 0.8743 - val_loss: 0.3458\n",
            "Epoch 47/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 849ms/step - accuracy: 1.0000 - loss: 0.0512 - val_accuracy: 0.8689 - val_loss: 0.3482\n",
            "Epoch 48/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 760ms/step - accuracy: 1.0000 - loss: 0.0481 - val_accuracy: 0.8689 - val_loss: 0.3438\n",
            "Epoch 49/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 773ms/step - accuracy: 1.0000 - loss: 0.0471 - val_accuracy: 0.8689 - val_loss: 0.3432\n",
            "Epoch 50/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 764ms/step - accuracy: 1.0000 - loss: 0.0440 - val_accuracy: 0.8634 - val_loss: 0.3424\n",
            "Epoch 51/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 852ms/step - accuracy: 1.0000 - loss: 0.0451 - val_accuracy: 0.8689 - val_loss: 0.3458\n",
            "Epoch 52/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 846ms/step - accuracy: 1.0000 - loss: 0.0416 - val_accuracy: 0.8689 - val_loss: 0.3526\n",
            "Epoch 53/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 763ms/step - accuracy: 1.0000 - loss: 0.0450 - val_accuracy: 0.8689 - val_loss: 0.3449\n",
            "Epoch 54/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 843ms/step - accuracy: 1.0000 - loss: 0.0383 - val_accuracy: 0.8689 - val_loss: 0.3471\n",
            "Epoch 55/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 769ms/step - accuracy: 1.0000 - loss: 0.0400 - val_accuracy: 0.8689 - val_loss: 0.3520\n",
            "Epoch 56/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 844ms/step - accuracy: 1.0000 - loss: 0.0385 - val_accuracy: 0.8579 - val_loss: 0.3471\n",
            "Epoch 57/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 761ms/step - accuracy: 1.0000 - loss: 0.0368 - val_accuracy: 0.8689 - val_loss: 0.3503\n",
            "Epoch 58/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 845ms/step - accuracy: 1.0000 - loss: 0.0367 - val_accuracy: 0.8689 - val_loss: 0.3497\n",
            "Epoch 59/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 774ms/step - accuracy: 1.0000 - loss: 0.0347 - val_accuracy: 0.8689 - val_loss: 0.3491\n",
            "Epoch 60/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 843ms/step - accuracy: 1.0000 - loss: 0.0334 - val_accuracy: 0.8743 - val_loss: 0.3520\n",
            "Epoch 61/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 853ms/step - accuracy: 1.0000 - loss: 0.0341 - val_accuracy: 0.8743 - val_loss: 0.3525\n",
            "Epoch 62/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 757ms/step - accuracy: 1.0000 - loss: 0.0315 - val_accuracy: 0.8634 - val_loss: 0.3502\n",
            "Epoch 63/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0334 - val_accuracy: 0.8689 - val_loss: 0.3596\n",
            "Epoch 64/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 850ms/step - accuracy: 1.0000 - loss: 0.0307 - val_accuracy: 0.8689 - val_loss: 0.3506\n",
            "Epoch 65/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 849ms/step - accuracy: 1.0000 - loss: 0.0306 - val_accuracy: 0.8689 - val_loss: 0.3531\n",
            "Epoch 66/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 838ms/step - accuracy: 1.0000 - loss: 0.0294 - val_accuracy: 0.8743 - val_loss: 0.3569\n",
            "Epoch 67/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 839ms/step - accuracy: 1.0000 - loss: 0.0290 - val_accuracy: 0.8689 - val_loss: 0.3545\n",
            "Epoch 68/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 848ms/step - accuracy: 1.0000 - loss: 0.0292 - val_accuracy: 0.8689 - val_loss: 0.3546\n",
            "Epoch 69/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 857ms/step - accuracy: 1.0000 - loss: 0.0265 - val_accuracy: 0.8634 - val_loss: 0.3545\n",
            "Epoch 70/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 758ms/step - accuracy: 1.0000 - loss: 0.0276 - val_accuracy: 0.8743 - val_loss: 0.3607\n",
            "Epoch 71/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 850ms/step - accuracy: 1.0000 - loss: 0.0257 - val_accuracy: 0.8634 - val_loss: 0.3558\n",
            "Epoch 72/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 764ms/step - accuracy: 1.0000 - loss: 0.0261 - val_accuracy: 0.8689 - val_loss: 0.3581\n",
            "Epoch 73/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 842ms/step - accuracy: 1.0000 - loss: 0.0247 - val_accuracy: 0.8634 - val_loss: 0.3573\n",
            "Epoch 74/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 771ms/step - accuracy: 1.0000 - loss: 0.0243 - val_accuracy: 0.8579 - val_loss: 0.3572\n",
            "Epoch 75/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 849ms/step - accuracy: 1.0000 - loss: 0.0247 - val_accuracy: 0.8743 - val_loss: 0.3626\n",
            "Epoch 76/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 850ms/step - accuracy: 1.0000 - loss: 0.0239 - val_accuracy: 0.8579 - val_loss: 0.3590\n",
            "Epoch 77/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 845ms/step - accuracy: 1.0000 - loss: 0.0236 - val_accuracy: 0.8743 - val_loss: 0.3641\n",
            "Epoch 78/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 761ms/step - accuracy: 1.0000 - loss: 0.0237 - val_accuracy: 0.8689 - val_loss: 0.3596\n",
            "Epoch 79/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 866ms/step - accuracy: 1.0000 - loss: 0.0223 - val_accuracy: 0.8689 - val_loss: 0.3657\n",
            "Epoch 80/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 847ms/step - accuracy: 1.0000 - loss: 0.0228 - val_accuracy: 0.8634 - val_loss: 0.3620\n",
            "Epoch 81/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 844ms/step - accuracy: 1.0000 - loss: 0.0215 - val_accuracy: 0.8634 - val_loss: 0.3630\n",
            "Epoch 82/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 765ms/step - accuracy: 1.0000 - loss: 0.0215 - val_accuracy: 0.8634 - val_loss: 0.3644\n",
            "Epoch 83/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 763ms/step - accuracy: 1.0000 - loss: 0.0212 - val_accuracy: 0.8743 - val_loss: 0.3677\n",
            "Epoch 84/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0217 - val_accuracy: 0.8579 - val_loss: 0.3635\n",
            "Epoch 85/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 844ms/step - accuracy: 1.0000 - loss: 0.0190 - val_accuracy: 0.8634 - val_loss: 0.3642\n",
            "Epoch 86/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0196 - val_accuracy: 0.8743 - val_loss: 0.3695\n",
            "Epoch 87/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 846ms/step - accuracy: 1.0000 - loss: 0.0196 - val_accuracy: 0.8579 - val_loss: 0.3647\n",
            "Epoch 88/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 850ms/step - accuracy: 1.0000 - loss: 0.0187 - val_accuracy: 0.8634 - val_loss: 0.3672\n",
            "Epoch 89/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 851ms/step - accuracy: 1.0000 - loss: 0.0178 - val_accuracy: 0.8634 - val_loss: 0.3662\n",
            "Epoch 90/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 866ms/step - accuracy: 1.0000 - loss: 0.0178 - val_accuracy: 0.8634 - val_loss: 0.3687\n",
            "Epoch 91/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 761ms/step - accuracy: 1.0000 - loss: 0.0180 - val_accuracy: 0.8689 - val_loss: 0.3709\n",
            "Epoch 92/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 843ms/step - accuracy: 1.0000 - loss: 0.0173 - val_accuracy: 0.8689 - val_loss: 0.3666\n",
            "Epoch 93/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 757ms/step - accuracy: 1.0000 - loss: 0.0171 - val_accuracy: 0.8689 - val_loss: 0.3758\n",
            "Epoch 94/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 828ms/step - accuracy: 1.0000 - loss: 0.0172 - val_accuracy: 0.8579 - val_loss: 0.3684\n",
            "Epoch 95/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 760ms/step - accuracy: 1.0000 - loss: 0.0166 - val_accuracy: 0.8634 - val_loss: 0.3724\n",
            "Epoch 96/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0165 - val_accuracy: 0.8634 - val_loss: 0.3717\n",
            "Epoch 97/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 763ms/step - accuracy: 1.0000 - loss: 0.0159 - val_accuracy: 0.8634 - val_loss: 0.3724\n",
            "Epoch 98/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 799ms/step - accuracy: 1.0000 - loss: 0.0159 - val_accuracy: 0.8634 - val_loss: 0.3721\n",
            "Epoch 99/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 763ms/step - accuracy: 1.0000 - loss: 0.0155 - val_accuracy: 0.8634 - val_loss: 0.3739\n",
            "Epoch 100/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0152 - val_accuracy: 0.8579 - val_loss: 0.3721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7b38f41dd080> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 1s/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7b38f41dd080> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4s/step\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.8573 - loss: 0.3645\n",
            "Test Accuracy: 0.8516\n",
            "F1 Score: 0.8941\n",
            "G-Mean: 0.8037\n",
            "Informedness (IBA): 0.6232\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Define dataset paths\n",
        "benign_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/benign/400X\"\n",
        "malignant_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/malignant/400X\"\n",
        "\n",
        "# Function to load image paths\n",
        "def load_image_paths(dir_path):\n",
        "    return [os.path.join(dir_path, img) for img in os.listdir(dir_path) if img.endswith('.png')]\n",
        "\n",
        "benign_images = load_image_paths(benign_dir)\n",
        "malignant_images = load_image_paths(malignant_dir)\n",
        "\n",
        "print(f\"Total Benign Images: {len(benign_images)}\")\n",
        "print(f\"Total Malignant Images: {len(malignant_images)}\")\n",
        "\n",
        "# Create labels (0 = Benign, 1 = Malignant)\n",
        "benign_labels = [0] * len(benign_images)\n",
        "malignant_labels = [1] * len(malignant_images)\n",
        "\n",
        "# Combine images and labels\n",
        "all_images = np.array(benign_images + malignant_images)\n",
        "all_labels = np.array(benign_labels + malignant_labels)\n",
        "\n",
        "# Split into training (60%), validation (10%), and testing (30%)\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(\n",
        "    all_images, all_labels, test_size=0.3, stratify=all_labels, random_state=42\n",
        ")\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(\n",
        "    train_images, train_labels, test_size=0.1429, stratify=train_labels, random_state=42  # 10% of total (1/7 of 70%)\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {len(train_images)}\")\n",
        "print(f\"Validation samples: {len(val_images)}\")\n",
        "print(f\"Testing samples: {len(test_images)}\")\n",
        "\n",
        "# Function to preprocess images\n",
        "def process_path(file_path, label):\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_png(img, channels=3)\n",
        "    img = tf.image.resize(img, [224, 224])\n",
        "    img = img / 255.0\n",
        "    return img, label\n",
        "\n",
        "# Create TensorFlow datasets\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "train_dataset = train_dataset.map(process_path).shuffle(1000).batch(BATCH_SIZE)\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
        "val_dataset = val_dataset.map(process_path).batch(BATCH_SIZE)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
        "test_dataset = test_dataset.map(process_path).batch(BATCH_SIZE)\n",
        "\n",
        "# Ensure testing dataset is not empty\n",
        "if sum(1 for _ in test_dataset) == 0:\n",
        "    raise ValueError(\"Testing dataset is empty. Adjust your dataset split.\")\n",
        "\n",
        "# Load VGG16 without the top classification layer\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the pre-trained layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add modified classifier (Single Dense Layer)\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(1, activation='sigmoid')(x)  # Single Dense Layer for Binary Classification\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "EPOCHS = 100\n",
        "history = model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS)\n",
        "\n",
        "# Evaluate model\n",
        "test_preds = model.predict(test_dataset)\n",
        "test_preds = (test_preds > 0.5).astype(int).flatten()\n",
        "\n",
        "# Get confusion matrix values\n",
        "tn, fp, fn, tp = confusion_matrix(test_labels, test_preds).ravel()\n",
        "\n",
        "# Calculate IBA\n",
        "iba = (tp / (tp + fn)) + (tn / (tn + fp)) - 1\n",
        "\n",
        "# Output results\n",
        "f1 = f1_score(test_labels, test_preds)\n",
        "gmean = geometric_mean_score(test_labels, test_preds)\n",
        "\n",
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"G-Mean: {gmean:.4f}\")\n",
        "print(f\"Informedness (IBA): {iba:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uG_IpqjhGjb"
      },
      "source": [
        "# Here is a table summarizing the performance metrics for all magnification factors (40X, 100X, 200X, 400X) from notebook:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3DDJ1EGDhHzn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "faa179af-db55-469c-ecbb-23e13fc83caf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7dcc8030d7d0>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_905af th {\n",
              "  background-color: #000000;\n",
              "  font-weight: bold;\n",
              "  color: white;\n",
              "}\n",
              "#T_905af_row0_col0, #T_905af_row0_col1, #T_905af_row0_col2, #T_905af_row0_col3, #T_905af_row0_col4, #T_905af_row1_col0, #T_905af_row1_col1, #T_905af_row1_col2, #T_905af_row1_col3, #T_905af_row1_col4, #T_905af_row2_col0, #T_905af_row2_col1, #T_905af_row2_col2, #T_905af_row2_col3, #T_905af_row2_col4, #T_905af_row3_col0, #T_905af_row3_col1, #T_905af_row3_col2, #T_905af_row3_col3, #T_905af_row3_col4 {\n",
              "  text-align: center;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_905af\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th id=\"T_905af_level0_col0\" class=\"col_heading level0 col0\" >Magnification</th>\n",
              "      <th id=\"T_905af_level0_col1\" class=\"col_heading level0 col1\" >Test Accuracy</th>\n",
              "      <th id=\"T_905af_level0_col2\" class=\"col_heading level0 col2\" >F1 Score</th>\n",
              "      <th id=\"T_905af_level0_col3\" class=\"col_heading level0 col3\" >G-Mean</th>\n",
              "      <th id=\"T_905af_level0_col4\" class=\"col_heading level0 col4\" >Informedness (IBA)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td id=\"T_905af_row0_col0\" class=\"data row0 col0\" >40X</td>\n",
              "      <td id=\"T_905af_row0_col1\" class=\"data row0 col1\" >0.8681</td>\n",
              "      <td id=\"T_905af_row0_col2\" class=\"data row0 col2\" >0.9067</td>\n",
              "      <td id=\"T_905af_row0_col3\" class=\"data row0 col3\" >0.8221</td>\n",
              "      <td id=\"T_905af_row0_col4\" class=\"data row0 col4\" >0.6577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_905af_row1_col0\" class=\"data row1 col0\" >100X</td>\n",
              "      <td id=\"T_905af_row1_col1\" class=\"data row1 col1\" >0.8626</td>\n",
              "      <td id=\"T_905af_row1_col2\" class=\"data row1 col2\" >0.9029</td>\n",
              "      <td id=\"T_905af_row1_col3\" class=\"data row1 col3\" >0.8163</td>\n",
              "      <td id=\"T_905af_row1_col4\" class=\"data row1 col4\" >0.6460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_905af_row2_col0\" class=\"data row2 col0\" >200X</td>\n",
              "      <td id=\"T_905af_row2_col1\" class=\"data row2 col1\" >0.8742</td>\n",
              "      <td id=\"T_905af_row2_col2\" class=\"data row2 col2\" >0.9112</td>\n",
              "      <td id=\"T_905af_row2_col3\" class=\"data row2 col3\" >0.8308</td>\n",
              "      <td id=\"T_905af_row2_col4\" class=\"data row2 col4\" >0.6732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_905af_row3_col0\" class=\"data row3 col0\" >400X</td>\n",
              "      <td id=\"T_905af_row3_col1\" class=\"data row3 col1\" >0.8516</td>\n",
              "      <td id=\"T_905af_row3_col2\" class=\"data row3 col2\" >0.8941</td>\n",
              "      <td id=\"T_905af_row3_col3\" class=\"data row3 col3\" >0.8037</td>\n",
              "      <td id=\"T_905af_row3_col4\" class=\"data row3 col4\" >0.6232</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame with the provided values\n",
        "data = {\n",
        "    'Magnification': ['40X', '100X', '200X', '400X'],\n",
        "    'Test Accuracy': [0.8681, 0.8626, 0.8742, 0.8516],\n",
        "    'F1 Score': [0.9067, 0.9029, 0.9112, 0.8941],\n",
        "    'G-Mean': [0.8221, 0.8163, 0.8308, 0.8037],\n",
        "    'Informedness (IBA)': [0.6577, 0.6460, 0.6732, 0.6232]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display the table with formatting\n",
        "styled_df = df.style \\\n",
        "    .format({\n",
        "        'Test Accuracy': '{:.4f}',\n",
        "        'F1 Score': '{:.4f}',\n",
        "        'G-Mean': '{:.4f}',\n",
        "        'Informedness (IBA)': '{:.4f}'\n",
        "    }) \\\n",
        "    .set_properties(**{'text-align': 'center'}) \\\n",
        "    .set_table_styles([\n",
        "        {'selector': 'th', 'props': [('background-color', '#000000'), ('font-weight', 'bold'), ('color', 'white')]}\n",
        "    ]) \\\n",
        "    .hide(axis='index')\n",
        "\n",
        "styled_df\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CrLEjtLNmE3r"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}