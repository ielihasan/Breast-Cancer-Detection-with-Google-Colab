{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Modified VGG16 with Inception Block for Cancer Classification**\n",
        "This Colab notebook implements a modified **VGG16** model for binary classification (benign vs. malignant) using the **BreaKHis** dataset. The model includes:\n",
        "- **Pre-trained VGG16** (with frozen convolutional layers).\n",
        "- **Custom Inception Block** added after VGG16 for feature extraction.\n",
        "- **Dense Layer for classification**.\n",
        "\n",
        "### **Dataset Details**\n",
        "- **BreaKHis dataset** (40X magnification).\n",
        "- Images are loaded from Google Drive.\n",
        "- Labels: **Benign (0)** and **Malignant (1)**.\n",
        "\n",
        "### **Data Split**\n",
        "- **60% Training**\n",
        "- **10% Validation**\n",
        "- **30% Testing**\n",
        "\n",
        "### **Training Details**\n",
        "- Image preprocessing: **224x224 resizing & normalization**.\n",
        "- **Adam Optimizer** with Binary Cross-Entropy Loss.\n",
        "- **Batch Size: 16**, **Epochs: 10**.\n",
        "\n",
        "### **Evaluation Metrics**\n",
        "- **Accuracy**\n",
        "- **F1 Score**\n",
        "- **Geometric Mean Score (G-Mean)**\n",
        "- **Informedness (IBA)**"
      ],
      "metadata": {
        "id": "RTtApM1DtTNO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "**Magnification Factor: 40X**\n",
        "***"
      ],
      "metadata": {
        "id": "Xs3qWHRftb-n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aPo72cLpkYe",
        "outputId": "5447d97d-26a3-4096-be57-cf3864733c7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Benign Images: 626\n",
            "Total Malignant Images: 1370\n",
            "Training samples: 1197\n",
            "Validation samples: 200\n",
            "Testing samples: 599\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 8s/step - accuracy: 0.5590 - loss: 0.9462 - val_accuracy: 0.6850 - val_loss: 0.6423\n",
            "Epoch 2/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 829ms/step - accuracy: 0.6869 - loss: 0.6414 - val_accuracy: 0.7000 - val_loss: 0.6006\n",
            "Epoch 3/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.7023 - loss: 0.5894 - val_accuracy: 0.6900 - val_loss: 0.5523\n",
            "Epoch 4/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 771ms/step - accuracy: 0.7264 - loss: 0.5540 - val_accuracy: 0.7650 - val_loss: 0.5056\n",
            "Epoch 5/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 827ms/step - accuracy: 0.7763 - loss: 0.5081 - val_accuracy: 0.8350 - val_loss: 0.4550\n",
            "Epoch 6/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 805ms/step - accuracy: 0.7715 - loss: 0.4865 - val_accuracy: 0.8000 - val_loss: 0.4572\n",
            "Epoch 7/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.8146 - loss: 0.4231 - val_accuracy: 0.7800 - val_loss: 0.4559\n",
            "Epoch 8/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 849ms/step - accuracy: 0.8397 - loss: 0.3916 - val_accuracy: 0.8300 - val_loss: 0.3947\n",
            "Epoch 9/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 801ms/step - accuracy: 0.8517 - loss: 0.3432 - val_accuracy: 0.8400 - val_loss: 0.3540\n",
            "Epoch 10/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 809ms/step - accuracy: 0.8636 - loss: 0.3169 - val_accuracy: 0.8700 - val_loss: 0.3401\n",
            "Epoch 11/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 841ms/step - accuracy: 0.9033 - loss: 0.2467 - val_accuracy: 0.8700 - val_loss: 0.3276\n",
            "Epoch 12/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 812ms/step - accuracy: 0.9249 - loss: 0.2058 - val_accuracy: 0.8900 - val_loss: 0.3025\n",
            "Epoch 13/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 922ms/step - accuracy: 0.9317 - loss: 0.1983 - val_accuracy: 0.8450 - val_loss: 0.3611\n",
            "Epoch 14/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.9505 - loss: 0.1520 - val_accuracy: 0.8850 - val_loss: 0.2890\n",
            "Epoch 15/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 841ms/step - accuracy: 0.9524 - loss: 0.1282 - val_accuracy: 0.8700 - val_loss: 0.3214\n",
            "Epoch 16/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 801ms/step - accuracy: 0.9672 - loss: 0.1012 - val_accuracy: 0.8500 - val_loss: 0.3994\n",
            "Epoch 17/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 850ms/step - accuracy: 0.9514 - loss: 0.1275 - val_accuracy: 0.8950 - val_loss: 0.2860\n",
            "Epoch 18/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 793ms/step - accuracy: 0.9832 - loss: 0.0633 - val_accuracy: 0.9050 - val_loss: 0.2705\n",
            "Epoch 19/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 839ms/step - accuracy: 0.9927 - loss: 0.0493 - val_accuracy: 0.8850 - val_loss: 0.2959\n",
            "Epoch 20/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 783ms/step - accuracy: 0.9849 - loss: 0.0545 - val_accuracy: 0.8700 - val_loss: 0.3919\n",
            "Epoch 21/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 776ms/step - accuracy: 0.9868 - loss: 0.0502 - val_accuracy: 0.8300 - val_loss: 0.5095\n",
            "Epoch 22/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 763ms/step - accuracy: 0.9759 - loss: 0.0676 - val_accuracy: 0.8600 - val_loss: 0.4542\n",
            "Epoch 23/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.9913 - loss: 0.0365 - val_accuracy: 0.9200 - val_loss: 0.2853\n",
            "Epoch 24/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 776ms/step - accuracy: 0.9986 - loss: 0.0198 - val_accuracy: 0.9150 - val_loss: 0.3164\n",
            "Epoch 25/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 830ms/step - accuracy: 0.9945 - loss: 0.0165 - val_accuracy: 0.9100 - val_loss: 0.3323\n",
            "Epoch 26/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 780ms/step - accuracy: 0.9994 - loss: 0.0099 - val_accuracy: 0.9050 - val_loss: 0.3534\n",
            "Epoch 27/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 838ms/step - accuracy: 0.9982 - loss: 0.0098 - val_accuracy: 0.9200 - val_loss: 0.3521\n",
            "Epoch 28/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 866ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 0.9150 - val_loss: 0.3557\n",
            "Epoch 29/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.9996 - loss: 0.0058 - val_accuracy: 0.9100 - val_loss: 0.3665\n",
            "Epoch 30/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 793ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.9200 - val_loss: 0.3678\n",
            "Epoch 31/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 842ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.9200 - val_loss: 0.3729\n",
            "Epoch 32/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 810ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.9150 - val_loss: 0.4066\n",
            "Epoch 33/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 809ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.9150 - val_loss: 0.3908\n",
            "Epoch 34/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 825ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9200 - val_loss: 0.3951\n",
            "Epoch 35/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 793ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9250 - val_loss: 0.3969\n",
            "Epoch 36/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 848ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9200 - val_loss: 0.4023\n",
            "Epoch 37/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 855ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9150 - val_loss: 0.4113\n",
            "Epoch 38/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 874ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9250 - val_loss: 0.4046\n",
            "Epoch 39/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 856ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9150 - val_loss: 0.4140\n",
            "Epoch 40/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9200 - val_loss: 0.4106\n",
            "Epoch 41/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 837ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9150 - val_loss: 0.4182\n",
            "Epoch 42/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 819ms/step - accuracy: 1.0000 - loss: 9.8068e-04 - val_accuracy: 0.9150 - val_loss: 0.4214\n",
            "Epoch 43/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 816ms/step - accuracy: 1.0000 - loss: 9.5635e-04 - val_accuracy: 0.9150 - val_loss: 0.4267\n",
            "Epoch 44/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 825ms/step - accuracy: 1.0000 - loss: 9.2188e-04 - val_accuracy: 0.9250 - val_loss: 0.4258\n",
            "Epoch 45/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 846ms/step - accuracy: 1.0000 - loss: 8.0860e-04 - val_accuracy: 0.9150 - val_loss: 0.4401\n",
            "Epoch 46/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 834ms/step - accuracy: 1.0000 - loss: 8.7390e-04 - val_accuracy: 0.9250 - val_loss: 0.4329\n",
            "Epoch 47/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 801ms/step - accuracy: 1.0000 - loss: 6.3712e-04 - val_accuracy: 0.9200 - val_loss: 0.4368\n",
            "Epoch 48/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 800ms/step - accuracy: 1.0000 - loss: 6.2210e-04 - val_accuracy: 0.9150 - val_loss: 0.4508\n",
            "Epoch 49/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 860ms/step - accuracy: 1.0000 - loss: 5.7264e-04 - val_accuracy: 0.9200 - val_loss: 0.4449\n",
            "Epoch 50/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 807ms/step - accuracy: 1.0000 - loss: 5.4537e-04 - val_accuracy: 0.9150 - val_loss: 0.4490\n",
            "Epoch 51/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 809ms/step - accuracy: 1.0000 - loss: 4.3482e-04 - val_accuracy: 0.9200 - val_loss: 0.4491\n",
            "Epoch 52/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 848ms/step - accuracy: 1.0000 - loss: 5.4934e-04 - val_accuracy: 0.9200 - val_loss: 0.4540\n",
            "Epoch 53/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.1903e-04 - val_accuracy: 0.9200 - val_loss: 0.4561\n",
            "Epoch 54/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 850ms/step - accuracy: 1.0000 - loss: 4.1672e-04 - val_accuracy: 0.9200 - val_loss: 0.4596\n",
            "Epoch 55/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 850ms/step - accuracy: 1.0000 - loss: 4.1061e-04 - val_accuracy: 0.9200 - val_loss: 0.4648\n",
            "Epoch 56/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 3.6128e-04 - val_accuracy: 0.9200 - val_loss: 0.4658\n",
            "Epoch 57/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.8826e-04 - val_accuracy: 0.9150 - val_loss: 0.4703\n",
            "Epoch 58/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 825ms/step - accuracy: 1.0000 - loss: 4.2241e-04 - val_accuracy: 0.9200 - val_loss: 0.4727\n",
            "Epoch 59/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 852ms/step - accuracy: 1.0000 - loss: 3.8365e-04 - val_accuracy: 0.9200 - val_loss: 0.4758\n",
            "Epoch 60/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 861ms/step - accuracy: 1.0000 - loss: 2.7207e-04 - val_accuracy: 0.9200 - val_loss: 0.4780\n",
            "Epoch 61/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 811ms/step - accuracy: 1.0000 - loss: 3.1330e-04 - val_accuracy: 0.9150 - val_loss: 0.4858\n",
            "Epoch 62/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 853ms/step - accuracy: 1.0000 - loss: 2.8880e-04 - val_accuracy: 0.9200 - val_loss: 0.4838\n",
            "Epoch 63/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.6492e-04 - val_accuracy: 0.9150 - val_loss: 0.4886\n",
            "Epoch 64/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 804ms/step - accuracy: 1.0000 - loss: 2.1236e-04 - val_accuracy: 0.9200 - val_loss: 0.4886\n",
            "Epoch 65/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 845ms/step - accuracy: 1.0000 - loss: 2.2347e-04 - val_accuracy: 0.9150 - val_loss: 0.4942\n",
            "Epoch 66/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 803ms/step - accuracy: 1.0000 - loss: 2.4530e-04 - val_accuracy: 0.9200 - val_loss: 0.4939\n",
            "Epoch 67/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 850ms/step - accuracy: 1.0000 - loss: 1.8060e-04 - val_accuracy: 0.9200 - val_loss: 0.4980\n",
            "Epoch 68/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 849ms/step - accuracy: 1.0000 - loss: 1.8833e-04 - val_accuracy: 0.9200 - val_loss: 0.5005\n",
            "Epoch 69/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 830ms/step - accuracy: 1.0000 - loss: 1.5985e-04 - val_accuracy: 0.9200 - val_loss: 0.5033\n",
            "Epoch 70/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.6389e-04 - val_accuracy: 0.9200 - val_loss: 0.5074\n",
            "Epoch 71/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 807ms/step - accuracy: 1.0000 - loss: 1.7486e-04 - val_accuracy: 0.9200 - val_loss: 0.5095\n",
            "Epoch 72/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 802ms/step - accuracy: 1.0000 - loss: 1.4571e-04 - val_accuracy: 0.9200 - val_loss: 0.5112\n",
            "Epoch 73/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 845ms/step - accuracy: 1.0000 - loss: 1.7205e-04 - val_accuracy: 0.9200 - val_loss: 0.5145\n",
            "Epoch 74/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 795ms/step - accuracy: 1.0000 - loss: 1.4036e-04 - val_accuracy: 0.9200 - val_loss: 0.5182\n",
            "Epoch 75/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 858ms/step - accuracy: 1.0000 - loss: 1.3649e-04 - val_accuracy: 0.9200 - val_loss: 0.5202\n",
            "Epoch 76/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 806ms/step - accuracy: 1.0000 - loss: 1.4700e-04 - val_accuracy: 0.9200 - val_loss: 0.5231\n",
            "Epoch 77/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 807ms/step - accuracy: 1.0000 - loss: 1.2327e-04 - val_accuracy: 0.9200 - val_loss: 0.5254\n",
            "Epoch 78/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 800ms/step - accuracy: 1.0000 - loss: 1.2015e-04 - val_accuracy: 0.9200 - val_loss: 0.5280\n",
            "Epoch 79/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 857ms/step - accuracy: 1.0000 - loss: 1.0769e-04 - val_accuracy: 0.9200 - val_loss: 0.5296\n",
            "Epoch 80/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 850ms/step - accuracy: 1.0000 - loss: 1.0929e-04 - val_accuracy: 0.9200 - val_loss: 0.5323\n",
            "Epoch 81/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 810ms/step - accuracy: 1.0000 - loss: 1.1550e-04 - val_accuracy: 0.9200 - val_loss: 0.5343\n",
            "Epoch 82/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 850ms/step - accuracy: 1.0000 - loss: 9.9843e-05 - val_accuracy: 0.9200 - val_loss: 0.5354\n",
            "Epoch 83/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 813ms/step - accuracy: 1.0000 - loss: 9.5798e-05 - val_accuracy: 0.9200 - val_loss: 0.5375\n",
            "Epoch 84/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 832ms/step - accuracy: 1.0000 - loss: 9.2447e-05 - val_accuracy: 0.9200 - val_loss: 0.5399\n",
            "Epoch 85/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 820ms/step - accuracy: 1.0000 - loss: 9.8621e-05 - val_accuracy: 0.9200 - val_loss: 0.5446\n",
            "Epoch 86/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 853ms/step - accuracy: 1.0000 - loss: 7.6770e-05 - val_accuracy: 0.9200 - val_loss: 0.5445\n",
            "Epoch 87/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 817ms/step - accuracy: 1.0000 - loss: 9.2873e-05 - val_accuracy: 0.9200 - val_loss: 0.5471\n",
            "Epoch 88/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 923ms/step - accuracy: 1.0000 - loss: 8.7136e-05 - val_accuracy: 0.9200 - val_loss: 0.5531\n",
            "Epoch 89/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 904ms/step - accuracy: 1.0000 - loss: 8.6838e-05 - val_accuracy: 0.9200 - val_loss: 0.5530\n",
            "Epoch 90/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.7066e-05 - val_accuracy: 0.9200 - val_loss: 0.5549\n",
            "Epoch 91/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 849ms/step - accuracy: 1.0000 - loss: 8.3761e-05 - val_accuracy: 0.9200 - val_loss: 0.5573\n",
            "Epoch 92/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 853ms/step - accuracy: 1.0000 - loss: 6.2706e-05 - val_accuracy: 0.9200 - val_loss: 0.5595\n",
            "Epoch 93/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 839ms/step - accuracy: 1.0000 - loss: 7.0131e-05 - val_accuracy: 0.9200 - val_loss: 0.5608\n",
            "Epoch 94/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 845ms/step - accuracy: 1.0000 - loss: 6.7703e-05 - val_accuracy: 0.9250 - val_loss: 0.5624\n",
            "Epoch 95/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 845ms/step - accuracy: 1.0000 - loss: 6.3725e-05 - val_accuracy: 0.9200 - val_loss: 0.5657\n",
            "Epoch 96/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 802ms/step - accuracy: 1.0000 - loss: 6.1826e-05 - val_accuracy: 0.9250 - val_loss: 0.5667\n",
            "Epoch 97/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 831ms/step - accuracy: 1.0000 - loss: 5.5789e-05 - val_accuracy: 0.9200 - val_loss: 0.5693\n",
            "Epoch 98/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 820ms/step - accuracy: 1.0000 - loss: 5.1301e-05 - val_accuracy: 0.9250 - val_loss: 0.5709\n",
            "Epoch 99/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 805ms/step - accuracy: 1.0000 - loss: 5.6418e-05 - val_accuracy: 0.9200 - val_loss: 0.5732\n",
            "Epoch 100/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 812ms/step - accuracy: 1.0000 - loss: 5.4521e-05 - val_accuracy: 0.9250 - val_loss: 0.5748\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 7s/step\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8938 - loss: 0.7840\n",
            "Test Accuracy: 0.8982\n",
            "F1 Score: 0.9264\n",
            "G-Mean: 0.8748\n",
            "Informedness (IBA): 0.7535\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, concatenate, AveragePooling2D, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "\n",
        "# Define dataset paths\n",
        "benign_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/benign/40X\"\n",
        "malignant_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/malignant/40X\"\n",
        "\n",
        "def load_image_paths(dir_path):\n",
        "    return [os.path.join(dir_path, img) for img in os.listdir(dir_path) if img.endswith('.png')]\n",
        "\n",
        "benign_images = load_image_paths(benign_dir)\n",
        "malignant_images = load_image_paths(malignant_dir)\n",
        "\n",
        "print(f\"Total Benign Images: {len(benign_images)}\")\n",
        "print(f\"Total Malignant Images: {len(malignant_images)}\")\n",
        "\n",
        "benign_labels = [0] * len(benign_images)\n",
        "malignant_labels = [1] * len(malignant_images)\n",
        "\n",
        "all_images = np.array(benign_images + malignant_images)\n",
        "all_labels = np.array(benign_labels + malignant_labels)\n",
        "\n",
        "# Split dataset (60% train, 10% val, 30% test)\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(\n",
        "    all_images, all_labels, test_size=0.3, stratify=all_labels, random_state=42)\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(\n",
        "    train_images, train_labels, test_size=0.1429, stratify=train_labels, random_state=42)\n",
        "\n",
        "print(f\"Training samples: {len(train_images)}\")\n",
        "print(f\"Validation samples: {len(val_images)}\")\n",
        "print(f\"Testing samples: {len(test_images)}\")\n",
        "\n",
        "def process_path(file_path, label):\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_png(img, channels=3)\n",
        "    img = tf.image.resize(img, [224, 224])\n",
        "    img = img / 255.0\n",
        "    return img, label\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).map(process_path).shuffle(1000).batch(BATCH_SIZE)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels)).map(process_path).batch(BATCH_SIZE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).map(process_path).batch(BATCH_SIZE)\n",
        "\n",
        "if sum(1 for _ in test_dataset) == 0:\n",
        "    raise ValueError(\"Testing dataset is empty. Adjust your dataset split.\")\n",
        "\n",
        "# Load VGG16 without top layers\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "def inception_block(x):\n",
        "    branch1 = Conv2D(64, (1, 1), activation='relu', padding='same')(x)\n",
        "\n",
        "    branch2 = Conv2D(64, (1, 1), activation='relu', padding='same')(x)\n",
        "    branch2 = Conv2D(128, (3, 3), activation='relu', padding='same')(branch2)\n",
        "\n",
        "    branch3 = Conv2D(64, (1, 1), activation='relu', padding='same')(x)\n",
        "    branch3 = Conv2D(128, (5, 5), activation='relu', padding='same')(branch3)\n",
        "\n",
        "    branch4 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "    branch4 = Conv2D(64, (1, 1), activation='relu', padding='same')(branch4)\n",
        "\n",
        "    output = concatenate([branch1, branch2, branch3, branch4], axis=-1)\n",
        "    return output\n",
        "\n",
        "# Add Inception block after VGG16\n",
        "x = inception_block(base_model.output)\n",
        "x = AveragePooling2D(pool_size=(2, 2))(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "EPOCHS = 100\n",
        "history = model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS)\n",
        "\n",
        "test_preds = model.predict(test_dataset)\n",
        "test_preds = (test_preds > 0.5).astype(int).flatten()\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(test_labels, test_preds).ravel()\n",
        "iba = (tp / (tp + fn)) + (tn / (tn + fp)) - 1\n",
        "\n",
        "f1 = f1_score(test_labels, test_preds)\n",
        "gmean = geometric_mean_score(test_labels, test_preds)\n",
        "\n",
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"G-Mean: {gmean:.4f}\")\n",
        "print(f\"Informedness (IBA): {iba:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "**Magnification Factor: 100X**\n",
        "***"
      ],
      "metadata": {
        "id": "0z4sZ-dzteNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, concatenate, AveragePooling2D, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "\n",
        "# Define dataset paths\n",
        "benign_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/benign/100X\"\n",
        "malignant_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/malignant/100X\"\n",
        "\n",
        "def load_image_paths(dir_path):\n",
        "    return [os.path.join(dir_path, img) for img in os.listdir(dir_path) if img.endswith('.png')]\n",
        "\n",
        "benign_images = load_image_paths(benign_dir)\n",
        "malignant_images = load_image_paths(malignant_dir)\n",
        "\n",
        "print(f\"Total Benign Images: {len(benign_images)}\")\n",
        "print(f\"Total Malignant Images: {len(malignant_images)}\")\n",
        "\n",
        "benign_labels = [0] * len(benign_images)\n",
        "malignant_labels = [1] * len(malignant_images)\n",
        "\n",
        "all_images = np.array(benign_images + malignant_images)\n",
        "all_labels = np.array(benign_labels + malignant_labels)\n",
        "\n",
        "# Split dataset (60% train, 10% val, 30% test)\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(\n",
        "    all_images, all_labels, test_size=0.3, stratify=all_labels, random_state=42)\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(\n",
        "    train_images, train_labels, test_size=0.1429, stratify=train_labels, random_state=42)\n",
        "\n",
        "print(f\"Training samples: {len(train_images)}\")\n",
        "print(f\"Validation samples: {len(val_images)}\")\n",
        "print(f\"Testing samples: {len(test_images)}\")\n",
        "\n",
        "def process_path(file_path, label):\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_png(img, channels=3)\n",
        "    img = tf.image.resize(img, [224, 224])\n",
        "    img = img / 255.0\n",
        "    return img, label\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).map(process_path).shuffle(1000).batch(BATCH_SIZE)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels)).map(process_path).batch(BATCH_SIZE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).map(process_path).batch(BATCH_SIZE)\n",
        "\n",
        "if sum(1 for _ in test_dataset) == 0:\n",
        "    raise ValueError(\"Testing dataset is empty. Adjust your dataset split.\")\n",
        "\n",
        "# Load VGG16 without top layers\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "def inception_block(x):\n",
        "    branch1 = Conv2D(64, (1, 1), activation='relu', padding='same')(x)\n",
        "\n",
        "    branch2 = Conv2D(64, (1, 1), activation='relu', padding='same')(x)\n",
        "    branch2 = Conv2D(128, (3, 3), activation='relu', padding='same')(branch2)\n",
        "\n",
        "    branch3 = Conv2D(64, (1, 1), activation='relu', padding='same')(x)\n",
        "    branch3 = Conv2D(128, (5, 5), activation='relu', padding='same')(branch3)\n",
        "\n",
        "    branch4 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "    branch4 = Conv2D(64, (1, 1), activation='relu', padding='same')(branch4)\n",
        "\n",
        "    output = concatenate([branch1, branch2, branch3, branch4], axis=-1)\n",
        "    return output\n",
        "\n",
        "# Add Inception block after VGG16\n",
        "x = inception_block(base_model.output)\n",
        "x = AveragePooling2D(pool_size=(2, 2))(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "EPOCHS = 100\n",
        "history = model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS)\n",
        "\n",
        "test_preds = model.predict(test_dataset)\n",
        "test_preds = (test_preds > 0.5).astype(int).flatten()\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(test_labels, test_preds).ravel()\n",
        "iba = (tp / (tp + fn)) + (tn / (tn + fp)) - 1\n",
        "\n",
        "f1 = f1_score(test_labels, test_preds)\n",
        "gmean = geometric_mean_score(test_labels, test_preds)\n",
        "\n",
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"G-Mean: {gmean:.4f}\")\n",
        "print(f\"Informedness (IBA): {iba:.4f}\")"
      ],
      "metadata": {
        "id": "scgOqqbgrWcR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04891f3d-3c2b-4dad-9997-747231a5b758"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Benign Images: 649\n",
            "Total Malignant Images: 1437\n",
            "Training samples: 1251\n",
            "Validation samples: 209\n",
            "Testing samples: 626\n",
            "Epoch 1/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 11s/step - accuracy: 0.5227 - loss: 1.0397 - val_accuracy: 0.6890 - val_loss: 0.6168\n",
            "Epoch 2/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.6880 - loss: 0.6283 - val_accuracy: 0.6890 - val_loss: 0.6092\n",
            "Epoch 3/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 932ms/step - accuracy: 0.7005 - loss: 0.5917 - val_accuracy: 0.6890 - val_loss: 0.5674\n",
            "Epoch 4/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 908ms/step - accuracy: 0.7043 - loss: 0.5526 - val_accuracy: 0.6890 - val_loss: 0.5262\n",
            "Epoch 5/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 942ms/step - accuracy: 0.7524 - loss: 0.4998 - val_accuracy: 0.8182 - val_loss: 0.4431\n",
            "Epoch 6/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 923ms/step - accuracy: 0.8206 - loss: 0.4255 - val_accuracy: 0.8182 - val_loss: 0.3861\n",
            "Epoch 7/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 924ms/step - accuracy: 0.8373 - loss: 0.3812 - val_accuracy: 0.8612 - val_loss: 0.3559\n",
            "Epoch 8/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - accuracy: 0.8606 - loss: 0.3285 - val_accuracy: 0.8612 - val_loss: 0.3367\n",
            "Epoch 9/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 933ms/step - accuracy: 0.8888 - loss: 0.2828 - val_accuracy: 0.8756 - val_loss: 0.3034\n",
            "Epoch 10/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 918ms/step - accuracy: 0.8901 - loss: 0.2519 - val_accuracy: 0.8565 - val_loss: 0.3293\n",
            "Epoch 11/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 930ms/step - accuracy: 0.9071 - loss: 0.2294 - val_accuracy: 0.8756 - val_loss: 0.3056\n",
            "Epoch 12/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 901ms/step - accuracy: 0.9334 - loss: 0.1816 - val_accuracy: 0.8612 - val_loss: 0.2989\n",
            "Epoch 13/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 956ms/step - accuracy: 0.9328 - loss: 0.1589 - val_accuracy: 0.8373 - val_loss: 0.4116\n",
            "Epoch 14/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.9388 - loss: 0.1433 - val_accuracy: 0.8612 - val_loss: 0.3367\n",
            "Epoch 15/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 990ms/step - accuracy: 0.9518 - loss: 0.1386 - val_accuracy: 0.8900 - val_loss: 0.2946\n",
            "Epoch 16/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - accuracy: 0.9842 - loss: 0.0704 - val_accuracy: 0.8708 - val_loss: 0.3239\n",
            "Epoch 17/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 895ms/step - accuracy: 0.9862 - loss: 0.0709 - val_accuracy: 0.8947 - val_loss: 0.3324\n",
            "Epoch 18/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 890ms/step - accuracy: 0.9826 - loss: 0.0564 - val_accuracy: 0.8804 - val_loss: 0.3320\n",
            "Epoch 19/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 928ms/step - accuracy: 0.9892 - loss: 0.0442 - val_accuracy: 0.9043 - val_loss: 0.3306\n",
            "Epoch 20/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 911ms/step - accuracy: 0.9943 - loss: 0.0303 - val_accuracy: 0.8995 - val_loss: 0.3275\n",
            "Epoch 21/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 905ms/step - accuracy: 0.9988 - loss: 0.0192 - val_accuracy: 0.8995 - val_loss: 0.3279\n",
            "Epoch 22/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 968ms/step - accuracy: 0.9967 - loss: 0.0188 - val_accuracy: 0.8852 - val_loss: 0.3768\n",
            "Epoch 23/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 943ms/step - accuracy: 0.9977 - loss: 0.0203 - val_accuracy: 0.8900 - val_loss: 0.3396\n",
            "Epoch 24/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 966ms/step - accuracy: 0.9975 - loss: 0.0150 - val_accuracy: 0.8947 - val_loss: 0.3990\n",
            "Epoch 25/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 932ms/step - accuracy: 0.9957 - loss: 0.0173 - val_accuracy: 0.9043 - val_loss: 0.3542\n",
            "Epoch 26/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 966ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.9043 - val_loss: 0.3819\n",
            "Epoch 27/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.8995 - val_loss: 0.4016\n",
            "Epoch 28/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 936ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.9043 - val_loss: 0.4001\n",
            "Epoch 29/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 922ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.8947 - val_loss: 0.3977\n",
            "Epoch 30/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 939ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9043 - val_loss: 0.4081\n",
            "Epoch 31/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.8947 - val_loss: 0.4210\n",
            "Epoch 32/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 909ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.8900 - val_loss: 0.4331\n",
            "Epoch 33/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 961ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.8947 - val_loss: 0.4378\n",
            "Epoch 34/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9091 - val_loss: 0.4484\n",
            "Epoch 35/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.8900 - val_loss: 0.4597\n",
            "Epoch 36/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.8995 - val_loss: 0.4562\n",
            "Epoch 37/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 904ms/step - accuracy: 1.0000 - loss: 9.2458e-04 - val_accuracy: 0.8947 - val_loss: 0.4643\n",
            "Epoch 38/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 912ms/step - accuracy: 1.0000 - loss: 8.9820e-04 - val_accuracy: 0.8995 - val_loss: 0.4682\n",
            "Epoch 39/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 8.3165e-04 - val_accuracy: 0.9043 - val_loss: 0.4785\n",
            "Epoch 40/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 7.7143e-04 - val_accuracy: 0.8947 - val_loss: 0.4805\n",
            "Epoch 41/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 937ms/step - accuracy: 1.0000 - loss: 5.8257e-04 - val_accuracy: 0.8947 - val_loss: 0.4868\n",
            "Epoch 42/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 907ms/step - accuracy: 1.0000 - loss: 6.0186e-04 - val_accuracy: 0.9043 - val_loss: 0.4916\n",
            "Epoch 43/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 886ms/step - accuracy: 1.0000 - loss: 5.6917e-04 - val_accuracy: 0.8995 - val_loss: 0.4966\n",
            "Epoch 44/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 899ms/step - accuracy: 1.0000 - loss: 4.8772e-04 - val_accuracy: 0.8995 - val_loss: 0.5101\n",
            "Epoch 45/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.7961e-04 - val_accuracy: 0.8995 - val_loss: 0.5078\n",
            "Epoch 46/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.5556e-04 - val_accuracy: 0.8995 - val_loss: 0.5117\n",
            "Epoch 47/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 931ms/step - accuracy: 1.0000 - loss: 3.4287e-04 - val_accuracy: 0.9043 - val_loss: 0.5213\n",
            "Epoch 48/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.4287e-04 - val_accuracy: 0.8947 - val_loss: 0.5246\n",
            "Epoch 49/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.8031e-04 - val_accuracy: 0.9091 - val_loss: 0.5345\n",
            "Epoch 50/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.8855e-04 - val_accuracy: 0.9043 - val_loss: 0.5375\n",
            "Epoch 51/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 930ms/step - accuracy: 1.0000 - loss: 2.4585e-04 - val_accuracy: 0.9043 - val_loss: 0.5436\n",
            "Epoch 52/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 898ms/step - accuracy: 1.0000 - loss: 2.1935e-04 - val_accuracy: 0.8995 - val_loss: 0.5465\n",
            "Epoch 53/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 898ms/step - accuracy: 1.0000 - loss: 1.7978e-04 - val_accuracy: 0.8995 - val_loss: 0.5536\n",
            "Epoch 54/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 915ms/step - accuracy: 1.0000 - loss: 1.7752e-04 - val_accuracy: 0.9043 - val_loss: 0.5606\n",
            "Epoch 55/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 903ms/step - accuracy: 1.0000 - loss: 1.5449e-04 - val_accuracy: 0.9043 - val_loss: 0.5642\n",
            "Epoch 56/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 904ms/step - accuracy: 1.0000 - loss: 1.7139e-04 - val_accuracy: 0.9091 - val_loss: 0.5675\n",
            "Epoch 57/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 936ms/step - accuracy: 1.0000 - loss: 1.4591e-04 - val_accuracy: 0.9091 - val_loss: 0.5757\n",
            "Epoch 58/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.3808e-04 - val_accuracy: 0.9091 - val_loss: 0.5822\n",
            "Epoch 59/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 988ms/step - accuracy: 1.0000 - loss: 1.2525e-04 - val_accuracy: 0.9043 - val_loss: 0.5847\n",
            "Epoch 60/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.1355e-04 - val_accuracy: 0.9043 - val_loss: 0.5887\n",
            "Epoch 61/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 920ms/step - accuracy: 1.0000 - loss: 1.0186e-04 - val_accuracy: 0.9091 - val_loss: 0.5919\n",
            "Epoch 62/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 946ms/step - accuracy: 1.0000 - loss: 9.0223e-05 - val_accuracy: 0.9091 - val_loss: 0.5963\n",
            "Epoch 63/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.0598e-05 - val_accuracy: 0.9043 - val_loss: 0.6047\n",
            "Epoch 64/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 933ms/step - accuracy: 1.0000 - loss: 9.5828e-05 - val_accuracy: 0.9043 - val_loss: 0.6066\n",
            "Epoch 65/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 898ms/step - accuracy: 1.0000 - loss: 7.8384e-05 - val_accuracy: 0.9043 - val_loss: 0.6113\n",
            "Epoch 66/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 923ms/step - accuracy: 1.0000 - loss: 6.9618e-05 - val_accuracy: 0.9091 - val_loss: 0.6142\n",
            "Epoch 67/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 900ms/step - accuracy: 1.0000 - loss: 6.9267e-05 - val_accuracy: 0.9043 - val_loss: 0.6222\n",
            "Epoch 68/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 908ms/step - accuracy: 1.0000 - loss: 6.5150e-05 - val_accuracy: 0.9091 - val_loss: 0.6224\n",
            "Epoch 69/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.2135e-05 - val_accuracy: 0.9043 - val_loss: 0.6270\n",
            "Epoch 70/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.1692e-05 - val_accuracy: 0.9043 - val_loss: 0.6340\n",
            "Epoch 71/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 914ms/step - accuracy: 1.0000 - loss: 5.5984e-05 - val_accuracy: 0.9043 - val_loss: 0.6357\n",
            "Epoch 72/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 898ms/step - accuracy: 1.0000 - loss: 5.2262e-05 - val_accuracy: 0.9043 - val_loss: 0.6376\n",
            "Epoch 73/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 908ms/step - accuracy: 1.0000 - loss: 5.3404e-05 - val_accuracy: 0.9043 - val_loss: 0.6436\n",
            "Epoch 74/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.3187e-05 - val_accuracy: 0.9043 - val_loss: 0.6481\n",
            "Epoch 75/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 932ms/step - accuracy: 1.0000 - loss: 4.9074e-05 - val_accuracy: 0.8995 - val_loss: 0.6518\n",
            "Epoch 76/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 922ms/step - accuracy: 1.0000 - loss: 4.5048e-05 - val_accuracy: 0.9043 - val_loss: 0.6543\n",
            "Epoch 77/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.1700e-05 - val_accuracy: 0.9043 - val_loss: 0.6583\n",
            "Epoch 78/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.1112e-05 - val_accuracy: 0.9043 - val_loss: 0.6606\n",
            "Epoch 79/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 932ms/step - accuracy: 1.0000 - loss: 3.9025e-05 - val_accuracy: 0.9043 - val_loss: 0.6638\n",
            "Epoch 80/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 908ms/step - accuracy: 1.0000 - loss: 3.5396e-05 - val_accuracy: 0.9043 - val_loss: 0.6721\n",
            "Epoch 81/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 891ms/step - accuracy: 1.0000 - loss: 3.2942e-05 - val_accuracy: 0.9043 - val_loss: 0.6694\n",
            "Epoch 82/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 926ms/step - accuracy: 1.0000 - loss: 3.1904e-05 - val_accuracy: 0.9043 - val_loss: 0.6774\n",
            "Epoch 83/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 908ms/step - accuracy: 1.0000 - loss: 3.0239e-05 - val_accuracy: 0.8995 - val_loss: 0.6779\n",
            "Epoch 84/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 926ms/step - accuracy: 1.0000 - loss: 2.4347e-05 - val_accuracy: 0.9043 - val_loss: 0.6785\n",
            "Epoch 85/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 891ms/step - accuracy: 1.0000 - loss: 3.0076e-05 - val_accuracy: 0.8995 - val_loss: 0.6873\n",
            "Epoch 86/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.5989e-05 - val_accuracy: 0.8995 - val_loss: 0.6893\n",
            "Epoch 87/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.6929e-05 - val_accuracy: 0.9043 - val_loss: 0.6882\n",
            "Epoch 88/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 927ms/step - accuracy: 1.0000 - loss: 2.5494e-05 - val_accuracy: 0.9043 - val_loss: 0.6922\n",
            "Epoch 89/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 927ms/step - accuracy: 1.0000 - loss: 2.7497e-05 - val_accuracy: 0.8995 - val_loss: 0.6990\n",
            "Epoch 90/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.4485e-05 - val_accuracy: 0.9043 - val_loss: 0.6960\n",
            "Epoch 91/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 943ms/step - accuracy: 1.0000 - loss: 2.3014e-05 - val_accuracy: 0.9043 - val_loss: 0.7002\n",
            "Epoch 92/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 906ms/step - accuracy: 1.0000 - loss: 2.1462e-05 - val_accuracy: 0.8995 - val_loss: 0.7043\n",
            "Epoch 93/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 926ms/step - accuracy: 1.0000 - loss: 1.9551e-05 - val_accuracy: 0.9043 - val_loss: 0.7017\n",
            "Epoch 94/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 893ms/step - accuracy: 1.0000 - loss: 1.8538e-05 - val_accuracy: 0.9043 - val_loss: 0.7126\n",
            "Epoch 95/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 888ms/step - accuracy: 1.0000 - loss: 2.1674e-05 - val_accuracy: 0.9043 - val_loss: 0.7085\n",
            "Epoch 96/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 879ms/step - accuracy: 1.0000 - loss: 1.7865e-05 - val_accuracy: 0.9043 - val_loss: 0.7140\n",
            "Epoch 97/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 949ms/step - accuracy: 1.0000 - loss: 1.7697e-05 - val_accuracy: 0.9043 - val_loss: 0.7148\n",
            "Epoch 98/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 895ms/step - accuracy: 1.0000 - loss: 1.7589e-05 - val_accuracy: 0.8995 - val_loss: 0.7218\n",
            "Epoch 99/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 847ms/step - accuracy: 1.0000 - loss: 1.6665e-05 - val_accuracy: 0.8995 - val_loss: 0.7237\n",
            "Epoch 100/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 857ms/step - accuracy: 1.0000 - loss: 1.6287e-05 - val_accuracy: 0.9043 - val_loss: 0.7213\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9s/step\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.8648 - loss: 0.7745\n",
            "Test Accuracy: 0.8658\n",
            "F1 Score: 0.9034\n",
            "G-Mean: 0.8347\n",
            "Informedness (IBA): 0.6759\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "**Magnification Factor: 200X**\n",
        "***"
      ],
      "metadata": {
        "id": "xOI_VYRptgFF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, concatenate, AveragePooling2D, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "\n",
        "# Define dataset paths\n",
        "benign_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/benign/200X\"\n",
        "malignant_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/malignant/200X\"\n",
        "\n",
        "def load_image_paths(dir_path):\n",
        "    return [os.path.join(dir_path, img) for img in os.listdir(dir_path) if img.endswith('.png')]\n",
        "\n",
        "benign_images = load_image_paths(benign_dir)\n",
        "malignant_images = load_image_paths(malignant_dir)\n",
        "\n",
        "print(f\"Total Benign Images: {len(benign_images)}\")\n",
        "print(f\"Total Malignant Images: {len(malignant_images)}\")\n",
        "\n",
        "benign_labels = [0] * len(benign_images)\n",
        "malignant_labels = [1] * len(malignant_images)\n",
        "\n",
        "all_images = np.array(benign_images + malignant_images)\n",
        "all_labels = np.array(benign_labels + malignant_labels)\n",
        "\n",
        "# Split dataset (60% train, 10% val, 30% test)\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(\n",
        "    all_images, all_labels, test_size=0.3, stratify=all_labels, random_state=42)\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(\n",
        "    train_images, train_labels, test_size=0.1429, stratify=train_labels, random_state=42)\n",
        "\n",
        "print(f\"Training samples: {len(train_images)}\")\n",
        "print(f\"Validation samples: {len(val_images)}\")\n",
        "print(f\"Testing samples: {len(test_images)}\")\n",
        "\n",
        "def process_path(file_path, label):\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_png(img, channels=3)\n",
        "    img = tf.image.resize(img, [224, 224])\n",
        "    img = img / 255.0\n",
        "    return img, label\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).map(process_path).shuffle(1000).batch(BATCH_SIZE)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels)).map(process_path).batch(BATCH_SIZE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).map(process_path).batch(BATCH_SIZE)\n",
        "\n",
        "if sum(1 for _ in test_dataset) == 0:\n",
        "    raise ValueError(\"Testing dataset is empty. Adjust your dataset split.\")\n",
        "\n",
        "# Load VGG16 without top layers\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "def inception_block(x):\n",
        "    branch1 = Conv2D(64, (1, 1), activation='relu', padding='same')(x)\n",
        "\n",
        "    branch2 = Conv2D(64, (1, 1), activation='relu', padding='same')(x)\n",
        "    branch2 = Conv2D(128, (3, 3), activation='relu', padding='same')(branch2)\n",
        "\n",
        "    branch3 = Conv2D(64, (1, 1), activation='relu', padding='same')(x)\n",
        "    branch3 = Conv2D(128, (5, 5), activation='relu', padding='same')(branch3)\n",
        "\n",
        "    branch4 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "    branch4 = Conv2D(64, (1, 1), activation='relu', padding='same')(branch4)\n",
        "\n",
        "    output = concatenate([branch1, branch2, branch3, branch4], axis=-1)\n",
        "    return output\n",
        "\n",
        "# Add Inception block after VGG16\n",
        "x = inception_block(base_model.output)\n",
        "x = AveragePooling2D(pool_size=(2, 2))(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "EPOCHS = 100\n",
        "history = model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS)\n",
        "\n",
        "test_preds = model.predict(test_dataset)\n",
        "test_preds = (test_preds > 0.5).astype(int).flatten()\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(test_labels, test_preds).ravel()\n",
        "iba = (tp / (tp + fn)) + (tn / (tn + fp)) - 1\n",
        "\n",
        "f1 = f1_score(test_labels, test_preds)\n",
        "gmean = geometric_mean_score(test_labels, test_preds)\n",
        "\n",
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"G-Mean: {gmean:.4f}\")\n",
        "print(f\"Informedness (IBA): {iba:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jg4ss6rhrZ6i",
        "outputId": "3e9ae635-583d-4bdc-93a8-3a89d9bdec86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Benign Images: 623\n",
            "Total Malignant Images: 1390\n",
            "Training samples: 1207\n",
            "Validation samples: 202\n",
            "Testing samples: 604\n",
            "Epoch 1/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 13s/step - accuracy: 0.6067 - loss: 0.8259 - val_accuracy: 0.6881 - val_loss: 0.6153\n",
            "Epoch 2/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 775ms/step - accuracy: 0.6914 - loss: 0.6017 - val_accuracy: 0.6881 - val_loss: 0.5767\n",
            "Epoch 3/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 788ms/step - accuracy: 0.6948 - loss: 0.5619 - val_accuracy: 0.7228 - val_loss: 0.5243\n",
            "Epoch 4/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 788ms/step - accuracy: 0.7715 - loss: 0.4860 - val_accuracy: 0.8069 - val_loss: 0.4833\n",
            "Epoch 5/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 817ms/step - accuracy: 0.8205 - loss: 0.4328 - val_accuracy: 0.7673 - val_loss: 0.4318\n",
            "Epoch 6/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.8412 - loss: 0.3654 - val_accuracy: 0.7772 - val_loss: 0.4238\n",
            "Epoch 7/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 769ms/step - accuracy: 0.8466 - loss: 0.3319 - val_accuracy: 0.8168 - val_loss: 0.3715\n",
            "Epoch 8/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 788ms/step - accuracy: 0.8769 - loss: 0.3019 - val_accuracy: 0.8317 - val_loss: 0.4042\n",
            "Epoch 9/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 778ms/step - accuracy: 0.8680 - loss: 0.2808 - val_accuracy: 0.7723 - val_loss: 0.4809\n",
            "Epoch 10/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 818ms/step - accuracy: 0.8627 - loss: 0.3190 - val_accuracy: 0.8267 - val_loss: 0.3760\n",
            "Epoch 11/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 786ms/step - accuracy: 0.9068 - loss: 0.2269 - val_accuracy: 0.8366 - val_loss: 0.3388\n",
            "Epoch 12/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 788ms/step - accuracy: 0.9390 - loss: 0.1757 - val_accuracy: 0.8515 - val_loss: 0.3587\n",
            "Epoch 13/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 791ms/step - accuracy: 0.9252 - loss: 0.1867 - val_accuracy: 0.8366 - val_loss: 0.3893\n",
            "Epoch 14/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 809ms/step - accuracy: 0.9420 - loss: 0.1526 - val_accuracy: 0.8762 - val_loss: 0.3336\n",
            "Epoch 15/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 813ms/step - accuracy: 0.9630 - loss: 0.1173 - val_accuracy: 0.8614 - val_loss: 0.3384\n",
            "Epoch 16/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 795ms/step - accuracy: 0.9786 - loss: 0.0805 - val_accuracy: 0.8663 - val_loss: 0.3543\n",
            "Epoch 17/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 820ms/step - accuracy: 0.9815 - loss: 0.0810 - val_accuracy: 0.8663 - val_loss: 0.3673\n",
            "Epoch 18/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 801ms/step - accuracy: 0.9932 - loss: 0.0525 - val_accuracy: 0.8416 - val_loss: 0.4369\n",
            "Epoch 19/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 858ms/step - accuracy: 0.9902 - loss: 0.0420 - val_accuracy: 0.8614 - val_loss: 0.4166\n",
            "Epoch 20/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 882ms/step - accuracy: 0.9968 - loss: 0.0314 - val_accuracy: 0.8713 - val_loss: 0.4073\n",
            "Epoch 21/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 898ms/step - accuracy: 0.9973 - loss: 0.0277 - val_accuracy: 0.8614 - val_loss: 0.4477\n",
            "Epoch 22/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 913ms/step - accuracy: 1.0000 - loss: 0.0183 - val_accuracy: 0.8614 - val_loss: 0.4720\n",
            "Epoch 23/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 855ms/step - accuracy: 0.9996 - loss: 0.0171 - val_accuracy: 0.8366 - val_loss: 0.5067\n",
            "Epoch 24/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 817ms/step - accuracy: 1.0000 - loss: 0.0109 - val_accuracy: 0.8515 - val_loss: 0.5143\n",
            "Epoch 25/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 833ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.8515 - val_loss: 0.5380\n",
            "Epoch 26/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 868ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.8614 - val_loss: 0.5592\n",
            "Epoch 27/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 828ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.8614 - val_loss: 0.5773\n",
            "Epoch 28/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.8614 - val_loss: 0.6052\n",
            "Epoch 29/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 855ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.8614 - val_loss: 0.6178\n",
            "Epoch 30/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 921ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.8614 - val_loss: 0.6294\n",
            "Epoch 31/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 836ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.8614 - val_loss: 0.6473\n",
            "Epoch 32/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 858ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.8663 - val_loss: 0.6821\n",
            "Epoch 33/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 887ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.8614 - val_loss: 0.6775\n",
            "Epoch 34/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.8614 - val_loss: 0.6730\n",
            "Epoch 35/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 812ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.8515 - val_loss: 0.6835\n",
            "Epoch 36/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 879ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.8515 - val_loss: 0.6877\n",
            "Epoch 37/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 847ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.8614 - val_loss: 0.7030\n",
            "Epoch 38/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.2145e-04 - val_accuracy: 0.8614 - val_loss: 0.7106\n",
            "Epoch 39/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 800ms/step - accuracy: 1.0000 - loss: 8.2391e-04 - val_accuracy: 0.8614 - val_loss: 0.7216\n",
            "Epoch 40/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 820ms/step - accuracy: 1.0000 - loss: 7.1621e-04 - val_accuracy: 0.8564 - val_loss: 0.7272\n",
            "Epoch 41/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 876ms/step - accuracy: 1.0000 - loss: 6.9786e-04 - val_accuracy: 0.8614 - val_loss: 0.7434\n",
            "Epoch 42/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 896ms/step - accuracy: 1.0000 - loss: 6.6095e-04 - val_accuracy: 0.8614 - val_loss: 0.7581\n",
            "Epoch 43/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 891ms/step - accuracy: 1.0000 - loss: 6.0754e-04 - val_accuracy: 0.8614 - val_loss: 0.7632\n",
            "Epoch 44/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 889ms/step - accuracy: 1.0000 - loss: 5.2371e-04 - val_accuracy: 0.8614 - val_loss: 0.7620\n",
            "Epoch 45/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 850ms/step - accuracy: 1.0000 - loss: 4.7526e-04 - val_accuracy: 0.8614 - val_loss: 0.7709\n",
            "Epoch 46/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 805ms/step - accuracy: 1.0000 - loss: 4.4441e-04 - val_accuracy: 0.8515 - val_loss: 0.7752\n",
            "Epoch 47/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 861ms/step - accuracy: 1.0000 - loss: 3.8355e-04 - val_accuracy: 0.8614 - val_loss: 0.7971\n",
            "Epoch 48/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 864ms/step - accuracy: 1.0000 - loss: 3.9953e-04 - val_accuracy: 0.8614 - val_loss: 0.8059\n",
            "Epoch 49/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 808ms/step - accuracy: 1.0000 - loss: 3.3783e-04 - val_accuracy: 0.8614 - val_loss: 0.8105\n",
            "Epoch 50/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 804ms/step - accuracy: 1.0000 - loss: 3.2018e-04 - val_accuracy: 0.8614 - val_loss: 0.8102\n",
            "Epoch 51/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 910ms/step - accuracy: 1.0000 - loss: 3.4859e-04 - val_accuracy: 0.8564 - val_loss: 0.8109\n",
            "Epoch 52/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 946ms/step - accuracy: 1.0000 - loss: 3.0940e-04 - val_accuracy: 0.8614 - val_loss: 0.8256\n",
            "Epoch 53/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 852ms/step - accuracy: 1.0000 - loss: 2.7682e-04 - val_accuracy: 0.8564 - val_loss: 0.8270\n",
            "Epoch 54/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 885ms/step - accuracy: 1.0000 - loss: 2.4480e-04 - val_accuracy: 0.8564 - val_loss: 0.8314\n",
            "Epoch 55/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 874ms/step - accuracy: 1.0000 - loss: 2.2570e-04 - val_accuracy: 0.8614 - val_loss: 0.8468\n",
            "Epoch 56/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 878ms/step - accuracy: 1.0000 - loss: 2.2138e-04 - val_accuracy: 0.8614 - val_loss: 0.8538\n",
            "Epoch 57/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 858ms/step - accuracy: 1.0000 - loss: 2.0764e-04 - val_accuracy: 0.8614 - val_loss: 0.8589\n",
            "Epoch 58/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 826ms/step - accuracy: 1.0000 - loss: 1.9653e-04 - val_accuracy: 0.8564 - val_loss: 0.8606\n",
            "Epoch 59/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 869ms/step - accuracy: 1.0000 - loss: 1.8345e-04 - val_accuracy: 0.8564 - val_loss: 0.8731\n",
            "Epoch 60/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 867ms/step - accuracy: 1.0000 - loss: 1.8320e-04 - val_accuracy: 0.8564 - val_loss: 0.8751\n",
            "Epoch 61/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 826ms/step - accuracy: 1.0000 - loss: 1.7149e-04 - val_accuracy: 0.8564 - val_loss: 0.8764\n",
            "Epoch 62/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 818ms/step - accuracy: 1.0000 - loss: 1.8268e-04 - val_accuracy: 0.8564 - val_loss: 0.8768\n",
            "Epoch 63/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 872ms/step - accuracy: 1.0000 - loss: 1.6685e-04 - val_accuracy: 0.8564 - val_loss: 0.8806\n",
            "Epoch 64/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 821ms/step - accuracy: 1.0000 - loss: 1.5273e-04 - val_accuracy: 0.8663 - val_loss: 0.9038\n",
            "Epoch 65/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 858ms/step - accuracy: 1.0000 - loss: 1.5025e-04 - val_accuracy: 0.8713 - val_loss: 0.9185\n",
            "Epoch 66/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 863ms/step - accuracy: 1.0000 - loss: 1.4584e-04 - val_accuracy: 0.8564 - val_loss: 0.9003\n",
            "Epoch 67/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 851ms/step - accuracy: 1.0000 - loss: 1.2548e-04 - val_accuracy: 0.8663 - val_loss: 0.9080\n",
            "Epoch 68/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 881ms/step - accuracy: 1.0000 - loss: 1.1388e-04 - val_accuracy: 0.8663 - val_loss: 0.9209\n",
            "Epoch 69/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 863ms/step - accuracy: 1.0000 - loss: 1.1113e-04 - val_accuracy: 0.8564 - val_loss: 0.9126\n",
            "Epoch 70/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 811ms/step - accuracy: 1.0000 - loss: 1.1351e-04 - val_accuracy: 0.8564 - val_loss: 0.9219\n",
            "Epoch 71/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 834ms/step - accuracy: 1.0000 - loss: 9.6473e-05 - val_accuracy: 0.8564 - val_loss: 0.9196\n",
            "Epoch 72/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 815ms/step - accuracy: 1.0000 - loss: 9.9067e-05 - val_accuracy: 0.8663 - val_loss: 0.9443\n",
            "Epoch 73/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 818ms/step - accuracy: 1.0000 - loss: 1.0389e-04 - val_accuracy: 0.8614 - val_loss: 0.9375\n",
            "Epoch 74/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 859ms/step - accuracy: 1.0000 - loss: 8.9945e-05 - val_accuracy: 0.8564 - val_loss: 0.9279\n",
            "Epoch 75/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 860ms/step - accuracy: 1.0000 - loss: 9.8839e-05 - val_accuracy: 0.8663 - val_loss: 0.9543\n",
            "Epoch 76/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 7.6569e-05 - val_accuracy: 0.8614 - val_loss: 0.9489\n",
            "Epoch 77/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 815ms/step - accuracy: 1.0000 - loss: 7.1464e-05 - val_accuracy: 0.8564 - val_loss: 0.9471\n",
            "Epoch 78/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 823ms/step - accuracy: 1.0000 - loss: 7.9822e-05 - val_accuracy: 0.8614 - val_loss: 0.9594\n",
            "Epoch 79/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 873ms/step - accuracy: 1.0000 - loss: 7.3337e-05 - val_accuracy: 0.8614 - val_loss: 0.9666\n",
            "Epoch 80/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 924ms/step - accuracy: 1.0000 - loss: 6.3032e-05 - val_accuracy: 0.8564 - val_loss: 0.9564\n",
            "Epoch 81/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 864ms/step - accuracy: 1.0000 - loss: 7.8009e-05 - val_accuracy: 0.8663 - val_loss: 0.9761\n",
            "Epoch 82/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 894ms/step - accuracy: 1.0000 - loss: 6.4943e-05 - val_accuracy: 0.8614 - val_loss: 0.9727\n",
            "Epoch 83/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 921ms/step - accuracy: 1.0000 - loss: 6.3298e-05 - val_accuracy: 0.8614 - val_loss: 0.9708\n",
            "Epoch 84/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.4811e-05 - val_accuracy: 0.8614 - val_loss: 0.9856\n",
            "Epoch 85/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 804ms/step - accuracy: 1.0000 - loss: 5.4627e-05 - val_accuracy: 0.8614 - val_loss: 0.9801\n",
            "Epoch 86/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 856ms/step - accuracy: 1.0000 - loss: 5.3447e-05 - val_accuracy: 0.8614 - val_loss: 0.9831\n",
            "Epoch 87/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 824ms/step - accuracy: 1.0000 - loss: 5.8017e-05 - val_accuracy: 0.8614 - val_loss: 0.9884\n",
            "Epoch 88/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 929ms/step - accuracy: 1.0000 - loss: 5.0329e-05 - val_accuracy: 0.8614 - val_loss: 1.0023\n",
            "Epoch 89/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 803ms/step - accuracy: 1.0000 - loss: 4.7453e-05 - val_accuracy: 0.8614 - val_loss: 0.9961\n",
            "Epoch 90/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 859ms/step - accuracy: 1.0000 - loss: 4.7487e-05 - val_accuracy: 0.8614 - val_loss: 1.0030\n",
            "Epoch 91/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 806ms/step - accuracy: 1.0000 - loss: 4.3885e-05 - val_accuracy: 0.8614 - val_loss: 1.0031\n",
            "Epoch 92/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 865ms/step - accuracy: 1.0000 - loss: 4.4879e-05 - val_accuracy: 0.8614 - val_loss: 1.0088\n",
            "Epoch 93/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 853ms/step - accuracy: 1.0000 - loss: 4.2993e-05 - val_accuracy: 0.8614 - val_loss: 1.0111\n",
            "Epoch 94/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 859ms/step - accuracy: 1.0000 - loss: 3.8221e-05 - val_accuracy: 0.8614 - val_loss: 1.0106\n",
            "Epoch 95/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 861ms/step - accuracy: 1.0000 - loss: 4.3393e-05 - val_accuracy: 0.8614 - val_loss: 1.0218\n",
            "Epoch 96/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 880ms/step - accuracy: 1.0000 - loss: 3.8445e-05 - val_accuracy: 0.8614 - val_loss: 1.0200\n",
            "Epoch 97/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 905ms/step - accuracy: 1.0000 - loss: 3.8165e-05 - val_accuracy: 0.8614 - val_loss: 1.0241\n",
            "Epoch 98/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 885ms/step - accuracy: 1.0000 - loss: 3.7824e-05 - val_accuracy: 0.8614 - val_loss: 1.0269\n",
            "Epoch 99/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 845ms/step - accuracy: 1.0000 - loss: 3.2625e-05 - val_accuracy: 0.8614 - val_loss: 1.0267\n",
            "Epoch 100/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 824ms/step - accuracy: 1.0000 - loss: 3.5195e-05 - val_accuracy: 0.8614 - val_loss: 1.0322\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7e00da77b6a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7e00da77b6a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 8s/step\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.8696 - loss: 0.9011\n",
            "Test Accuracy: 0.8742\n",
            "F1 Score: 0.9100\n",
            "G-Mean: 0.8421\n",
            "Informedness (IBA): 0.6909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "**Magnification Factor: 400X**\n",
        "***"
      ],
      "metadata": {
        "id": "Uk934eexthsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, concatenate, AveragePooling2D, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "\n",
        "# Define dataset paths\n",
        "benign_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/benign/400X\"\n",
        "malignant_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/malignant/400X\"\n",
        "\n",
        "def load_image_paths(dir_path):\n",
        "    return [os.path.join(dir_path, img) for img in os.listdir(dir_path) if img.endswith('.png')]\n",
        "\n",
        "benign_images = load_image_paths(benign_dir)\n",
        "malignant_images = load_image_paths(malignant_dir)\n",
        "\n",
        "print(f\"Total Benign Images: {len(benign_images)}\")\n",
        "print(f\"Total Malignant Images: {len(malignant_images)}\")\n",
        "\n",
        "benign_labels = [0] * len(benign_images)\n",
        "malignant_labels = [1] * len(malignant_images)\n",
        "\n",
        "all_images = np.array(benign_images + malignant_images)\n",
        "all_labels = np.array(benign_labels + malignant_labels)\n",
        "\n",
        "# Split dataset (60% train, 10% val, 30% test)\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(\n",
        "    all_images, all_labels, test_size=0.3, stratify=all_labels, random_state=42)\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(\n",
        "    train_images, train_labels, test_size=0.1429, stratify=train_labels, random_state=42)\n",
        "\n",
        "print(f\"Training samples: {len(train_images)}\")\n",
        "print(f\"Validation samples: {len(val_images)}\")\n",
        "print(f\"Testing samples: {len(test_images)}\")\n",
        "\n",
        "def process_path(file_path, label):\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_png(img, channels=3)\n",
        "    img = tf.image.resize(img, [224, 224])\n",
        "    img = img / 255.0\n",
        "    return img, label\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).map(process_path).shuffle(1000).batch(BATCH_SIZE)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels)).map(process_path).batch(BATCH_SIZE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).map(process_path).batch(BATCH_SIZE)\n",
        "\n",
        "if sum(1 for _ in test_dataset) == 0:\n",
        "    raise ValueError(\"Testing dataset is empty. Adjust your dataset split.\")\n",
        "\n",
        "# Load VGG16 without top layers\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "def inception_block(x):\n",
        "    branch1 = Conv2D(64, (1, 1), activation='relu', padding='same')(x)\n",
        "\n",
        "    branch2 = Conv2D(64, (1, 1), activation='relu', padding='same')(x)\n",
        "    branch2 = Conv2D(128, (3, 3), activation='relu', padding='same')(branch2)\n",
        "\n",
        "    branch3 = Conv2D(64, (1, 1), activation='relu', padding='same')(x)\n",
        "    branch3 = Conv2D(128, (5, 5), activation='relu', padding='same')(branch3)\n",
        "\n",
        "    branch4 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "    branch4 = Conv2D(64, (1, 1), activation='relu', padding='same')(branch4)\n",
        "\n",
        "    output = concatenate([branch1, branch2, branch3, branch4], axis=-1)\n",
        "    return output\n",
        "\n",
        "# Add Inception block after VGG16\n",
        "x = inception_block(base_model.output)\n",
        "x = AveragePooling2D(pool_size=(2, 2))(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "EPOCHS = 100\n",
        "history = model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS)\n",
        "\n",
        "test_preds = model.predict(test_dataset)\n",
        "test_preds = (test_preds > 0.5).astype(int).flatten()\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(test_labels, test_preds).ravel()\n",
        "iba = (tp / (tp + fn)) + (tn / (tn + fp)) - 1\n",
        "\n",
        "f1 = f1_score(test_labels, test_preds)\n",
        "gmean = geometric_mean_score(test_labels, test_preds)\n",
        "\n",
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"G-Mean: {gmean:.4f}\")\n",
        "print(f\"Informedness (IBA): {iba:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QW3Hiqqvraz4",
        "outputId": "897b388a-2ed5-44f2-d633-c7537029d15f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Benign Images: 588\n",
            "Total Malignant Images: 1232\n",
            "Training samples: 1091\n",
            "Validation samples: 183\n",
            "Testing samples: 546\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 7s/step - accuracy: 0.5317 - loss: 0.9610 - val_accuracy: 0.6776 - val_loss: 0.6309\n",
            "Epoch 2/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 1s/step - accuracy: 0.6745 - loss: 0.6338 - val_accuracy: 0.6776 - val_loss: 0.6150\n",
            "Epoch 3/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 795ms/step - accuracy: 0.6691 - loss: 0.6111 - val_accuracy: 0.6776 - val_loss: 0.5851\n",
            "Epoch 4/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 826ms/step - accuracy: 0.6855 - loss: 0.5692 - val_accuracy: 0.7541 - val_loss: 0.5362\n",
            "Epoch 5/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 901ms/step - accuracy: 0.7435 - loss: 0.5358 - val_accuracy: 0.7978 - val_loss: 0.4833\n",
            "Epoch 6/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - accuracy: 0.7929 - loss: 0.4547 - val_accuracy: 0.8033 - val_loss: 0.4348\n",
            "Epoch 7/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 880ms/step - accuracy: 0.8036 - loss: 0.4315 - val_accuracy: 0.8197 - val_loss: 0.4201\n",
            "Epoch 8/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 824ms/step - accuracy: 0.8448 - loss: 0.3878 - val_accuracy: 0.8251 - val_loss: 0.3823\n",
            "Epoch 9/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 922ms/step - accuracy: 0.8470 - loss: 0.3410 - val_accuracy: 0.8306 - val_loss: 0.3962\n",
            "Epoch 10/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 804ms/step - accuracy: 0.8668 - loss: 0.3362 - val_accuracy: 0.8251 - val_loss: 0.3768\n",
            "Epoch 11/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 799ms/step - accuracy: 0.8887 - loss: 0.2734 - val_accuracy: 0.8525 - val_loss: 0.3304\n",
            "Epoch 12/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.9184 - loss: 0.2199 - val_accuracy: 0.8634 - val_loss: 0.3116\n",
            "Epoch 13/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 812ms/step - accuracy: 0.9275 - loss: 0.1930 - val_accuracy: 0.8197 - val_loss: 0.3760\n",
            "Epoch 14/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 826ms/step - accuracy: 0.9206 - loss: 0.1860 - val_accuracy: 0.8470 - val_loss: 0.3426\n",
            "Epoch 15/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 898ms/step - accuracy: 0.9404 - loss: 0.1527 - val_accuracy: 0.8579 - val_loss: 0.3048\n",
            "Epoch 16/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 796ms/step - accuracy: 0.9808 - loss: 0.0902 - val_accuracy: 0.8689 - val_loss: 0.3109\n",
            "Epoch 17/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 0.9844 - loss: 0.0719 - val_accuracy: 0.8907 - val_loss: 0.3309\n",
            "Epoch 18/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 829ms/step - accuracy: 0.9887 - loss: 0.0557 - val_accuracy: 0.8579 - val_loss: 0.3887\n",
            "Epoch 19/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 895ms/step - accuracy: 0.9918 - loss: 0.0468 - val_accuracy: 0.8852 - val_loss: 0.3448\n",
            "Epoch 20/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 815ms/step - accuracy: 0.9985 - loss: 0.0302 - val_accuracy: 0.8579 - val_loss: 0.3906\n",
            "Epoch 21/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 804ms/step - accuracy: 0.9993 - loss: 0.0293 - val_accuracy: 0.8743 - val_loss: 0.3720\n",
            "Epoch 22/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0129 - val_accuracy: 0.8798 - val_loss: 0.3837\n",
            "Epoch 23/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 824ms/step - accuracy: 1.0000 - loss: 0.0103 - val_accuracy: 0.8798 - val_loss: 0.3965\n",
            "Epoch 24/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 819ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.8689 - val_loss: 0.4010\n",
            "Epoch 25/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 928ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.8689 - val_loss: 0.4174\n",
            "Epoch 26/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 880ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.8743 - val_loss: 0.4339\n",
            "Epoch 27/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 941ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.8798 - val_loss: 0.4398\n",
            "Epoch 28/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 889ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.8798 - val_loss: 0.4623\n",
            "Epoch 29/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 889ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.8634 - val_loss: 0.4697\n",
            "Epoch 30/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 809ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.8852 - val_loss: 0.4782\n",
            "Epoch 31/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 948ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.8798 - val_loss: 0.4745\n",
            "Epoch 32/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 898ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.8743 - val_loss: 0.4840\n",
            "Epoch 33/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 933ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.8634 - val_loss: 0.5009\n",
            "Epoch 34/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 799ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.8689 - val_loss: 0.5097\n",
            "Epoch 35/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 877ms/step - accuracy: 1.0000 - loss: 8.3724e-04 - val_accuracy: 0.8798 - val_loss: 0.5112\n",
            "Epoch 36/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 906ms/step - accuracy: 1.0000 - loss: 8.9811e-04 - val_accuracy: 0.8689 - val_loss: 0.5151\n",
            "Epoch 37/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 819ms/step - accuracy: 1.0000 - loss: 6.9970e-04 - val_accuracy: 0.8798 - val_loss: 0.5222\n",
            "Epoch 38/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 872ms/step - accuracy: 1.0000 - loss: 6.4043e-04 - val_accuracy: 0.8798 - val_loss: 0.5292\n",
            "Epoch 39/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 886ms/step - accuracy: 1.0000 - loss: 6.0259e-04 - val_accuracy: 0.8743 - val_loss: 0.5418\n",
            "Epoch 40/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 889ms/step - accuracy: 1.0000 - loss: 5.4091e-04 - val_accuracy: 0.8798 - val_loss: 0.5407\n",
            "Epoch 41/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 901ms/step - accuracy: 1.0000 - loss: 4.5595e-04 - val_accuracy: 0.8743 - val_loss: 0.5469\n",
            "Epoch 42/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 953ms/step - accuracy: 1.0000 - loss: 3.7511e-04 - val_accuracy: 0.8798 - val_loss: 0.5507\n",
            "Epoch 43/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 880ms/step - accuracy: 1.0000 - loss: 3.3100e-04 - val_accuracy: 0.8743 - val_loss: 0.5652\n",
            "Epoch 44/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 946ms/step - accuracy: 1.0000 - loss: 3.3510e-04 - val_accuracy: 0.8525 - val_loss: 0.5681\n",
            "Epoch 45/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 825ms/step - accuracy: 1.0000 - loss: 3.0021e-04 - val_accuracy: 0.8743 - val_loss: 0.5703\n",
            "Epoch 46/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 869ms/step - accuracy: 1.0000 - loss: 2.8445e-04 - val_accuracy: 0.8743 - val_loss: 0.5737\n",
            "Epoch 47/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 874ms/step - accuracy: 1.0000 - loss: 2.5366e-04 - val_accuracy: 0.8689 - val_loss: 0.5815\n",
            "Epoch 48/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 950ms/step - accuracy: 1.0000 - loss: 2.2911e-04 - val_accuracy: 0.8743 - val_loss: 0.5880\n",
            "Epoch 49/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 831ms/step - accuracy: 1.0000 - loss: 2.2964e-04 - val_accuracy: 0.8743 - val_loss: 0.5938\n",
            "Epoch 50/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 871ms/step - accuracy: 1.0000 - loss: 2.0170e-04 - val_accuracy: 0.8743 - val_loss: 0.5981\n",
            "Epoch 51/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 865ms/step - accuracy: 1.0000 - loss: 1.8075e-04 - val_accuracy: 0.8689 - val_loss: 0.6130\n",
            "Epoch 52/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 815ms/step - accuracy: 1.0000 - loss: 1.5023e-04 - val_accuracy: 0.8743 - val_loss: 0.6131\n",
            "Epoch 53/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.6604e-04 - val_accuracy: 0.8689 - val_loss: 0.6204\n",
            "Epoch 54/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 815ms/step - accuracy: 1.0000 - loss: 1.3933e-04 - val_accuracy: 0.8743 - val_loss: 0.6284\n",
            "Epoch 55/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 877ms/step - accuracy: 1.0000 - loss: 1.3076e-04 - val_accuracy: 0.8743 - val_loss: 0.6375\n",
            "Epoch 56/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 852ms/step - accuracy: 1.0000 - loss: 1.3307e-04 - val_accuracy: 0.8743 - val_loss: 0.6565\n",
            "Epoch 57/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 892ms/step - accuracy: 1.0000 - loss: 1.2543e-04 - val_accuracy: 0.8743 - val_loss: 0.6567\n",
            "Epoch 58/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 876ms/step - accuracy: 1.0000 - loss: 1.1380e-04 - val_accuracy: 0.8743 - val_loss: 0.6528\n",
            "Epoch 59/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 806ms/step - accuracy: 1.0000 - loss: 1.0108e-04 - val_accuracy: 0.8743 - val_loss: 0.6533\n",
            "Epoch 60/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 893ms/step - accuracy: 1.0000 - loss: 7.8600e-05 - val_accuracy: 0.8743 - val_loss: 0.6599\n",
            "Epoch 61/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 841ms/step - accuracy: 1.0000 - loss: 7.0604e-05 - val_accuracy: 0.8634 - val_loss: 0.6672\n",
            "Epoch 62/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 875ms/step - accuracy: 1.0000 - loss: 6.6063e-05 - val_accuracy: 0.8743 - val_loss: 0.6757\n",
            "Epoch 63/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.2100e-05 - val_accuracy: 0.8689 - val_loss: 0.6831\n",
            "Epoch 64/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 888ms/step - accuracy: 1.0000 - loss: 5.3160e-05 - val_accuracy: 0.8689 - val_loss: 0.6844\n",
            "Epoch 65/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 831ms/step - accuracy: 1.0000 - loss: 5.4454e-05 - val_accuracy: 0.8689 - val_loss: 0.6886\n",
            "Epoch 66/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.8499e-05 - val_accuracy: 0.8743 - val_loss: 0.6948\n",
            "Epoch 67/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 865ms/step - accuracy: 1.0000 - loss: 4.6287e-05 - val_accuracy: 0.8689 - val_loss: 0.7031\n",
            "Epoch 68/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.5054e-05 - val_accuracy: 0.8689 - val_loss: 0.7127\n",
            "Epoch 69/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 842ms/step - accuracy: 1.0000 - loss: 4.3040e-05 - val_accuracy: 0.8689 - val_loss: 0.7109\n",
            "Epoch 70/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 905ms/step - accuracy: 1.0000 - loss: 3.9822e-05 - val_accuracy: 0.8689 - val_loss: 0.7185\n",
            "Epoch 71/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.8051e-05 - val_accuracy: 0.8689 - val_loss: 0.7246\n",
            "Epoch 72/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 871ms/step - accuracy: 1.0000 - loss: 3.7786e-05 - val_accuracy: 0.8689 - val_loss: 0.7259\n",
            "Epoch 73/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 880ms/step - accuracy: 1.0000 - loss: 3.2702e-05 - val_accuracy: 0.8743 - val_loss: 0.7304\n",
            "Epoch 74/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 829ms/step - accuracy: 1.0000 - loss: 3.0912e-05 - val_accuracy: 0.8689 - val_loss: 0.7345\n",
            "Epoch 75/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 821ms/step - accuracy: 1.0000 - loss: 2.7768e-05 - val_accuracy: 0.8743 - val_loss: 0.7400\n",
            "Epoch 76/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 812ms/step - accuracy: 1.0000 - loss: 2.6675e-05 - val_accuracy: 0.8743 - val_loss: 0.7459\n",
            "Epoch 77/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 952ms/step - accuracy: 1.0000 - loss: 2.6449e-05 - val_accuracy: 0.8634 - val_loss: 0.7476\n",
            "Epoch 78/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 896ms/step - accuracy: 1.0000 - loss: 2.6419e-05 - val_accuracy: 0.8743 - val_loss: 0.7567\n",
            "Epoch 79/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 810ms/step - accuracy: 1.0000 - loss: 2.2033e-05 - val_accuracy: 0.8689 - val_loss: 0.7544\n",
            "Epoch 80/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 807ms/step - accuracy: 1.0000 - loss: 2.2039e-05 - val_accuracy: 0.8743 - val_loss: 0.7587\n",
            "Epoch 81/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 938ms/step - accuracy: 1.0000 - loss: 2.1315e-05 - val_accuracy: 0.8689 - val_loss: 0.7654\n",
            "Epoch 82/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 835ms/step - accuracy: 1.0000 - loss: 2.1215e-05 - val_accuracy: 0.8689 - val_loss: 0.7672\n",
            "Epoch 83/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 923ms/step - accuracy: 1.0000 - loss: 1.9796e-05 - val_accuracy: 0.8689 - val_loss: 0.7705\n",
            "Epoch 84/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 880ms/step - accuracy: 1.0000 - loss: 1.9367e-05 - val_accuracy: 0.8689 - val_loss: 0.7782\n",
            "Epoch 85/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.7469e-05 - val_accuracy: 0.8689 - val_loss: 0.7774\n",
            "Epoch 86/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 801ms/step - accuracy: 1.0000 - loss: 1.7156e-05 - val_accuracy: 0.8743 - val_loss: 0.7859\n",
            "Epoch 87/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 818ms/step - accuracy: 1.0000 - loss: 1.7216e-05 - val_accuracy: 0.8689 - val_loss: 0.7844\n",
            "Epoch 88/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 843ms/step - accuracy: 1.0000 - loss: 1.4901e-05 - val_accuracy: 0.8689 - val_loss: 0.7905\n",
            "Epoch 89/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 808ms/step - accuracy: 1.0000 - loss: 1.5481e-05 - val_accuracy: 0.8743 - val_loss: 0.7909\n",
            "Epoch 90/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.5168e-05 - val_accuracy: 0.8743 - val_loss: 0.7947\n",
            "Epoch 91/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 882ms/step - accuracy: 1.0000 - loss: 1.5720e-05 - val_accuracy: 0.8743 - val_loss: 0.7977\n",
            "Epoch 92/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 894ms/step - accuracy: 1.0000 - loss: 1.2371e-05 - val_accuracy: 0.8743 - val_loss: 0.8015\n",
            "Epoch 93/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 818ms/step - accuracy: 1.0000 - loss: 1.2597e-05 - val_accuracy: 0.8689 - val_loss: 0.8058\n",
            "Epoch 94/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 886ms/step - accuracy: 1.0000 - loss: 1.1988e-05 - val_accuracy: 0.8689 - val_loss: 0.8065\n",
            "Epoch 95/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 884ms/step - accuracy: 1.0000 - loss: 1.2814e-05 - val_accuracy: 0.8743 - val_loss: 0.8124\n",
            "Epoch 96/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 885ms/step - accuracy: 1.0000 - loss: 1.1856e-05 - val_accuracy: 0.8743 - val_loss: 0.8141\n",
            "Epoch 97/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 889ms/step - accuracy: 1.0000 - loss: 1.1395e-05 - val_accuracy: 0.8689 - val_loss: 0.8157\n",
            "Epoch 98/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 945ms/step - accuracy: 1.0000 - loss: 9.9239e-06 - val_accuracy: 0.8743 - val_loss: 0.8194\n",
            "Epoch 99/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 816ms/step - accuracy: 1.0000 - loss: 9.6248e-06 - val_accuracy: 0.8743 - val_loss: 0.8230\n",
            "Epoch 100/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 937ms/step - accuracy: 1.0000 - loss: 1.0279e-05 - val_accuracy: 0.8743 - val_loss: 0.8255\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5s/step\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.8448 - loss: 1.0505\n",
            "Test Accuracy: 0.8370\n",
            "F1 Score: 0.8802\n",
            "G-Mean: 0.8080\n",
            "Informedness (IBA): 0.6224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Here is a table summarizing the performance metrics for all magnification factors (40X, 100X, 200X, 400X) from notebook:"
      ],
      "metadata": {
        "id": "LDf0UOoNtjOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame with the updated metrics\n",
        "data = {\n",
        "    'Magnification': ['40X', '100X', '200X', '400X'],\n",
        "    'Test Accuracy': [0.8982, 0.8658, 0.8742, 0.8370],\n",
        "    'F1 Score': [0.9264, 0.9034, 0.9100, 0.8802],\n",
        "    'G-Mean': [0.8748, 0.8347, 0.8421, 0.8080],\n",
        "    'Informedness (IBA)': [0.7535, 0.6759, 0.6909, 0.6224]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display the table with formatting\n",
        "styled_df = df.style \\\n",
        "    .format({\n",
        "        'Test Accuracy': '{:.4f}',\n",
        "        'F1 Score': '{:.4f}',\n",
        "        'G-Mean': '{:.4f}',\n",
        "        'Informedness (IBA)': '{:.4f}'\n",
        "    }) \\\n",
        "    .set_properties(**{'text-align': 'center'}) \\\n",
        "    .set_table_styles([{\n",
        "        'selector': 'th',\n",
        "        'props': [('background-color', '#000000'), ('font-weight', 'bold')]\n",
        "    }]) \\\n",
        "    .hide(axis='index')\n",
        "\n",
        "styled_df\n"
      ],
      "metadata": {
        "id": "w3sEXPqczU86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "c024e1c0-c7e6-4099-c74f-72aa174626ae"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7e568ea5df90>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_b3876 th {\n",
              "  background-color: #000000;\n",
              "  font-weight: bold;\n",
              "}\n",
              "#T_b3876_row0_col0, #T_b3876_row0_col1, #T_b3876_row0_col2, #T_b3876_row0_col3, #T_b3876_row0_col4, #T_b3876_row1_col0, #T_b3876_row1_col1, #T_b3876_row1_col2, #T_b3876_row1_col3, #T_b3876_row1_col4, #T_b3876_row2_col0, #T_b3876_row2_col1, #T_b3876_row2_col2, #T_b3876_row2_col3, #T_b3876_row2_col4, #T_b3876_row3_col0, #T_b3876_row3_col1, #T_b3876_row3_col2, #T_b3876_row3_col3, #T_b3876_row3_col4 {\n",
              "  text-align: center;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_b3876\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th id=\"T_b3876_level0_col0\" class=\"col_heading level0 col0\" >Magnification</th>\n",
              "      <th id=\"T_b3876_level0_col1\" class=\"col_heading level0 col1\" >Test Accuracy</th>\n",
              "      <th id=\"T_b3876_level0_col2\" class=\"col_heading level0 col2\" >F1 Score</th>\n",
              "      <th id=\"T_b3876_level0_col3\" class=\"col_heading level0 col3\" >G-Mean</th>\n",
              "      <th id=\"T_b3876_level0_col4\" class=\"col_heading level0 col4\" >Informedness (IBA)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td id=\"T_b3876_row0_col0\" class=\"data row0 col0\" >40X</td>\n",
              "      <td id=\"T_b3876_row0_col1\" class=\"data row0 col1\" >0.8982</td>\n",
              "      <td id=\"T_b3876_row0_col2\" class=\"data row0 col2\" >0.9264</td>\n",
              "      <td id=\"T_b3876_row0_col3\" class=\"data row0 col3\" >0.8748</td>\n",
              "      <td id=\"T_b3876_row0_col4\" class=\"data row0 col4\" >0.7535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_b3876_row1_col0\" class=\"data row1 col0\" >100X</td>\n",
              "      <td id=\"T_b3876_row1_col1\" class=\"data row1 col1\" >0.8658</td>\n",
              "      <td id=\"T_b3876_row1_col2\" class=\"data row1 col2\" >0.9034</td>\n",
              "      <td id=\"T_b3876_row1_col3\" class=\"data row1 col3\" >0.8347</td>\n",
              "      <td id=\"T_b3876_row1_col4\" class=\"data row1 col4\" >0.6759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_b3876_row2_col0\" class=\"data row2 col0\" >200X</td>\n",
              "      <td id=\"T_b3876_row2_col1\" class=\"data row2 col1\" >0.8742</td>\n",
              "      <td id=\"T_b3876_row2_col2\" class=\"data row2 col2\" >0.9100</td>\n",
              "      <td id=\"T_b3876_row2_col3\" class=\"data row2 col3\" >0.8421</td>\n",
              "      <td id=\"T_b3876_row2_col4\" class=\"data row2 col4\" >0.6909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_b3876_row3_col0\" class=\"data row3 col0\" >400X</td>\n",
              "      <td id=\"T_b3876_row3_col1\" class=\"data row3 col1\" >0.8370</td>\n",
              "      <td id=\"T_b3876_row3_col2\" class=\"data row3 col2\" >0.8802</td>\n",
              "      <td id=\"T_b3876_row3_col3\" class=\"data row3 col3\" >0.8080</td>\n",
              "      <td id=\"T_b3876_row3_col4\" class=\"data row3 col4\" >0.6224</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FwYFtWXqj11b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}