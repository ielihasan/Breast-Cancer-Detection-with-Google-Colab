{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **GoogLeNet (InceptionV3) for BreaKHis Dataset - Breast Cancer Classification**\n",
        "***\n",
        "This code implements a **GoogLeNet-based deep learning model** (using `InceptionV3`) to classify histology images into **Benign** and **Malignant** categories from the **BreaKHis dataset**.\n",
        "\n",
        "### **Key Steps:**\n",
        "1. **Dataset Preparation**  \n",
        "   - Loads image paths from the dataset directories (`benign/40X` and `malignant/40X`).\n",
        "   - Assigns labels: **0 for Benign, 1 for Malignant**.\n",
        "   - Splits the dataset into **60% training, 10% validation, and 30% testing**.\n",
        "   - Converts images into a TensorFlow dataset with preprocessing:\n",
        "     - Reads images as PNG.\n",
        "     - Resizes to **224x224** (compatible with GoogLeNet).\n",
        "     - Normalizes pixel values.\n",
        "\n",
        "2. **Model Implementation (GoogLeNet - InceptionV3)**\n",
        "   - Loads **InceptionV3** (pre-trained on ImageNet) **without the top layer**.\n",
        "   - **Freezes pre-trained layers** to prevent overfitting.\n",
        "   - Adds a custom classifier:\n",
        "     - **GlobalAveragePooling2D** layer.\n",
        "     - **Fully connected layer (128 neurons, ReLU activation).**\n",
        "     - **Output layer (1 neuron, Sigmoid activation for binary classification).**\n",
        "   - Compiles the model using **Adam optimizer** and **binary cross-entropy loss**.\n",
        "\n",
        "3. **Training the Model**\n",
        "   - Trains the model using the training dataset.\n",
        "   - Validates on a separate validation set.\n",
        "\n",
        "4. **Evaluating the Model**\n",
        "   - Predicts on the test dataset.\n",
        "   - Computes performance metrics:\n",
        "     - **Accuracy**\n",
        "     - **F1 Score**\n",
        "     - **Geometric Mean (G-Mean)**\n",
        "     - **Informedness (IBA)**\n",
        "\n",
        "This model helps classify histology images into **benign or malignant tumors** using deep learning.\n"
      ],
      "metadata": {
        "id": "xttoN66vj1s6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaN7-IlW4EUd",
        "outputId": "bc4a80e0-b181-4a91-de34-16cc68bcd27c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "**Magnification Factor: 40X**\n",
        "***"
      ],
      "metadata": {
        "id": "oIqBeDxhkGR-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tg6GFYFtPQqM",
        "outputId": "7c9102d2-8480-4ce3-a7c8-de9c7ca2b26d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Benign Images: 626\n",
            "Total Malignant Images: 1370\n",
            "Training samples: 1197\n",
            "Validation samples: 200\n",
            "Testing samples: 599\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Epoch 1/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 6s/step - accuracy: 0.5706 - loss: 0.7954 - val_accuracy: 0.7650 - val_loss: 0.4498\n",
            "Epoch 2/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 553ms/step - accuracy: 0.7658 - loss: 0.4956 - val_accuracy: 0.8250 - val_loss: 0.3661\n",
            "Epoch 3/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 621ms/step - accuracy: 0.8109 - loss: 0.4073 - val_accuracy: 0.9000 - val_loss: 0.3083\n",
            "Epoch 4/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 545ms/step - accuracy: 0.8547 - loss: 0.3315 - val_accuracy: 0.9000 - val_loss: 0.2813\n",
            "Epoch 5/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 559ms/step - accuracy: 0.8850 - loss: 0.2979 - val_accuracy: 0.8850 - val_loss: 0.2738\n",
            "Epoch 6/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 839ms/step - accuracy: 0.8916 - loss: 0.2809 - val_accuracy: 0.9150 - val_loss: 0.2448\n",
            "Epoch 7/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 561ms/step - accuracy: 0.9011 - loss: 0.2510 - val_accuracy: 0.9150 - val_loss: 0.2438\n",
            "Epoch 8/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 559ms/step - accuracy: 0.9049 - loss: 0.2394 - val_accuracy: 0.9050 - val_loss: 0.2402\n",
            "Epoch 9/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 602ms/step - accuracy: 0.9144 - loss: 0.2108 - val_accuracy: 0.8950 - val_loss: 0.2632\n",
            "Epoch 10/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 488ms/step - accuracy: 0.9097 - loss: 0.2281 - val_accuracy: 0.9000 - val_loss: 0.2379\n",
            "Epoch 11/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 507ms/step - accuracy: 0.9451 - loss: 0.1759 - val_accuracy: 0.9100 - val_loss: 0.2040\n",
            "Epoch 12/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 489ms/step - accuracy: 0.9488 - loss: 0.1538 - val_accuracy: 0.9050 - val_loss: 0.2094\n",
            "Epoch 13/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 492ms/step - accuracy: 0.9715 - loss: 0.1485 - val_accuracy: 0.9000 - val_loss: 0.2066\n",
            "Epoch 14/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 555ms/step - accuracy: 0.9722 - loss: 0.1295 - val_accuracy: 0.9200 - val_loss: 0.1950\n",
            "Epoch 15/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 482ms/step - accuracy: 0.9774 - loss: 0.1188 - val_accuracy: 0.9200 - val_loss: 0.1951\n",
            "Epoch 16/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 621ms/step - accuracy: 0.9851 - loss: 0.1021 - val_accuracy: 0.9100 - val_loss: 0.1926\n",
            "Epoch 17/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 486ms/step - accuracy: 0.9826 - loss: 0.0986 - val_accuracy: 0.9200 - val_loss: 0.1953\n",
            "Epoch 18/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 499ms/step - accuracy: 0.9803 - loss: 0.0982 - val_accuracy: 0.9050 - val_loss: 0.2267\n",
            "Epoch 19/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 509ms/step - accuracy: 0.9701 - loss: 0.1010 - val_accuracy: 0.9200 - val_loss: 0.1948\n",
            "Epoch 20/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 848ms/step - accuracy: 0.9860 - loss: 0.0796 - val_accuracy: 0.9250 - val_loss: 0.1800\n",
            "Epoch 21/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 491ms/step - accuracy: 0.9888 - loss: 0.0699 - val_accuracy: 0.9250 - val_loss: 0.1846\n",
            "Epoch 22/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 495ms/step - accuracy: 0.9928 - loss: 0.0661 - val_accuracy: 0.9200 - val_loss: 0.1938\n",
            "Epoch 23/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 616ms/step - accuracy: 0.9964 - loss: 0.0545 - val_accuracy: 0.8950 - val_loss: 0.1965\n",
            "Epoch 24/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 491ms/step - accuracy: 0.9972 - loss: 0.0501 - val_accuracy: 0.9100 - val_loss: 0.1919\n",
            "Epoch 25/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 598ms/step - accuracy: 0.9991 - loss: 0.0442 - val_accuracy: 0.9150 - val_loss: 0.1893\n",
            "Epoch 26/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 622ms/step - accuracy: 0.9989 - loss: 0.0407 - val_accuracy: 0.9150 - val_loss: 0.1882\n",
            "Epoch 27/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 495ms/step - accuracy: 0.9997 - loss: 0.0363 - val_accuracy: 0.9150 - val_loss: 0.1875\n",
            "Epoch 28/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 486ms/step - accuracy: 0.9998 - loss: 0.0339 - val_accuracy: 0.9000 - val_loss: 0.1922\n",
            "Epoch 29/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 843ms/step - accuracy: 0.9998 - loss: 0.0313 - val_accuracy: 0.8950 - val_loss: 0.2101\n",
            "Epoch 30/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 559ms/step - accuracy: 0.9978 - loss: 0.0341 - val_accuracy: 0.8950 - val_loss: 0.1972\n",
            "Epoch 31/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 490ms/step - accuracy: 0.9978 - loss: 0.0309 - val_accuracy: 0.9100 - val_loss: 0.1920\n",
            "Epoch 32/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 845ms/step - accuracy: 0.9989 - loss: 0.0275 - val_accuracy: 0.9200 - val_loss: 0.2036\n",
            "Epoch 33/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 553ms/step - accuracy: 0.9989 - loss: 0.0233 - val_accuracy: 0.9100 - val_loss: 0.1936\n",
            "Epoch 34/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 613ms/step - accuracy: 0.9989 - loss: 0.0220 - val_accuracy: 0.9100 - val_loss: 0.2002\n",
            "Epoch 35/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 547ms/step - accuracy: 0.9997 - loss: 0.0185 - val_accuracy: 0.9050 - val_loss: 0.1981\n",
            "Epoch 36/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 497ms/step - accuracy: 1.0000 - loss: 0.0178 - val_accuracy: 0.8950 - val_loss: 0.2132\n",
            "Epoch 37/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 590ms/step - accuracy: 0.9996 - loss: 0.0174 - val_accuracy: 0.8850 - val_loss: 0.2090\n",
            "Epoch 38/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 555ms/step - accuracy: 1.0000 - loss: 0.0159 - val_accuracy: 0.9000 - val_loss: 0.2209\n",
            "Epoch 39/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 528ms/step - accuracy: 1.0000 - loss: 0.0177 - val_accuracy: 0.8900 - val_loss: 0.2108\n",
            "Epoch 40/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 501ms/step - accuracy: 1.0000 - loss: 0.0146 - val_accuracy: 0.8850 - val_loss: 0.2052\n",
            "Epoch 41/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 489ms/step - accuracy: 1.0000 - loss: 0.0141 - val_accuracy: 0.8950 - val_loss: 0.2054\n",
            "Epoch 42/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 845ms/step - accuracy: 1.0000 - loss: 0.0121 - val_accuracy: 0.9100 - val_loss: 0.2071\n",
            "Epoch 43/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 574ms/step - accuracy: 1.0000 - loss: 0.0116 - val_accuracy: 0.8950 - val_loss: 0.2126\n",
            "Epoch 44/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 573ms/step - accuracy: 1.0000 - loss: 0.0116 - val_accuracy: 0.9100 - val_loss: 0.2128\n",
            "Epoch 45/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 498ms/step - accuracy: 1.0000 - loss: 0.0115 - val_accuracy: 0.9150 - val_loss: 0.2188\n",
            "Epoch 46/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 564ms/step - accuracy: 1.0000 - loss: 0.0097 - val_accuracy: 0.9050 - val_loss: 0.2128\n",
            "Epoch 47/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 494ms/step - accuracy: 1.0000 - loss: 0.0095 - val_accuracy: 0.9100 - val_loss: 0.2123\n",
            "Epoch 48/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 642ms/step - accuracy: 1.0000 - loss: 0.0087 - val_accuracy: 0.9050 - val_loss: 0.2148\n",
            "Epoch 49/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 492ms/step - accuracy: 1.0000 - loss: 0.0084 - val_accuracy: 0.9050 - val_loss: 0.2182\n",
            "Epoch 50/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 494ms/step - accuracy: 1.0000 - loss: 0.0085 - val_accuracy: 0.9050 - val_loss: 0.2186\n",
            "Epoch 51/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 555ms/step - accuracy: 1.0000 - loss: 0.0081 - val_accuracy: 0.9050 - val_loss: 0.2207\n",
            "Epoch 52/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 551ms/step - accuracy: 1.0000 - loss: 0.0074 - val_accuracy: 0.9050 - val_loss: 0.2220\n",
            "Epoch 53/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 612ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.9050 - val_loss: 0.2238\n",
            "Epoch 54/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 617ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.8950 - val_loss: 0.2260\n",
            "Epoch 55/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 558ms/step - accuracy: 1.0000 - loss: 0.0064 - val_accuracy: 0.8950 - val_loss: 0.2273\n",
            "Epoch 56/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 552ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.9000 - val_loss: 0.2274\n",
            "Epoch 57/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 488ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.8950 - val_loss: 0.2273\n",
            "Epoch 58/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 489ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.8950 - val_loss: 0.2283\n",
            "Epoch 59/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 591ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 0.8950 - val_loss: 0.2298\n",
            "Epoch 60/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 575ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.9050 - val_loss: 0.2296\n",
            "Epoch 61/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 574ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.9000 - val_loss: 0.2344\n",
            "Epoch 62/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 561ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.9050 - val_loss: 0.2336\n",
            "Epoch 63/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 492ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.9050 - val_loss: 0.2346\n",
            "Epoch 64/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 840ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.8950 - val_loss: 0.2357\n",
            "Epoch 65/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 506ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9000 - val_loss: 0.2344\n",
            "Epoch 66/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 491ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.8950 - val_loss: 0.2358\n",
            "Epoch 67/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 556ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.9000 - val_loss: 0.2370\n",
            "Epoch 68/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 560ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9000 - val_loss: 0.2395\n",
            "Epoch 69/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 555ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.9000 - val_loss: 0.2392\n",
            "Epoch 70/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 848ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.9000 - val_loss: 0.2409\n",
            "Epoch 71/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 482ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9000 - val_loss: 0.2392\n",
            "Epoch 72/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 842ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9000 - val_loss: 0.2410\n",
            "Epoch 73/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 504ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9000 - val_loss: 0.2420\n",
            "Epoch 74/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 493ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9000 - val_loss: 0.2436\n",
            "Epoch 75/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 609ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9000 - val_loss: 0.2439\n",
            "Epoch 76/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 482ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9000 - val_loss: 0.2449\n",
            "Epoch 77/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 616ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9050 - val_loss: 0.2470\n",
            "Epoch 78/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 463ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9000 - val_loss: 0.2489\n",
            "Epoch 79/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 580ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9000 - val_loss: 0.2488\n",
            "Epoch 80/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 598ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9050 - val_loss: 0.2499\n",
            "Epoch 81/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 516ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.9000 - val_loss: 0.2489\n",
            "Epoch 82/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 482ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9000 - val_loss: 0.2491\n",
            "Epoch 83/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 538ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9000 - val_loss: 0.2495\n",
            "Epoch 84/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 604ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9000 - val_loss: 0.2514\n",
            "Epoch 85/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 526ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9000 - val_loss: 0.2522\n",
            "Epoch 86/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 469ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9000 - val_loss: 0.2558\n",
            "Epoch 87/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 600ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9000 - val_loss: 0.2542\n",
            "Epoch 88/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 536ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9000 - val_loss: 0.2558\n",
            "Epoch 89/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 465ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9000 - val_loss: 0.2565\n",
            "Epoch 90/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 470ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9000 - val_loss: 0.2582\n",
            "Epoch 91/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 538ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9000 - val_loss: 0.2576\n",
            "Epoch 92/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 823ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9000 - val_loss: 0.2584\n",
            "Epoch 93/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 460ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9000 - val_loss: 0.2594\n",
            "Epoch 94/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 478ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9000 - val_loss: 0.2596\n",
            "Epoch 95/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 538ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9000 - val_loss: 0.2593\n",
            "Epoch 96/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 540ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9000 - val_loss: 0.2614\n",
            "Epoch 97/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 606ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9000 - val_loss: 0.2626\n",
            "Epoch 98/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 477ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9000 - val_loss: 0.2620\n",
            "Epoch 99/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 573ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9000 - val_loss: 0.2624\n",
            "Epoch 100/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 589ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9000 - val_loss: 0.2646\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4s/step\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.8615 - loss: 0.5395\n",
            "Test Accuracy: 0.8748\n",
            "F1 Score: 0.9100\n",
            "G-Mean: 0.8433\n",
            "Informedness (IBA): 0.6934\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import InceptionV3  # Using InceptionV3 (closest to GoogLeNet)\n",
        "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Define dataset paths\n",
        "benign_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/benign/40X\"\n",
        "malignant_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/malignant/40X\"\n",
        "\n",
        "# Function to load image paths\n",
        "def load_image_paths(dir_path):\n",
        "    return [os.path.join(dir_path, img) for img in os.listdir(dir_path) if img.endswith('.png')]\n",
        "\n",
        "benign_images = load_image_paths(benign_dir)\n",
        "malignant_images = load_image_paths(malignant_dir)\n",
        "\n",
        "print(f\"Total Benign Images: {len(benign_images)}\")\n",
        "print(f\"Total Malignant Images: {len(malignant_images)}\")\n",
        "\n",
        "# Create labels (0 = Benign, 1 = Malignant)\n",
        "benign_labels = [0] * len(benign_images)\n",
        "malignant_labels = [1] * len(malignant_images)\n",
        "\n",
        "# Combine images and labels\n",
        "all_images = np.array(benign_images + malignant_images)\n",
        "all_labels = np.array(benign_labels + malignant_labels)\n",
        "\n",
        "# Split into training (60%), validation (10%), and testing (30%)\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(\n",
        "    all_images, all_labels, test_size=0.3, stratify=all_labels, random_state=42\n",
        ")\n",
        "\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(\n",
        "    train_images, train_labels, test_size=0.1429, stratify=train_labels, random_state=42  # 10% of total dataset\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {len(train_images)}\")\n",
        "print(f\"Validation samples: {len(val_images)}\")\n",
        "print(f\"Testing samples: {len(test_images)}\")\n",
        "\n",
        "# Function to preprocess images\n",
        "def process_path(file_path, label):\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_png(img, channels=3)  # Decode PNG images\n",
        "    img = tf.image.resize(img, [224, 224])  # Resize to 224x224\n",
        "    img = img / 255.0  # Normalize pixel values\n",
        "    return img, label\n",
        "\n",
        "# Create TensorFlow datasets\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "def prepare_dataset(images, labels, shuffle=False):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "    dataset = dataset.map(process_path)\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(1000)\n",
        "    return dataset.batch(BATCH_SIZE)\n",
        "\n",
        "train_dataset = prepare_dataset(train_images, train_labels, shuffle=True)\n",
        "val_dataset = prepare_dataset(val_images, val_labels)\n",
        "test_dataset = prepare_dataset(test_images, test_labels)\n",
        "\n",
        "# Ensure testing dataset is not empty\n",
        "if sum(1 for _ in test_dataset) == 0:\n",
        "    raise ValueError(\"Testing dataset is empty. Adjust your dataset split.\")\n",
        "\n",
        "# Load GoogLeNet (InceptionV3) without the top classification layer\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the pre-trained layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom classifier on top\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dense(1, activation='sigmoid')(x)  # Binary classification\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "EPOCHS = 100\n",
        "history = model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS)\n",
        "\n",
        "# Evaluate model\n",
        "test_preds = model.predict(test_dataset)\n",
        "test_preds = (test_preds > 0.5).astype(int).flatten()\n",
        "\n",
        "# Get confusion matrix values\n",
        "tn, fp, fn, tp = confusion_matrix(test_labels, test_preds).ravel()\n",
        "\n",
        "# Calculate IBA\n",
        "iba = (tp / (tp + fn)) + (tn / (tn + fp)) - 1\n",
        "\n",
        "# Output results\n",
        "f1 = f1_score(test_labels, test_preds)\n",
        "gmean = geometric_mean_score(test_labels, test_preds)\n",
        "\n",
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"G-Mean: {gmean:.4f}\")\n",
        "print(f\"Informedness (IBA): {iba:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "**Magnification Factor: 100X**\n",
        "***"
      ],
      "metadata": {
        "id": "d4kK-fU1kJwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import InceptionV3  # Using InceptionV3 (closest to GoogLeNet)\n",
        "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Define dataset paths\n",
        "benign_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/benign/100X\"\n",
        "malignant_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/malignant/100X\"\n",
        "\n",
        "# Function to load image paths\n",
        "def load_image_paths(dir_path):\n",
        "    return [os.path.join(dir_path, img) for img in os.listdir(dir_path) if img.endswith('.png')]\n",
        "\n",
        "benign_images = load_image_paths(benign_dir)\n",
        "malignant_images = load_image_paths(malignant_dir)\n",
        "\n",
        "print(f\"Total Benign Images: {len(benign_images)}\")\n",
        "print(f\"Total Malignant Images: {len(malignant_images)}\")\n",
        "\n",
        "# Create labels (0 = Benign, 1 = Malignant)\n",
        "benign_labels = [0] * len(benign_images)\n",
        "malignant_labels = [1] * len(malignant_images)\n",
        "\n",
        "# Combine images and labels\n",
        "all_images = np.array(benign_images + malignant_images)\n",
        "all_labels = np.array(benign_labels + malignant_labels)\n",
        "\n",
        "# Split into training (60%), validation (10%), and testing (30%)\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(\n",
        "    all_images, all_labels, test_size=0.3, stratify=all_labels, random_state=42\n",
        ")\n",
        "\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(\n",
        "    train_images, train_labels, test_size=0.1429, stratify=train_labels, random_state=42  # 10% of total dataset\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {len(train_images)}\")\n",
        "print(f\"Validation samples: {len(val_images)}\")\n",
        "print(f\"Testing samples: {len(test_images)}\")\n",
        "\n",
        "# Function to preprocess images\n",
        "def process_path(file_path, label):\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_png(img, channels=3)  # Decode PNG images\n",
        "    img = tf.image.resize(img, [224, 224])  # Resize to 224x224\n",
        "    img = img / 255.0  # Normalize pixel values\n",
        "    return img, label\n",
        "\n",
        "# Create TensorFlow datasets\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "def prepare_dataset(images, labels, shuffle=False):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "    dataset = dataset.map(process_path)\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(1000)\n",
        "    return dataset.batch(BATCH_SIZE)\n",
        "\n",
        "train_dataset = prepare_dataset(train_images, train_labels, shuffle=True)\n",
        "val_dataset = prepare_dataset(val_images, val_labels)\n",
        "test_dataset = prepare_dataset(test_images, test_labels)\n",
        "\n",
        "# Ensure testing dataset is not empty\n",
        "if sum(1 for _ in test_dataset) == 0:\n",
        "    raise ValueError(\"Testing dataset is empty. Adjust your dataset split.\")\n",
        "\n",
        "# Load GoogLeNet (InceptionV3) without the top classification layer\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the pre-trained layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom classifier on top\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dense(1, activation='sigmoid')(x)  # Binary classification\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "EPOCHS = 100\n",
        "history = model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS)\n",
        "\n",
        "# Evaluate model\n",
        "test_preds = model.predict(test_dataset)\n",
        "test_preds = (test_preds > 0.5).astype(int).flatten()\n",
        "\n",
        "# Get confusion matrix values\n",
        "tn, fp, fn, tp = confusion_matrix(test_labels, test_preds).ravel()\n",
        "\n",
        "# Calculate IBA\n",
        "iba = (tp / (tp + fn)) + (tn / (tn + fp)) - 1\n",
        "\n",
        "# Output results\n",
        "f1 = f1_score(test_labels, test_preds)\n",
        "gmean = geometric_mean_score(test_labels, test_preds)\n",
        "\n",
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"G-Mean: {gmean:.4f}\")\n",
        "print(f\"Informedness (IBA): {iba:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rm3Q3LefQ_yp",
        "outputId": "68978750-71b4-4adc-aa30-6d589fbc7627"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Benign Images: 649\n",
            "Total Malignant Images: 1437\n",
            "Training samples: 1251\n",
            "Validation samples: 209\n",
            "Testing samples: 626\n",
            "Epoch 1/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 7s/step - accuracy: 0.5785 - loss: 1.0862 - val_accuracy: 0.7608 - val_loss: 0.5527\n",
            "Epoch 2/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 573ms/step - accuracy: 0.7107 - loss: 0.5333 - val_accuracy: 0.7464 - val_loss: 0.5115\n",
            "Epoch 3/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 662ms/step - accuracy: 0.7868 - loss: 0.4701 - val_accuracy: 0.8086 - val_loss: 0.4271\n",
            "Epoch 4/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 556ms/step - accuracy: 0.8159 - loss: 0.4105 - val_accuracy: 0.8230 - val_loss: 0.3893\n",
            "Epoch 5/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 617ms/step - accuracy: 0.8190 - loss: 0.3936 - val_accuracy: 0.8325 - val_loss: 0.3745\n",
            "Epoch 6/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 575ms/step - accuracy: 0.8286 - loss: 0.3711 - val_accuracy: 0.8517 - val_loss: 0.3539\n",
            "Epoch 7/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 710ms/step - accuracy: 0.8407 - loss: 0.3456 - val_accuracy: 0.8565 - val_loss: 0.3365\n",
            "Epoch 8/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 629ms/step - accuracy: 0.8494 - loss: 0.3245 - val_accuracy: 0.8660 - val_loss: 0.3261\n",
            "Epoch 9/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 658ms/step - accuracy: 0.8418 - loss: 0.3304 - val_accuracy: 0.8660 - val_loss: 0.3186\n",
            "Epoch 10/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 623ms/step - accuracy: 0.8612 - loss: 0.3098 - val_accuracy: 0.8756 - val_loss: 0.3103\n",
            "Epoch 11/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 603ms/step - accuracy: 0.8718 - loss: 0.2975 - val_accuracy: 0.8804 - val_loss: 0.3059\n",
            "Epoch 12/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 751ms/step - accuracy: 0.8720 - loss: 0.2954 - val_accuracy: 0.8852 - val_loss: 0.3118\n",
            "Epoch 13/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 559ms/step - accuracy: 0.8884 - loss: 0.2687 - val_accuracy: 0.8804 - val_loss: 0.3246\n",
            "Epoch 14/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 597ms/step - accuracy: 0.8948 - loss: 0.2595 - val_accuracy: 0.8517 - val_loss: 0.3333\n",
            "Epoch 15/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 901ms/step - accuracy: 0.9064 - loss: 0.2352 - val_accuracy: 0.8852 - val_loss: 0.3063\n",
            "Epoch 16/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 565ms/step - accuracy: 0.9137 - loss: 0.2390 - val_accuracy: 0.8852 - val_loss: 0.2913\n",
            "Epoch 17/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 630ms/step - accuracy: 0.8995 - loss: 0.2345 - val_accuracy: 0.8947 - val_loss: 0.2902\n",
            "Epoch 18/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 673ms/step - accuracy: 0.9221 - loss: 0.2175 - val_accuracy: 0.8947 - val_loss: 0.2812\n",
            "Epoch 19/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 552ms/step - accuracy: 0.9318 - loss: 0.2074 - val_accuracy: 0.8900 - val_loss: 0.2753\n",
            "Epoch 20/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 624ms/step - accuracy: 0.9338 - loss: 0.1963 - val_accuracy: 0.9043 - val_loss: 0.2969\n",
            "Epoch 21/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 571ms/step - accuracy: 0.9368 - loss: 0.1902 - val_accuracy: 0.9043 - val_loss: 0.2856\n",
            "Epoch 22/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 724ms/step - accuracy: 0.9409 - loss: 0.1780 - val_accuracy: 0.8852 - val_loss: 0.2689\n",
            "Epoch 23/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 781ms/step - accuracy: 0.9432 - loss: 0.1683 - val_accuracy: 0.8852 - val_loss: 0.2687\n",
            "Epoch 24/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 580ms/step - accuracy: 0.9506 - loss: 0.1635 - val_accuracy: 0.8900 - val_loss: 0.2640\n",
            "Epoch 25/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 639ms/step - accuracy: 0.9591 - loss: 0.1413 - val_accuracy: 0.8852 - val_loss: 0.2628\n",
            "Epoch 26/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 629ms/step - accuracy: 0.9671 - loss: 0.1341 - val_accuracy: 0.9043 - val_loss: 0.2640\n",
            "Epoch 27/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 681ms/step - accuracy: 0.9661 - loss: 0.1278 - val_accuracy: 0.8995 - val_loss: 0.2666\n",
            "Epoch 28/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 624ms/step - accuracy: 0.9669 - loss: 0.1208 - val_accuracy: 0.8947 - val_loss: 0.2582\n",
            "Epoch 29/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 614ms/step - accuracy: 0.9735 - loss: 0.1228 - val_accuracy: 0.8900 - val_loss: 0.2620\n",
            "Epoch 30/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 574ms/step - accuracy: 0.9740 - loss: 0.1192 - val_accuracy: 0.8995 - val_loss: 0.2543\n",
            "Epoch 31/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 708ms/step - accuracy: 0.9813 - loss: 0.1022 - val_accuracy: 0.8900 - val_loss: 0.2615\n",
            "Epoch 32/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 733ms/step - accuracy: 0.9873 - loss: 0.0969 - val_accuracy: 0.8947 - val_loss: 0.2525\n",
            "Epoch 33/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 566ms/step - accuracy: 0.9864 - loss: 0.0933 - val_accuracy: 0.8995 - val_loss: 0.2713\n",
            "Epoch 34/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 903ms/step - accuracy: 0.9824 - loss: 0.0952 - val_accuracy: 0.8756 - val_loss: 0.2544\n",
            "Epoch 35/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 637ms/step - accuracy: 0.9928 - loss: 0.0805 - val_accuracy: 0.8804 - val_loss: 0.2540\n",
            "Epoch 36/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 699ms/step - accuracy: 0.9944 - loss: 0.0747 - val_accuracy: 0.8900 - val_loss: 0.2545\n",
            "Epoch 37/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 627ms/step - accuracy: 0.9958 - loss: 0.0724 - val_accuracy: 0.8900 - val_loss: 0.2632\n",
            "Epoch 38/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 680ms/step - accuracy: 0.9964 - loss: 0.0648 - val_accuracy: 0.8947 - val_loss: 0.2727\n",
            "Epoch 39/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 674ms/step - accuracy: 0.9961 - loss: 0.0674 - val_accuracy: 0.8804 - val_loss: 0.2580\n",
            "Epoch 40/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 907ms/step - accuracy: 0.9962 - loss: 0.0624 - val_accuracy: 0.8804 - val_loss: 0.3072\n",
            "Epoch 41/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 565ms/step - accuracy: 0.9953 - loss: 0.0651 - val_accuracy: 0.8900 - val_loss: 0.2610\n",
            "Epoch 42/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 564ms/step - accuracy: 0.9989 - loss: 0.0492 - val_accuracy: 0.8852 - val_loss: 0.2576\n",
            "Epoch 43/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 762ms/step - accuracy: 0.9996 - loss: 0.0514 - val_accuracy: 0.8852 - val_loss: 0.2587\n",
            "Epoch 44/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 620ms/step - accuracy: 1.0000 - loss: 0.0473 - val_accuracy: 0.8852 - val_loss: 0.2615\n",
            "Epoch 45/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 685ms/step - accuracy: 0.9996 - loss: 0.0450 - val_accuracy: 0.8947 - val_loss: 0.2693\n",
            "Epoch 46/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 564ms/step - accuracy: 0.9997 - loss: 0.0431 - val_accuracy: 0.8852 - val_loss: 0.2633\n",
            "Epoch 47/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 562ms/step - accuracy: 1.0000 - loss: 0.0434 - val_accuracy: 0.8995 - val_loss: 0.2676\n",
            "Epoch 48/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 686ms/step - accuracy: 0.9978 - loss: 0.0396 - val_accuracy: 0.8852 - val_loss: 0.2654\n",
            "Epoch 49/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 557ms/step - accuracy: 1.0000 - loss: 0.0352 - val_accuracy: 0.8900 - val_loss: 0.2684\n",
            "Epoch 50/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 642ms/step - accuracy: 1.0000 - loss: 0.0348 - val_accuracy: 0.8852 - val_loss: 0.2701\n",
            "Epoch 51/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 662ms/step - accuracy: 1.0000 - loss: 0.0299 - val_accuracy: 0.8995 - val_loss: 0.2698\n",
            "Epoch 52/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 912ms/step - accuracy: 1.0000 - loss: 0.0286 - val_accuracy: 0.8804 - val_loss: 0.2739\n",
            "Epoch 53/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 583ms/step - accuracy: 1.0000 - loss: 0.0297 - val_accuracy: 0.8900 - val_loss: 0.2754\n",
            "Epoch 54/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 719ms/step - accuracy: 1.0000 - loss: 0.0262 - val_accuracy: 0.8900 - val_loss: 0.2759\n",
            "Epoch 55/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 723ms/step - accuracy: 1.0000 - loss: 0.0246 - val_accuracy: 0.8947 - val_loss: 0.2784\n",
            "Epoch 56/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 643ms/step - accuracy: 1.0000 - loss: 0.0216 - val_accuracy: 0.8900 - val_loss: 0.2795\n",
            "Epoch 57/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 636ms/step - accuracy: 1.0000 - loss: 0.0220 - val_accuracy: 0.8995 - val_loss: 0.2788\n",
            "Epoch 58/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 706ms/step - accuracy: 1.0000 - loss: 0.0213 - val_accuracy: 0.8995 - val_loss: 0.2824\n",
            "Epoch 59/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 721ms/step - accuracy: 1.0000 - loss: 0.0221 - val_accuracy: 0.8995 - val_loss: 0.2812\n",
            "Epoch 60/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 559ms/step - accuracy: 1.0000 - loss: 0.0195 - val_accuracy: 0.8995 - val_loss: 0.2825\n",
            "Epoch 61/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 657ms/step - accuracy: 1.0000 - loss: 0.0183 - val_accuracy: 0.9043 - val_loss: 0.2857\n",
            "Epoch 62/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 566ms/step - accuracy: 1.0000 - loss: 0.0172 - val_accuracy: 0.8995 - val_loss: 0.2885\n",
            "Epoch 63/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 570ms/step - accuracy: 1.0000 - loss: 0.0162 - val_accuracy: 0.8947 - val_loss: 0.2920\n",
            "Epoch 64/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 690ms/step - accuracy: 1.0000 - loss: 0.0152 - val_accuracy: 0.8995 - val_loss: 0.2906\n",
            "Epoch 65/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 713ms/step - accuracy: 1.0000 - loss: 0.0157 - val_accuracy: 0.8947 - val_loss: 0.2914\n",
            "Epoch 66/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 562ms/step - accuracy: 1.0000 - loss: 0.0144 - val_accuracy: 0.8995 - val_loss: 0.2950\n",
            "Epoch 67/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 700ms/step - accuracy: 1.0000 - loss: 0.0135 - val_accuracy: 0.8900 - val_loss: 0.2977\n",
            "Epoch 68/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 716ms/step - accuracy: 1.0000 - loss: 0.0137 - val_accuracy: 0.8947 - val_loss: 0.2986\n",
            "Epoch 69/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 625ms/step - accuracy: 1.0000 - loss: 0.0134 - val_accuracy: 0.8947 - val_loss: 0.2974\n",
            "Epoch 70/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 910ms/step - accuracy: 1.0000 - loss: 0.0131 - val_accuracy: 0.8947 - val_loss: 0.2990\n",
            "Epoch 71/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 558ms/step - accuracy: 1.0000 - loss: 0.0120 - val_accuracy: 0.8995 - val_loss: 0.2993\n",
            "Epoch 72/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 917ms/step - accuracy: 1.0000 - loss: 0.0118 - val_accuracy: 0.8995 - val_loss: 0.3008\n",
            "Epoch 73/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 559ms/step - accuracy: 1.0000 - loss: 0.0106 - val_accuracy: 0.8995 - val_loss: 0.3018\n",
            "Epoch 74/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 627ms/step - accuracy: 1.0000 - loss: 0.0110 - val_accuracy: 0.8947 - val_loss: 0.3043\n",
            "Epoch 75/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 655ms/step - accuracy: 1.0000 - loss: 0.0103 - val_accuracy: 0.8995 - val_loss: 0.3064\n",
            "Epoch 76/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 567ms/step - accuracy: 1.0000 - loss: 0.0105 - val_accuracy: 0.8995 - val_loss: 0.3070\n",
            "Epoch 77/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 712ms/step - accuracy: 1.0000 - loss: 0.0099 - val_accuracy: 0.8995 - val_loss: 0.3085\n",
            "Epoch 78/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 662ms/step - accuracy: 1.0000 - loss: 0.0097 - val_accuracy: 0.8995 - val_loss: 0.3115\n",
            "Epoch 79/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 615ms/step - accuracy: 1.0000 - loss: 0.0087 - val_accuracy: 0.8995 - val_loss: 0.3116\n",
            "Epoch 80/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 628ms/step - accuracy: 1.0000 - loss: 0.0086 - val_accuracy: 0.8995 - val_loss: 0.3098\n",
            "Epoch 81/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 705ms/step - accuracy: 1.0000 - loss: 0.0091 - val_accuracy: 0.8995 - val_loss: 0.3158\n",
            "Epoch 82/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 617ms/step - accuracy: 1.0000 - loss: 0.0084 - val_accuracy: 0.8995 - val_loss: 0.3204\n",
            "Epoch 83/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 599ms/step - accuracy: 1.0000 - loss: 0.0084 - val_accuracy: 0.8995 - val_loss: 0.3187\n",
            "Epoch 84/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 682ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 0.8995 - val_loss: 0.3156\n",
            "Epoch 85/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 693ms/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 0.8995 - val_loss: 0.3175\n",
            "Epoch 86/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 569ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.8995 - val_loss: 0.3168\n",
            "Epoch 87/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 568ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.8995 - val_loss: 0.3247\n",
            "Epoch 88/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 623ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.8995 - val_loss: 0.3223\n",
            "Epoch 89/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 656ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 0.8995 - val_loss: 0.3223\n",
            "Epoch 90/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 643ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.8995 - val_loss: 0.3228\n",
            "Epoch 91/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 630ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.9043 - val_loss: 0.3249\n",
            "Epoch 92/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 623ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.8995 - val_loss: 0.3303\n",
            "Epoch 93/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 626ms/step - accuracy: 1.0000 - loss: 0.0064 - val_accuracy: 0.8995 - val_loss: 0.3386\n",
            "Epoch 94/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 660ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.8995 - val_loss: 0.3275\n",
            "Epoch 95/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 622ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.8995 - val_loss: 0.3295\n",
            "Epoch 96/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 903ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.8995 - val_loss: 0.3301\n",
            "Epoch 97/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 621ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.8995 - val_loss: 0.3301\n",
            "Epoch 98/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 689ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.8995 - val_loss: 0.3322\n",
            "Epoch 99/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 714ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.8995 - val_loss: 0.3324\n",
            "Epoch 100/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 909ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.8995 - val_loss: 0.3360\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5s/step\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.8573 - loss: 0.4868\n",
            "Test Accuracy: 0.8498\n",
            "F1 Score: 0.8929\n",
            "G-Mean: 0.8081\n",
            "Informedness (IBA): 0.6275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "**Magnification Factor: 200X**\n",
        "***"
      ],
      "metadata": {
        "id": "TXbInWyBkPmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import InceptionV3  # Using InceptionV3 (closest to GoogLeNet)\n",
        "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Define dataset paths\n",
        "benign_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/benign/200X\"\n",
        "malignant_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/malignant/200X\"\n",
        "\n",
        "# Function to load image paths\n",
        "def load_image_paths(dir_path):\n",
        "    return [os.path.join(dir_path, img) for img in os.listdir(dir_path) if img.endswith('.png')]\n",
        "\n",
        "benign_images = load_image_paths(benign_dir)\n",
        "malignant_images = load_image_paths(malignant_dir)\n",
        "\n",
        "print(f\"Total Benign Images: {len(benign_images)}\")\n",
        "print(f\"Total Malignant Images: {len(malignant_images)}\")\n",
        "\n",
        "# Create labels (0 = Benign, 1 = Malignant)\n",
        "benign_labels = [0] * len(benign_images)\n",
        "malignant_labels = [1] * len(malignant_images)\n",
        "\n",
        "# Combine images and labels\n",
        "all_images = np.array(benign_images + malignant_images)\n",
        "all_labels = np.array(benign_labels + malignant_labels)\n",
        "\n",
        "# Split into training (60%), validation (10%), and testing (30%)\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(\n",
        "    all_images, all_labels, test_size=0.3, stratify=all_labels, random_state=42\n",
        ")\n",
        "\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(\n",
        "    train_images, train_labels, test_size=0.1429, stratify=train_labels, random_state=42  # 10% of total dataset\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {len(train_images)}\")\n",
        "print(f\"Validation samples: {len(val_images)}\")\n",
        "print(f\"Testing samples: {len(test_images)}\")\n",
        "\n",
        "# Function to preprocess images\n",
        "def process_path(file_path, label):\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_png(img, channels=3)  # Decode PNG images\n",
        "    img = tf.image.resize(img, [224, 224])  # Resize to 224x224\n",
        "    img = img / 255.0  # Normalize pixel values\n",
        "    return img, label\n",
        "\n",
        "# Create TensorFlow datasets\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "def prepare_dataset(images, labels, shuffle=False):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "    dataset = dataset.map(process_path)\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(1000)\n",
        "    return dataset.batch(BATCH_SIZE)\n",
        "\n",
        "train_dataset = prepare_dataset(train_images, train_labels, shuffle=True)\n",
        "val_dataset = prepare_dataset(val_images, val_labels)\n",
        "test_dataset = prepare_dataset(test_images, test_labels)\n",
        "\n",
        "# Ensure testing dataset is not empty\n",
        "if sum(1 for _ in test_dataset) == 0:\n",
        "    raise ValueError(\"Testing dataset is empty. Adjust your dataset split.\")\n",
        "\n",
        "# Load GoogLeNet (InceptionV3) without the top classification layer\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the pre-trained layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom classifier on top\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dense(1, activation='sigmoid')(x)  # Binary classification\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "EPOCHS = 100\n",
        "history = model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS)\n",
        "\n",
        "# Evaluate model\n",
        "test_preds = model.predict(test_dataset)\n",
        "test_preds = (test_preds > 0.5).astype(int).flatten()\n",
        "\n",
        "# Get confusion matrix values\n",
        "tn, fp, fn, tp = confusion_matrix(test_labels, test_preds).ravel()\n",
        "\n",
        "# Calculate IBA\n",
        "iba = (tp / (tp + fn)) + (tn / (tn + fp)) - 1\n",
        "\n",
        "# Output results\n",
        "f1 = f1_score(test_labels, test_preds)\n",
        "gmean = geometric_mean_score(test_labels, test_preds)\n",
        "\n",
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"G-Mean: {gmean:.4f}\")\n",
        "print(f\"Informedness (IBA): {iba:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86q7LV5OTngW",
        "outputId": "1e5f21be-786d-4e89-be7a-f30b214043a2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Benign Images: 623\n",
            "Total Malignant Images: 1390\n",
            "Training samples: 1207\n",
            "Validation samples: 202\n",
            "Testing samples: 604\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 6s/step - accuracy: 0.7219 - loss: 0.5838 - val_accuracy: 0.7822 - val_loss: 0.4239\n",
            "Epoch 2/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 541ms/step - accuracy: 0.8275 - loss: 0.4166 - val_accuracy: 0.8317 - val_loss: 0.3927\n",
            "Epoch 3/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 612ms/step - accuracy: 0.8450 - loss: 0.3718 - val_accuracy: 0.8366 - val_loss: 0.3959\n",
            "Epoch 4/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 491ms/step - accuracy: 0.8803 - loss: 0.3042 - val_accuracy: 0.8267 - val_loss: 0.3871\n",
            "Epoch 5/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 832ms/step - accuracy: 0.8768 - loss: 0.2929 - val_accuracy: 0.8267 - val_loss: 0.4059\n",
            "Epoch 6/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 604ms/step - accuracy: 0.9131 - loss: 0.2476 - val_accuracy: 0.8069 - val_loss: 0.3846\n",
            "Epoch 7/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 536ms/step - accuracy: 0.9188 - loss: 0.2332 - val_accuracy: 0.7970 - val_loss: 0.3902\n",
            "Epoch 8/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 539ms/step - accuracy: 0.9149 - loss: 0.2204 - val_accuracy: 0.8267 - val_loss: 0.3886\n",
            "Epoch 9/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 487ms/step - accuracy: 0.9376 - loss: 0.1918 - val_accuracy: 0.8069 - val_loss: 0.4419\n",
            "Epoch 10/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 547ms/step - accuracy: 0.8953 - loss: 0.2349 - val_accuracy: 0.8416 - val_loss: 0.3758\n",
            "Epoch 11/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 467ms/step - accuracy: 0.9519 - loss: 0.1593 - val_accuracy: 0.8317 - val_loss: 0.3771\n",
            "Epoch 12/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 476ms/step - accuracy: 0.9616 - loss: 0.1387 - val_accuracy: 0.8465 - val_loss: 0.3825\n",
            "Epoch 13/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 478ms/step - accuracy: 0.9554 - loss: 0.1403 - val_accuracy: 0.8317 - val_loss: 0.3774\n",
            "Epoch 14/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 466ms/step - accuracy: 0.9706 - loss: 0.1217 - val_accuracy: 0.8465 - val_loss: 0.3845\n",
            "Epoch 15/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 553ms/step - accuracy: 0.9779 - loss: 0.1132 - val_accuracy: 0.8317 - val_loss: 0.3818\n",
            "Epoch 16/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 548ms/step - accuracy: 0.9804 - loss: 0.1000 - val_accuracy: 0.8663 - val_loss: 0.3847\n",
            "Epoch 17/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 525ms/step - accuracy: 0.9908 - loss: 0.0917 - val_accuracy: 0.8366 - val_loss: 0.3846\n",
            "Epoch 18/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 471ms/step - accuracy: 0.9885 - loss: 0.0828 - val_accuracy: 0.8366 - val_loss: 0.4093\n",
            "Epoch 19/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 536ms/step - accuracy: 0.9899 - loss: 0.0697 - val_accuracy: 0.8614 - val_loss: 0.3989\n",
            "Epoch 20/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 550ms/step - accuracy: 0.9912 - loss: 0.0643 - val_accuracy: 0.8614 - val_loss: 0.3983\n",
            "Epoch 21/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 546ms/step - accuracy: 0.9950 - loss: 0.0614 - val_accuracy: 0.8564 - val_loss: 0.4043\n",
            "Epoch 22/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 469ms/step - accuracy: 0.9986 - loss: 0.0462 - val_accuracy: 0.8614 - val_loss: 0.3968\n",
            "Epoch 23/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 471ms/step - accuracy: 0.9983 - loss: 0.0475 - val_accuracy: 0.8564 - val_loss: 0.4044\n",
            "Epoch 24/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 473ms/step - accuracy: 1.0000 - loss: 0.0392 - val_accuracy: 0.8713 - val_loss: 0.4123\n",
            "Epoch 25/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 489ms/step - accuracy: 0.9998 - loss: 0.0380 - val_accuracy: 0.8564 - val_loss: 0.4151\n",
            "Epoch 26/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 550ms/step - accuracy: 1.0000 - loss: 0.0332 - val_accuracy: 0.8564 - val_loss: 0.4170\n",
            "Epoch 27/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 531ms/step - accuracy: 1.0000 - loss: 0.0320 - val_accuracy: 0.8564 - val_loss: 0.4235\n",
            "Epoch 28/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 465ms/step - accuracy: 1.0000 - loss: 0.0277 - val_accuracy: 0.8614 - val_loss: 0.4317\n",
            "Epoch 29/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 466ms/step - accuracy: 1.0000 - loss: 0.0231 - val_accuracy: 0.8564 - val_loss: 0.4359\n",
            "Epoch 30/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 607ms/step - accuracy: 1.0000 - loss: 0.0214 - val_accuracy: 0.8416 - val_loss: 0.4460\n",
            "Epoch 31/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 558ms/step - accuracy: 1.0000 - loss: 0.0221 - val_accuracy: 0.8564 - val_loss: 0.4422\n",
            "Epoch 32/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 829ms/step - accuracy: 1.0000 - loss: 0.0205 - val_accuracy: 0.8564 - val_loss: 0.4408\n",
            "Epoch 33/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 543ms/step - accuracy: 1.0000 - loss: 0.0162 - val_accuracy: 0.8614 - val_loss: 0.4445\n",
            "Epoch 34/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 831ms/step - accuracy: 1.0000 - loss: 0.0159 - val_accuracy: 0.8515 - val_loss: 0.4597\n",
            "Epoch 35/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 540ms/step - accuracy: 1.0000 - loss: 0.0166 - val_accuracy: 0.8465 - val_loss: 0.4563\n",
            "Epoch 36/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 838ms/step - accuracy: 1.0000 - loss: 0.0151 - val_accuracy: 0.8515 - val_loss: 0.4556\n",
            "Epoch 37/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 469ms/step - accuracy: 1.0000 - loss: 0.0132 - val_accuracy: 0.8564 - val_loss: 0.4575\n",
            "Epoch 38/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 467ms/step - accuracy: 1.0000 - loss: 0.0115 - val_accuracy: 0.8515 - val_loss: 0.4716\n",
            "Epoch 39/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 832ms/step - accuracy: 1.0000 - loss: 0.0119 - val_accuracy: 0.8515 - val_loss: 0.4737\n",
            "Epoch 40/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 546ms/step - accuracy: 1.0000 - loss: 0.0108 - val_accuracy: 0.8564 - val_loss: 0.4809\n",
            "Epoch 41/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 836ms/step - accuracy: 1.0000 - loss: 0.0092 - val_accuracy: 0.8663 - val_loss: 0.4759\n",
            "Epoch 42/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 553ms/step - accuracy: 1.0000 - loss: 0.0093 - val_accuracy: 0.8614 - val_loss: 0.4797\n",
            "Epoch 43/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 648ms/step - accuracy: 1.0000 - loss: 0.0088 - val_accuracy: 0.8614 - val_loss: 0.4836\n",
            "Epoch 44/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 579ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 0.8614 - val_loss: 0.4837\n",
            "Epoch 45/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 547ms/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.8614 - val_loss: 0.4874\n",
            "Epoch 46/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 543ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.8614 - val_loss: 0.4931\n",
            "Epoch 47/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 545ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.8564 - val_loss: 0.4944\n",
            "Epoch 48/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 549ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.8614 - val_loss: 0.4980\n",
            "Epoch 49/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 830ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.8564 - val_loss: 0.4994\n",
            "Epoch 50/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 509ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 0.8564 - val_loss: 0.4973\n",
            "Epoch 51/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 832ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.8564 - val_loss: 0.5038\n",
            "Epoch 52/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 535ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.8515 - val_loss: 0.5073\n",
            "Epoch 53/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 539ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.8465 - val_loss: 0.5101\n",
            "Epoch 54/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 479ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.8515 - val_loss: 0.5168\n",
            "Epoch 55/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 549ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.8564 - val_loss: 0.5146\n",
            "Epoch 56/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 649ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.8614 - val_loss: 0.5172\n",
            "Epoch 57/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 617ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.8564 - val_loss: 0.5164\n",
            "Epoch 58/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 469ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.8515 - val_loss: 0.5188\n",
            "Epoch 59/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 623ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.8564 - val_loss: 0.5169\n",
            "Epoch 60/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 533ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.8564 - val_loss: 0.5250\n",
            "Epoch 61/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 503ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.8614 - val_loss: 0.5239\n",
            "Epoch 62/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 834ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.8614 - val_loss: 0.5312\n",
            "Epoch 63/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 542ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.8564 - val_loss: 0.5326\n",
            "Epoch 64/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 581ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.8564 - val_loss: 0.5339\n",
            "Epoch 65/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 612ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.8614 - val_loss: 0.5373\n",
            "Epoch 66/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 545ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.8614 - val_loss: 0.5358\n",
            "Epoch 67/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 471ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.8564 - val_loss: 0.5439\n",
            "Epoch 68/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 550ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.8515 - val_loss: 0.5420\n",
            "Epoch 69/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 831ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.8515 - val_loss: 0.5444\n",
            "Epoch 70/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 599ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.8614 - val_loss: 0.5478\n",
            "Epoch 71/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 474ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.8564 - val_loss: 0.5480\n",
            "Epoch 72/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 471ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.8564 - val_loss: 0.5515\n",
            "Epoch 73/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 832ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.8515 - val_loss: 0.5524\n",
            "Epoch 74/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 544ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.8515 - val_loss: 0.5589\n",
            "Epoch 75/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 829ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.8515 - val_loss: 0.5579\n",
            "Epoch 76/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 469ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.8515 - val_loss: 0.5597\n",
            "Epoch 77/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 475ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.8515 - val_loss: 0.5617\n",
            "Epoch 78/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 551ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.8515 - val_loss: 0.5641\n",
            "Epoch 79/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 546ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.8564 - val_loss: 0.5641\n",
            "Epoch 80/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 527ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.8515 - val_loss: 0.5661\n",
            "Epoch 81/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 546ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.8564 - val_loss: 0.5647\n",
            "Epoch 82/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 534ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.8515 - val_loss: 0.5694\n",
            "Epoch 83/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 575ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.8564 - val_loss: 0.5699\n",
            "Epoch 84/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 602ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.8515 - val_loss: 0.5726\n",
            "Epoch 85/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 546ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.8564 - val_loss: 0.5739\n",
            "Epoch 86/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 613ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.8515 - val_loss: 0.5764\n",
            "Epoch 87/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 546ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.8515 - val_loss: 0.5774\n",
            "Epoch 88/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 473ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.8515 - val_loss: 0.5760\n",
            "Epoch 89/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 473ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.8515 - val_loss: 0.5815\n",
            "Epoch 90/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 537ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.8515 - val_loss: 0.5825\n",
            "Epoch 91/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 543ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.8564 - val_loss: 0.5830\n",
            "Epoch 92/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 577ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.8614 - val_loss: 0.5860\n",
            "Epoch 93/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 529ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.8515 - val_loss: 0.5881\n",
            "Epoch 94/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 548ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.8564 - val_loss: 0.5905\n",
            "Epoch 95/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 497ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.8564 - val_loss: 0.5917\n",
            "Epoch 96/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 475ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.8564 - val_loss: 0.5889\n",
            "Epoch 97/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 576ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.8515 - val_loss: 0.5938\n",
            "Epoch 98/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 472ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.8564 - val_loss: 0.5938\n",
            "Epoch 99/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 545ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.8515 - val_loss: 0.5957\n",
            "Epoch 100/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 598ms/step - accuracy: 1.0000 - loss: 9.8825e-04 - val_accuracy: 0.8564 - val_loss: 0.5976\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4s/step\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.8335 - loss: 0.5779\n",
            "Test Accuracy: 0.8411\n",
            "F1 Score: 0.8873\n",
            "G-Mean: 0.7938\n",
            "Informedness (IBA): 0.6017\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "**Magnification Factor: 400X**\n",
        "***"
      ],
      "metadata": {
        "id": "BoMsXtvTkTit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import InceptionV3  # Using InceptionV3 (closest to GoogLeNet)\n",
        "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Define dataset paths\n",
        "benign_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/benign/400X\"\n",
        "malignant_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/malignant/400X\"\n",
        "\n",
        "# Function to load image paths\n",
        "def load_image_paths(dir_path):\n",
        "    return [os.path.join(dir_path, img) for img in os.listdir(dir_path) if img.endswith('.png')]\n",
        "\n",
        "benign_images = load_image_paths(benign_dir)\n",
        "malignant_images = load_image_paths(malignant_dir)\n",
        "\n",
        "print(f\"Total Benign Images: {len(benign_images)}\")\n",
        "print(f\"Total Malignant Images: {len(malignant_images)}\")\n",
        "\n",
        "# Create labels (0 = Benign, 1 = Malignant)\n",
        "benign_labels = [0] * len(benign_images)\n",
        "malignant_labels = [1] * len(malignant_images)\n",
        "\n",
        "# Combine images and labels\n",
        "all_images = np.array(benign_images + malignant_images)\n",
        "all_labels = np.array(benign_labels + malignant_labels)\n",
        "\n",
        "# Split into training (60%), validation (10%), and testing (30%)\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(\n",
        "    all_images, all_labels, test_size=0.3, stratify=all_labels, random_state=42\n",
        ")\n",
        "\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(\n",
        "    train_images, train_labels, test_size=0.1429, stratify=train_labels, random_state=42  # 10% of total dataset\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {len(train_images)}\")\n",
        "print(f\"Validation samples: {len(val_images)}\")\n",
        "print(f\"Testing samples: {len(test_images)}\")\n",
        "\n",
        "# Function to preprocess images\n",
        "def process_path(file_path, label):\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_png(img, channels=3)  # Decode PNG images\n",
        "    img = tf.image.resize(img, [224, 224])  # Resize to 224x224\n",
        "    img = img / 255.0  # Normalize pixel values\n",
        "    return img, label\n",
        "\n",
        "# Create TensorFlow datasets\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "def prepare_dataset(images, labels, shuffle=False):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "    dataset = dataset.map(process_path)\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(1000)\n",
        "    return dataset.batch(BATCH_SIZE)\n",
        "\n",
        "train_dataset = prepare_dataset(train_images, train_labels, shuffle=True)\n",
        "val_dataset = prepare_dataset(val_images, val_labels)\n",
        "test_dataset = prepare_dataset(test_images, test_labels)\n",
        "\n",
        "# Ensure testing dataset is not empty\n",
        "if sum(1 for _ in test_dataset) == 0:\n",
        "    raise ValueError(\"Testing dataset is empty. Adjust your dataset split.\")\n",
        "\n",
        "# Load GoogLeNet (InceptionV3) without the top classification layer\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the pre-trained layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom classifier on top\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dense(1, activation='sigmoid')(x)  # Binary classification\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "EPOCHS = 100\n",
        "history = model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS)\n",
        "\n",
        "# Evaluate model\n",
        "test_preds = model.predict(test_dataset)\n",
        "test_preds = (test_preds > 0.5).astype(int).flatten()\n",
        "\n",
        "# Get confusion matrix values\n",
        "tn, fp, fn, tp = confusion_matrix(test_labels, test_preds).ravel()\n",
        "\n",
        "# Calculate IBA\n",
        "iba = (tp / (tp + fn)) + (tn / (tn + fp)) - 1\n",
        "\n",
        "# Output results\n",
        "f1 = f1_score(test_labels, test_preds)\n",
        "gmean = geometric_mean_score(test_labels, test_preds)\n",
        "\n",
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"G-Mean: {gmean:.4f}\")\n",
        "print(f\"Informedness (IBA): {iba:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qq6VIG2aVQFB",
        "outputId": "cc577ef4-03e7-4aba-f858-fa93c93821ec"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Benign Images: 588\n",
            "Total Malignant Images: 1232\n",
            "Training samples: 1091\n",
            "Validation samples: 183\n",
            "Testing samples: 546\n",
            "Epoch 1/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 4s/step - accuracy: 0.5691 - loss: 1.0226 - val_accuracy: 0.6940 - val_loss: 0.5287\n",
            "Epoch 2/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 424ms/step - accuracy: 0.6906 - loss: 0.5770 - val_accuracy: 0.7814 - val_loss: 0.5026\n",
            "Epoch 3/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 426ms/step - accuracy: 0.7743 - loss: 0.5098 - val_accuracy: 0.7705 - val_loss: 0.4497\n",
            "Epoch 4/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 575ms/step - accuracy: 0.7780 - loss: 0.4774 - val_accuracy: 0.8087 - val_loss: 0.4112\n",
            "Epoch 5/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 422ms/step - accuracy: 0.8133 - loss: 0.4272 - val_accuracy: 0.8306 - val_loss: 0.3851\n",
            "Epoch 6/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 499ms/step - accuracy: 0.8001 - loss: 0.4192 - val_accuracy: 0.8415 - val_loss: 0.3791\n",
            "Epoch 7/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 540ms/step - accuracy: 0.8478 - loss: 0.3697 - val_accuracy: 0.8470 - val_loss: 0.3653\n",
            "Epoch 8/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 531ms/step - accuracy: 0.8548 - loss: 0.3644 - val_accuracy: 0.8470 - val_loss: 0.3592\n",
            "Epoch 9/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 435ms/step - accuracy: 0.8500 - loss: 0.3449 - val_accuracy: 0.8525 - val_loss: 0.3466\n",
            "Epoch 10/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 855ms/step - accuracy: 0.8761 - loss: 0.3245 - val_accuracy: 0.8579 - val_loss: 0.3439\n",
            "Epoch 11/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 427ms/step - accuracy: 0.8870 - loss: 0.3041 - val_accuracy: 0.8525 - val_loss: 0.3417\n",
            "Epoch 12/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 534ms/step - accuracy: 0.8972 - loss: 0.2798 - val_accuracy: 0.8525 - val_loss: 0.3321\n",
            "Epoch 13/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 532ms/step - accuracy: 0.9003 - loss: 0.2680 - val_accuracy: 0.8470 - val_loss: 0.3298\n",
            "Epoch 14/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 537ms/step - accuracy: 0.9036 - loss: 0.2534 - val_accuracy: 0.8470 - val_loss: 0.3398\n",
            "Epoch 15/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 535ms/step - accuracy: 0.9003 - loss: 0.2504 - val_accuracy: 0.8306 - val_loss: 0.3727\n",
            "Epoch 16/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 546ms/step - accuracy: 0.9001 - loss: 0.2486 - val_accuracy: 0.8470 - val_loss: 0.3196\n",
            "Epoch 17/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 549ms/step - accuracy: 0.9295 - loss: 0.2239 - val_accuracy: 0.8634 - val_loss: 0.3255\n",
            "Epoch 18/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 535ms/step - accuracy: 0.9437 - loss: 0.2050 - val_accuracy: 0.8525 - val_loss: 0.3469\n",
            "Epoch 19/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 542ms/step - accuracy: 0.9298 - loss: 0.2164 - val_accuracy: 0.8743 - val_loss: 0.3236\n",
            "Epoch 20/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 434ms/step - accuracy: 0.9494 - loss: 0.1758 - val_accuracy: 0.8689 - val_loss: 0.3096\n",
            "Epoch 21/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 434ms/step - accuracy: 0.9507 - loss: 0.1769 - val_accuracy: 0.8798 - val_loss: 0.3152\n",
            "Epoch 22/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 532ms/step - accuracy: 0.9549 - loss: 0.1635 - val_accuracy: 0.8743 - val_loss: 0.3127\n",
            "Epoch 23/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 536ms/step - accuracy: 0.9571 - loss: 0.1579 - val_accuracy: 0.8306 - val_loss: 0.3604\n",
            "Epoch 24/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 860ms/step - accuracy: 0.9407 - loss: 0.1732 - val_accuracy: 0.8415 - val_loss: 0.3635\n",
            "Epoch 25/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 539ms/step - accuracy: 0.9421 - loss: 0.1721 - val_accuracy: 0.8689 - val_loss: 0.3129\n",
            "Epoch 26/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 532ms/step - accuracy: 0.9633 - loss: 0.1349 - val_accuracy: 0.8852 - val_loss: 0.3155\n",
            "Epoch 27/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 858ms/step - accuracy: 0.9678 - loss: 0.1236 - val_accuracy: 0.8525 - val_loss: 0.3416\n",
            "Epoch 28/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 540ms/step - accuracy: 0.9644 - loss: 0.1237 - val_accuracy: 0.8852 - val_loss: 0.3147\n",
            "Epoch 29/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 431ms/step - accuracy: 0.9684 - loss: 0.1167 - val_accuracy: 0.8689 - val_loss: 0.3276\n",
            "Epoch 30/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 538ms/step - accuracy: 0.9855 - loss: 0.1081 - val_accuracy: 0.8852 - val_loss: 0.3184\n",
            "Epoch 31/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 540ms/step - accuracy: 0.9856 - loss: 0.0961 - val_accuracy: 0.8579 - val_loss: 0.3306\n",
            "Epoch 32/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 537ms/step - accuracy: 0.9902 - loss: 0.0949 - val_accuracy: 0.8852 - val_loss: 0.3224\n",
            "Epoch 33/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 438ms/step - accuracy: 0.9885 - loss: 0.0858 - val_accuracy: 0.8743 - val_loss: 0.3250\n",
            "Epoch 34/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 502ms/step - accuracy: 0.9926 - loss: 0.0820 - val_accuracy: 0.8798 - val_loss: 0.3293\n",
            "Epoch 35/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 543ms/step - accuracy: 0.9953 - loss: 0.0781 - val_accuracy: 0.8852 - val_loss: 0.3226\n",
            "Epoch 36/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 532ms/step - accuracy: 0.9954 - loss: 0.0707 - val_accuracy: 0.8907 - val_loss: 0.3217\n",
            "Epoch 37/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 531ms/step - accuracy: 0.9964 - loss: 0.0644 - val_accuracy: 0.8798 - val_loss: 0.3251\n",
            "Epoch 38/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 856ms/step - accuracy: 0.9928 - loss: 0.0668 - val_accuracy: 0.8852 - val_loss: 0.3303\n",
            "Epoch 39/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 430ms/step - accuracy: 0.9957 - loss: 0.0588 - val_accuracy: 0.8907 - val_loss: 0.3259\n",
            "Epoch 40/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 428ms/step - accuracy: 0.9984 - loss: 0.0549 - val_accuracy: 0.8852 - val_loss: 0.3307\n",
            "Epoch 41/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 539ms/step - accuracy: 1.0000 - loss: 0.0502 - val_accuracy: 0.8798 - val_loss: 0.3352\n",
            "Epoch 42/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 439ms/step - accuracy: 0.9985 - loss: 0.0474 - val_accuracy: 0.8743 - val_loss: 0.3453\n",
            "Epoch 43/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 536ms/step - accuracy: 0.9969 - loss: 0.0468 - val_accuracy: 0.8689 - val_loss: 0.3523\n",
            "Epoch 44/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 535ms/step - accuracy: 0.9972 - loss: 0.0476 - val_accuracy: 0.8743 - val_loss: 0.3427\n",
            "Epoch 45/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 493ms/step - accuracy: 1.0000 - loss: 0.0417 - val_accuracy: 0.8798 - val_loss: 0.3349\n",
            "Epoch 46/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 442ms/step - accuracy: 0.9995 - loss: 0.0419 - val_accuracy: 0.8798 - val_loss: 0.3402\n",
            "Epoch 47/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 534ms/step - accuracy: 1.0000 - loss: 0.0355 - val_accuracy: 0.8907 - val_loss: 0.3434\n",
            "Epoch 48/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 419ms/step - accuracy: 1.0000 - loss: 0.0341 - val_accuracy: 0.8907 - val_loss: 0.3371\n",
            "Epoch 49/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 579ms/step - accuracy: 1.0000 - loss: 0.0323 - val_accuracy: 0.8907 - val_loss: 0.3504\n",
            "Epoch 50/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 538ms/step - accuracy: 1.0000 - loss: 0.0308 - val_accuracy: 0.8798 - val_loss: 0.3433\n",
            "Epoch 51/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 550ms/step - accuracy: 1.0000 - loss: 0.0286 - val_accuracy: 0.8798 - val_loss: 0.3536\n",
            "Epoch 52/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 435ms/step - accuracy: 1.0000 - loss: 0.0281 - val_accuracy: 0.8798 - val_loss: 0.3566\n",
            "Epoch 53/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 536ms/step - accuracy: 1.0000 - loss: 0.0272 - val_accuracy: 0.8798 - val_loss: 0.3505\n",
            "Epoch 54/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 537ms/step - accuracy: 1.0000 - loss: 0.0257 - val_accuracy: 0.8579 - val_loss: 0.3493\n",
            "Epoch 55/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 431ms/step - accuracy: 1.0000 - loss: 0.0268 - val_accuracy: 0.8798 - val_loss: 0.3532\n",
            "Epoch 56/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 539ms/step - accuracy: 1.0000 - loss: 0.0225 - val_accuracy: 0.8798 - val_loss: 0.3531\n",
            "Epoch 57/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 456ms/step - accuracy: 1.0000 - loss: 0.0229 - val_accuracy: 0.8798 - val_loss: 0.3561\n",
            "Epoch 58/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 424ms/step - accuracy: 1.0000 - loss: 0.0197 - val_accuracy: 0.8852 - val_loss: 0.3617\n",
            "Epoch 59/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 421ms/step - accuracy: 1.0000 - loss: 0.0183 - val_accuracy: 0.8852 - val_loss: 0.3618\n",
            "Epoch 60/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 858ms/step - accuracy: 1.0000 - loss: 0.0181 - val_accuracy: 0.8852 - val_loss: 0.3655\n",
            "Epoch 61/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 425ms/step - accuracy: 1.0000 - loss: 0.0176 - val_accuracy: 0.8743 - val_loss: 0.3714\n",
            "Epoch 62/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 534ms/step - accuracy: 1.0000 - loss: 0.0173 - val_accuracy: 0.8798 - val_loss: 0.3707\n",
            "Epoch 63/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 437ms/step - accuracy: 1.0000 - loss: 0.0179 - val_accuracy: 0.8852 - val_loss: 0.3680\n",
            "Epoch 64/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 539ms/step - accuracy: 1.0000 - loss: 0.0155 - val_accuracy: 0.8852 - val_loss: 0.3666\n",
            "Epoch 65/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 535ms/step - accuracy: 1.0000 - loss: 0.0148 - val_accuracy: 0.8798 - val_loss: 0.3691\n",
            "Epoch 66/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 573ms/step - accuracy: 1.0000 - loss: 0.0141 - val_accuracy: 0.8798 - val_loss: 0.3749\n",
            "Epoch 67/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 536ms/step - accuracy: 1.0000 - loss: 0.0135 - val_accuracy: 0.8798 - val_loss: 0.3752\n",
            "Epoch 68/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 452ms/step - accuracy: 1.0000 - loss: 0.0132 - val_accuracy: 0.8798 - val_loss: 0.3787\n",
            "Epoch 69/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 454ms/step - accuracy: 1.0000 - loss: 0.0128 - val_accuracy: 0.8798 - val_loss: 0.3728\n",
            "Epoch 70/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 536ms/step - accuracy: 1.0000 - loss: 0.0124 - val_accuracy: 0.8798 - val_loss: 0.3737\n",
            "Epoch 71/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 578ms/step - accuracy: 1.0000 - loss: 0.0127 - val_accuracy: 0.8743 - val_loss: 0.3727\n",
            "Epoch 72/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 477ms/step - accuracy: 1.0000 - loss: 0.0119 - val_accuracy: 0.8798 - val_loss: 0.3764\n",
            "Epoch 73/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 467ms/step - accuracy: 1.0000 - loss: 0.0103 - val_accuracy: 0.8852 - val_loss: 0.3825\n",
            "Epoch 74/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 442ms/step - accuracy: 1.0000 - loss: 0.0113 - val_accuracy: 0.8743 - val_loss: 0.3979\n",
            "Epoch 75/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 534ms/step - accuracy: 1.0000 - loss: 0.0112 - val_accuracy: 0.8743 - val_loss: 0.3803\n",
            "Epoch 76/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 544ms/step - accuracy: 1.0000 - loss: 0.0099 - val_accuracy: 0.8743 - val_loss: 0.3826\n",
            "Epoch 77/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 536ms/step - accuracy: 1.0000 - loss: 0.0098 - val_accuracy: 0.8798 - val_loss: 0.3818\n",
            "Epoch 78/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 551ms/step - accuracy: 1.0000 - loss: 0.0088 - val_accuracy: 0.8798 - val_loss: 0.3947\n",
            "Epoch 79/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 535ms/step - accuracy: 1.0000 - loss: 0.0091 - val_accuracy: 0.8798 - val_loss: 0.3862\n",
            "Epoch 80/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 487ms/step - accuracy: 1.0000 - loss: 0.0087 - val_accuracy: 0.8798 - val_loss: 0.3912\n",
            "Epoch 81/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 437ms/step - accuracy: 1.0000 - loss: 0.0083 - val_accuracy: 0.8743 - val_loss: 0.3874\n",
            "Epoch 82/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 431ms/step - accuracy: 1.0000 - loss: 0.0082 - val_accuracy: 0.8798 - val_loss: 0.3902\n",
            "Epoch 83/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 542ms/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 0.8743 - val_loss: 0.3968\n",
            "Epoch 84/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 879ms/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 0.8798 - val_loss: 0.3907\n",
            "Epoch 85/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 430ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 0.8798 - val_loss: 0.3964\n",
            "Epoch 86/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 531ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.8743 - val_loss: 0.3976\n",
            "Epoch 87/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 857ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.8798 - val_loss: 0.3977\n",
            "Epoch 88/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 432ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.8798 - val_loss: 0.3972\n",
            "Epoch 89/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 485ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.8798 - val_loss: 0.4109\n",
            "Epoch 90/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 576ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.8798 - val_loss: 0.4005\n",
            "Epoch 91/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 543ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.8798 - val_loss: 0.4011\n",
            "Epoch 92/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 434ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.8743 - val_loss: 0.4063\n",
            "Epoch 93/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 424ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.8743 - val_loss: 0.4065\n",
            "Epoch 94/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 538ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.8743 - val_loss: 0.4017\n",
            "Epoch 95/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 567ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.8743 - val_loss: 0.4095\n",
            "Epoch 96/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 423ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.8743 - val_loss: 0.4086\n",
            "Epoch 97/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 551ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.8743 - val_loss: 0.4117\n",
            "Epoch 98/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 560ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.8743 - val_loss: 0.4059\n",
            "Epoch 99/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 535ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.8634 - val_loss: 0.4040\n",
            "Epoch 100/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 531ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.8798 - val_loss: 0.4228\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3s/step\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2s/step - accuracy: 0.8427 - loss: 0.5249\n",
            "Test Accuracy: 0.8352\n",
            "F1 Score: 0.8822\n",
            "G-Mean: 0.7847\n",
            "Informedness (IBA): 0.5869\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Here is a table summarizing the performance metrics for all magnification factors (40X, 100X, 200X, 400X) from notebook:"
      ],
      "metadata": {
        "id": "93FiBULsmprB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame with the provided values\n",
        "data = {\n",
        "    'Magnification': ['40X', '100X', '200X', '400X'],\n",
        "    'Test Accuracy': [0.8748, 0.8498, 0.8411, 0.8352],\n",
        "    'F1 Score': [0.9100, 0.8929, 0.8873, 0.8822],\n",
        "    'G-Mean': [0.8433, 0.8081, 0.7938, 0.7847],\n",
        "    'Informedness (IBA)': [0.6934, 0.6275, 0.6017, 0.5869]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display the table with formatting\n",
        "styled_df = df.style \\\n",
        "    .format({\n",
        "        'Test Accuracy': '{:.4f}',\n",
        "        'F1 Score': '{:.4f}',\n",
        "        'G-Mean': '{:.4f}',\n",
        "        'Informedness (IBA)': '{:.4f}'\n",
        "    }) \\\n",
        "    .set_properties(**{'text-align': 'center'}) \\\n",
        "    .set_table_styles([\n",
        "        {'selector': 'th', 'props': [('background-color', '#000000'), ('font-weight', 'bold'), ('color', 'white')]}\n",
        "    ]) \\\n",
        "    .hide(axis='index')\n",
        "\n",
        "styled_df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "UuNYl6RWg0dC",
        "outputId": "58ed3ff3-02b2-4675-9d6f-42ee13e91d8a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x78efb1e935d0>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_25811 th {\n",
              "  background-color: #000000;\n",
              "  font-weight: bold;\n",
              "  color: white;\n",
              "}\n",
              "#T_25811_row0_col0, #T_25811_row0_col1, #T_25811_row0_col2, #T_25811_row0_col3, #T_25811_row0_col4, #T_25811_row1_col0, #T_25811_row1_col1, #T_25811_row1_col2, #T_25811_row1_col3, #T_25811_row1_col4, #T_25811_row2_col0, #T_25811_row2_col1, #T_25811_row2_col2, #T_25811_row2_col3, #T_25811_row2_col4, #T_25811_row3_col0, #T_25811_row3_col1, #T_25811_row3_col2, #T_25811_row3_col3, #T_25811_row3_col4 {\n",
              "  text-align: center;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_25811\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th id=\"T_25811_level0_col0\" class=\"col_heading level0 col0\" >Magnification</th>\n",
              "      <th id=\"T_25811_level0_col1\" class=\"col_heading level0 col1\" >Test Accuracy</th>\n",
              "      <th id=\"T_25811_level0_col2\" class=\"col_heading level0 col2\" >F1 Score</th>\n",
              "      <th id=\"T_25811_level0_col3\" class=\"col_heading level0 col3\" >G-Mean</th>\n",
              "      <th id=\"T_25811_level0_col4\" class=\"col_heading level0 col4\" >Informedness (IBA)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td id=\"T_25811_row0_col0\" class=\"data row0 col0\" >40X</td>\n",
              "      <td id=\"T_25811_row0_col1\" class=\"data row0 col1\" >0.8748</td>\n",
              "      <td id=\"T_25811_row0_col2\" class=\"data row0 col2\" >0.9100</td>\n",
              "      <td id=\"T_25811_row0_col3\" class=\"data row0 col3\" >0.8433</td>\n",
              "      <td id=\"T_25811_row0_col4\" class=\"data row0 col4\" >0.6934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_25811_row1_col0\" class=\"data row1 col0\" >100X</td>\n",
              "      <td id=\"T_25811_row1_col1\" class=\"data row1 col1\" >0.8498</td>\n",
              "      <td id=\"T_25811_row1_col2\" class=\"data row1 col2\" >0.8929</td>\n",
              "      <td id=\"T_25811_row1_col3\" class=\"data row1 col3\" >0.8081</td>\n",
              "      <td id=\"T_25811_row1_col4\" class=\"data row1 col4\" >0.6275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_25811_row2_col0\" class=\"data row2 col0\" >200X</td>\n",
              "      <td id=\"T_25811_row2_col1\" class=\"data row2 col1\" >0.8411</td>\n",
              "      <td id=\"T_25811_row2_col2\" class=\"data row2 col2\" >0.8873</td>\n",
              "      <td id=\"T_25811_row2_col3\" class=\"data row2 col3\" >0.7938</td>\n",
              "      <td id=\"T_25811_row2_col4\" class=\"data row2 col4\" >0.6017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_25811_row3_col0\" class=\"data row3 col0\" >400X</td>\n",
              "      <td id=\"T_25811_row3_col1\" class=\"data row3 col1\" >0.8352</td>\n",
              "      <td id=\"T_25811_row3_col2\" class=\"data row3 col2\" >0.8822</td>\n",
              "      <td id=\"T_25811_row3_col3\" class=\"data row3 col3\" >0.7847</td>\n",
              "      <td id=\"T_25811_row3_col4\" class=\"data row3 col4\" >0.5869</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9tBHjYoslX2U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}