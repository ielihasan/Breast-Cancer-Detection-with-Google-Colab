{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 🔬 **Multi-Magnification Breast Classification using VGG16 + Inception Block by performing Oversampling**\n",
        "***"
      ],
      "metadata": {
        "id": "nPnT1PfT13pQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🔬 40X Magnification\n",
        "\n",
        "- Dataset: 625 benign and 1370 malignant images.  \n",
        "- Images are loaded from class-specific directories.  \n",
        "- Stratified data split: 60% train, 10% val, 30% test.  \n",
        "- Images resized to 224×224 and normalized.  \n",
        "- VGG16 + Inception model with oversampling applied.\n",
        "\n"
      ],
      "metadata": {
        "id": "vd_6orHwz2fY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Putoji1kRXp",
        "outputId": "d02dd628-8d2e-4e4b-9ea9-eaff18eed874"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Benign Images: 626\n",
            "Total Malignant Images: 1370\n",
            "Training samples: 1197\n",
            "Validation samples: 200\n",
            "Testing samples: 599\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 8s/step - accuracy: 0.4977 - loss: 1.1253 - val_accuracy: 0.3150 - val_loss: 0.7155\n",
            "Epoch 2/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 0.5082 - loss: 0.6918 - val_accuracy: 0.7400 - val_loss: 0.6691\n",
            "Epoch 3/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - accuracy: 0.6772 - loss: 0.6733 - val_accuracy: 0.7750 - val_loss: 0.6439\n",
            "Epoch 4/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.6938 - loss: 0.6219 - val_accuracy: 0.7700 - val_loss: 0.5084\n",
            "Epoch 5/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - accuracy: 0.7388 - loss: 0.5503 - val_accuracy: 0.8050 - val_loss: 0.4619\n",
            "Epoch 6/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - accuracy: 0.7973 - loss: 0.4681 - val_accuracy: 0.8000 - val_loss: 0.4429\n",
            "Epoch 7/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - accuracy: 0.8250 - loss: 0.4032 - val_accuracy: 0.8450 - val_loss: 0.3685\n",
            "Epoch 8/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 0.8629 - loss: 0.3322 - val_accuracy: 0.8400 - val_loss: 0.3392\n",
            "Epoch 9/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - accuracy: 0.8750 - loss: 0.3025 - val_accuracy: 0.8750 - val_loss: 0.3278\n",
            "Epoch 10/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - accuracy: 0.9094 - loss: 0.2364 - val_accuracy: 0.8800 - val_loss: 0.3034\n",
            "Epoch 11/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 0.9221 - loss: 0.2137 - val_accuracy: 0.8700 - val_loss: 0.3268\n",
            "Epoch 12/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.9473 - loss: 0.1639 - val_accuracy: 0.8600 - val_loss: 0.3340\n",
            "Epoch 13/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 0.9392 - loss: 0.1640 - val_accuracy: 0.8900 - val_loss: 0.2937\n",
            "Epoch 14/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 0.9618 - loss: 0.1255 - val_accuracy: 0.8500 - val_loss: 0.3732\n",
            "Epoch 15/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.9538 - loss: 0.1246 - val_accuracy: 0.8850 - val_loss: 0.3275\n",
            "Epoch 16/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1s/step - accuracy: 0.9659 - loss: 0.1178 - val_accuracy: 0.9050 - val_loss: 0.2493\n",
            "Epoch 17/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 0.9724 - loss: 0.0829 - val_accuracy: 0.9150 - val_loss: 0.2592\n",
            "Epoch 18/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.9839 - loss: 0.0624 - val_accuracy: 0.9150 - val_loss: 0.2727\n",
            "Epoch 19/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - accuracy: 0.9896 - loss: 0.0474 - val_accuracy: 0.9200 - val_loss: 0.2668\n",
            "Epoch 20/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 0.9890 - loss: 0.0383 - val_accuracy: 0.9250 - val_loss: 0.2746\n",
            "Epoch 21/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 0.9946 - loss: 0.0273 - val_accuracy: 0.9200 - val_loss: 0.2912\n",
            "Epoch 22/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - accuracy: 0.9929 - loss: 0.0327 - val_accuracy: 0.9100 - val_loss: 0.3379\n",
            "Epoch 23/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 0.9935 - loss: 0.0280 - val_accuracy: 0.9150 - val_loss: 0.3021\n",
            "Epoch 24/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.9993 - loss: 0.0156 - val_accuracy: 0.9150 - val_loss: 0.3021\n",
            "Epoch 25/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.9995 - loss: 0.0120 - val_accuracy: 0.9200 - val_loss: 0.2998\n",
            "Epoch 26/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 0.9990 - loss: 0.0116 - val_accuracy: 0.9150 - val_loss: 0.2971\n",
            "Epoch 27/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.9996 - loss: 0.0092 - val_accuracy: 0.9150 - val_loss: 0.2989\n",
            "Epoch 28/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - accuracy: 0.9993 - loss: 0.0084 - val_accuracy: 0.9250 - val_loss: 0.3302\n",
            "Epoch 29/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 0.9995 - loss: 0.0057 - val_accuracy: 0.9150 - val_loss: 0.3167\n",
            "Epoch 30/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.9987 - loss: 0.0101 - val_accuracy: 0.9100 - val_loss: 0.3668\n",
            "Epoch 31/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 0.9992 - loss: 0.0130 - val_accuracy: 0.9200 - val_loss: 0.3343\n",
            "Epoch 32/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - accuracy: 0.9990 - loss: 0.0060 - val_accuracy: 0.9100 - val_loss: 0.3472\n",
            "Epoch 33/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.9200 - val_loss: 0.3371\n",
            "Epoch 34/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9150 - val_loss: 0.3201\n",
            "Epoch 35/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9250 - val_loss: 0.3281\n",
            "Epoch 36/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9050 - val_loss: 0.3260\n",
            "Epoch 37/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9300 - val_loss: 0.3487\n",
            "Epoch 38/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9250 - val_loss: 0.3474\n",
            "Epoch 39/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9300 - val_loss: 0.3479\n",
            "Epoch 40/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9300 - val_loss: 0.3518\n",
            "Epoch 41/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9300 - val_loss: 0.3558\n",
            "Epoch 42/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9300 - val_loss: 0.3564\n",
            "Epoch 43/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9300 - val_loss: 0.3748\n",
            "Epoch 44/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9300 - val_loss: 0.3640\n",
            "Epoch 45/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.8969e-04 - val_accuracy: 0.9300 - val_loss: 0.3695\n",
            "Epoch 46/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.6014e-04 - val_accuracy: 0.9200 - val_loss: 0.3699\n",
            "Epoch 47/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 8.4604e-04 - val_accuracy: 0.9300 - val_loss: 0.3769\n",
            "Epoch 48/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 8.5731e-04 - val_accuracy: 0.9300 - val_loss: 0.3984\n",
            "Epoch 49/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 7.5923e-04 - val_accuracy: 0.9300 - val_loss: 0.3816\n",
            "Epoch 50/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.6651e-04 - val_accuracy: 0.9250 - val_loss: 0.3833\n",
            "Epoch 51/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.4853e-04 - val_accuracy: 0.9200 - val_loss: 0.3874\n",
            "Epoch 52/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.5331e-04 - val_accuracy: 0.9250 - val_loss: 0.3944\n",
            "Epoch 53/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.1585e-04 - val_accuracy: 0.9200 - val_loss: 0.3945\n",
            "Epoch 54/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.9242e-04 - val_accuracy: 0.9200 - val_loss: 0.3976\n",
            "Epoch 55/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.8638e-04 - val_accuracy: 0.9150 - val_loss: 0.4023\n",
            "Epoch 56/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.3922e-04 - val_accuracy: 0.9250 - val_loss: 0.4106\n",
            "Epoch 57/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.6214e-04 - val_accuracy: 0.9250 - val_loss: 0.4114\n",
            "Epoch 58/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.3492e-04 - val_accuracy: 0.9300 - val_loss: 0.4208\n",
            "Epoch 59/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.5609e-04 - val_accuracy: 0.9250 - val_loss: 0.4172\n",
            "Epoch 60/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.0407e-04 - val_accuracy: 0.9150 - val_loss: 0.4200\n",
            "Epoch 61/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.8898e-04 - val_accuracy: 0.9250 - val_loss: 0.4290\n",
            "Epoch 62/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.6208e-04 - val_accuracy: 0.9250 - val_loss: 0.4335\n",
            "Epoch 63/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.5575e-04 - val_accuracy: 0.9250 - val_loss: 0.4347\n",
            "Epoch 64/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.5552e-04 - val_accuracy: 0.9250 - val_loss: 0.4379\n",
            "Epoch 65/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.2178e-04 - val_accuracy: 0.9250 - val_loss: 0.4386\n",
            "Epoch 66/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.0167e-04 - val_accuracy: 0.9150 - val_loss: 0.4372\n",
            "Epoch 67/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.9336e-04 - val_accuracy: 0.9250 - val_loss: 0.4438\n",
            "Epoch 68/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.8745e-04 - val_accuracy: 0.9250 - val_loss: 0.4547\n",
            "Epoch 69/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.9211e-04 - val_accuracy: 0.9250 - val_loss: 0.4486\n",
            "Epoch 70/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.8512e-04 - val_accuracy: 0.9250 - val_loss: 0.4602\n",
            "Epoch 71/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.8475e-04 - val_accuracy: 0.9250 - val_loss: 0.4557\n",
            "Epoch 72/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 999ms/step - accuracy: 1.0000 - loss: 1.7257e-04 - val_accuracy: 0.9100 - val_loss: 0.4538\n",
            "Epoch 73/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.4252e-04 - val_accuracy: 0.9250 - val_loss: 0.4656\n",
            "Epoch 74/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.3498e-04 - val_accuracy: 0.9250 - val_loss: 0.4646\n",
            "Epoch 75/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.2824e-04 - val_accuracy: 0.9250 - val_loss: 0.4685\n",
            "Epoch 76/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.2918e-04 - val_accuracy: 0.9250 - val_loss: 0.4701\n",
            "Epoch 77/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.3787e-04 - val_accuracy: 0.9250 - val_loss: 0.4720\n",
            "Epoch 78/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.0388e-04 - val_accuracy: 0.9250 - val_loss: 0.4758\n",
            "Epoch 79/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.1826e-04 - val_accuracy: 0.9150 - val_loss: 0.4744\n",
            "Epoch 80/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.0854e-04 - val_accuracy: 0.9250 - val_loss: 0.4825\n",
            "Epoch 81/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.0967e-04 - val_accuracy: 0.9250 - val_loss: 0.4806\n",
            "Epoch 82/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.3337e-05 - val_accuracy: 0.9250 - val_loss: 0.4839\n",
            "Epoch 83/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.2314e-05 - val_accuracy: 0.9150 - val_loss: 0.4817\n",
            "Epoch 84/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.0062e-04 - val_accuracy: 0.9150 - val_loss: 0.4857\n",
            "Epoch 85/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 7.8706e-05 - val_accuracy: 0.9250 - val_loss: 0.4956\n",
            "Epoch 86/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.1401e-05 - val_accuracy: 0.9250 - val_loss: 0.4934\n",
            "Epoch 87/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 8.6543e-05 - val_accuracy: 0.9250 - val_loss: 0.4980\n",
            "Epoch 88/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 7.4297e-05 - val_accuracy: 0.9250 - val_loss: 0.4973\n",
            "Epoch 89/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 997ms/step - accuracy: 1.0000 - loss: 7.5470e-05 - val_accuracy: 0.9250 - val_loss: 0.5004\n",
            "Epoch 90/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.7531e-05 - val_accuracy: 0.9250 - val_loss: 0.5072\n",
            "Epoch 91/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.8052e-05 - val_accuracy: 0.9250 - val_loss: 0.5108\n",
            "Epoch 92/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 992ms/step - accuracy: 1.0000 - loss: 7.6334e-05 - val_accuracy: 0.9250 - val_loss: 0.5096\n",
            "Epoch 93/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.0549e-05 - val_accuracy: 0.9200 - val_loss: 0.5089\n",
            "Epoch 94/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 997ms/step - accuracy: 1.0000 - loss: 6.3730e-05 - val_accuracy: 0.9250 - val_loss: 0.5133\n",
            "Epoch 95/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.1700e-05 - val_accuracy: 0.9200 - val_loss: 0.5134\n",
            "Epoch 96/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.6262e-05 - val_accuracy: 0.9200 - val_loss: 0.5155\n",
            "Epoch 97/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.2355e-05 - val_accuracy: 0.9250 - val_loss: 0.5208\n",
            "Epoch 98/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.4913e-05 - val_accuracy: 0.9150 - val_loss: 0.5193\n",
            "Epoch 99/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.6110e-05 - val_accuracy: 0.9150 - val_loss: 0.5185\n",
            "Epoch 100/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.2458e-05 - val_accuracy: 0.9250 - val_loss: 0.5253\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 8s/step\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8987 - loss: 0.7712\n",
            "Test Accuracy: 0.9015\n",
            "F1 Score: 0.9287\n",
            "G-Mean: 0.8805\n",
            "Informedness (IBA): 0.7641\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, concatenate, AveragePooling2D, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "from sklearn.utils import resample  # Added for oversampling\n",
        "\n",
        "# Define dataset paths\n",
        "benign_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/benign/40X\"\n",
        "malignant_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/malignant/40X\"\n",
        "\n",
        "def load_image_paths(dir_path):\n",
        "    return [os.path.join(dir_path, img) for img in os.listdir(dir_path) if img.endswith('.png')]\n",
        "\n",
        "benign_images = load_image_paths(benign_dir)\n",
        "malignant_images = load_image_paths(malignant_dir)\n",
        "\n",
        "print(f\"Total Benign Images: {len(benign_images)}\")\n",
        "print(f\"Total Malignant Images: {len(malignant_images)}\")\n",
        "\n",
        "benign_labels = [0] * len(benign_images)\n",
        "malignant_labels = [1] * len(malignant_images)\n",
        "\n",
        "all_images = np.array(benign_images + malignant_images)\n",
        "all_labels = np.array(benign_labels + malignant_labels)\n",
        "\n",
        "# Split dataset (60% train, 10% val, 30% test)\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(\n",
        "    all_images, all_labels, test_size=0.3, stratify=all_labels, random_state=42)\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(\n",
        "    train_images, train_labels, test_size=0.1429, stratify=train_labels, random_state=42)\n",
        "\n",
        "print(f\"Training samples: {len(train_images)}\")\n",
        "print(f\"Validation samples: {len(val_images)}\")\n",
        "print(f\"Testing samples: {len(test_images)}\")\n",
        "\n",
        "def process_path(file_path, label):\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_png(img, channels=3)\n",
        "    img = tf.image.resize(img, [224, 224])\n",
        "    img = img / 255.0\n",
        "    return img, label\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# ---------------------- OVERSAMPLING ----------------------\n",
        "train_images = np.array(train_images)\n",
        "train_labels = np.array(train_labels)\n",
        "\n",
        "benign_mask = train_labels == 0\n",
        "malignant_mask = train_labels == 1\n",
        "\n",
        "benign_images_train = train_images[benign_mask]\n",
        "malignant_images_train = train_images[malignant_mask]\n",
        "\n",
        "benign_labels_train = train_labels[benign_mask]\n",
        "malignant_labels_train = train_labels[malignant_mask]\n",
        "\n",
        "# Oversample benign class to match malignant\n",
        "benign_images_upsampled, benign_labels_upsampled = resample(\n",
        "    benign_images_train,\n",
        "    benign_labels_train,\n",
        "    replace=True,\n",
        "    n_samples=len(malignant_images_train),\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Combine and shuffle\n",
        "oversampled_train_images = np.concatenate([malignant_images_train, benign_images_upsampled])\n",
        "oversampled_train_labels = np.concatenate([malignant_labels_train, benign_labels_upsampled])\n",
        "\n",
        "shuffle_idx = np.random.permutation(len(oversampled_train_images))\n",
        "oversampled_train_images = oversampled_train_images[shuffle_idx]\n",
        "oversampled_train_labels = oversampled_train_labels[shuffle_idx]\n",
        "\n",
        "# Dataset pipelines\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((oversampled_train_images, oversampled_train_labels)) \\\n",
        "    .map(process_path).shuffle(1000).batch(BATCH_SIZE)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels)).map(process_path).batch(BATCH_SIZE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).map(process_path).batch(BATCH_SIZE)\n",
        "\n",
        "if sum(1 for _ in test_dataset) == 0:\n",
        "    raise ValueError(\"Testing dataset is empty. Adjust your dataset split.\")\n",
        "\n",
        "# ------------------ MODEL ------------------\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "def inception_block(x):\n",
        "    branch1 = Conv2D(64, (1, 1), activation='relu', padding='same')(x)\n",
        "\n",
        "    branch2 = Conv2D(64, (1, 1), activation='relu', padding='same')(x)\n",
        "    branch2 = Conv2D(128, (3, 3), activation='relu', padding='same')(branch2)\n",
        "\n",
        "    branch3 = Conv2D(64, (1, 1), activation='relu', padding='same')(x)\n",
        "    branch3 = Conv2D(128, (5, 5), activation='relu', padding='same')(branch3)\n",
        "\n",
        "    branch4 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "    branch4 = Conv2D(64, (1, 1), activation='relu', padding='same')(branch4)\n",
        "\n",
        "    output = concatenate([branch1, branch2, branch3, branch4], axis=-1)\n",
        "    return output\n",
        "\n",
        "# Add Inception block after VGG16\n",
        "x = inception_block(base_model.output)\n",
        "x = AveragePooling2D(pool_size=(2, 2))(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# ------------------ TRAIN ------------------\n",
        "EPOCHS = 100\n",
        "history = model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS)\n",
        "\n",
        "# ------------------ EVALUATION ------------------\n",
        "test_preds = model.predict(test_dataset)\n",
        "test_preds = (test_preds > 0.5).astype(int).flatten()\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(test_labels, test_preds).ravel()\n",
        "iba = (tp / (tp + fn)) + (tn / (tn + fp)) - 1\n",
        "\n",
        "f1 = f1_score(test_labels, test_preds)\n",
        "gmean = geometric_mean_score(test_labels, test_preds)\n",
        "\n",
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"G-Mean: {gmean:.4f}\")\n",
        "print(f\"Informedness (IBA): {iba:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### 🔬 100X Magnification\n",
        "\n",
        "- Dataset: 644 benign and 1437 malignant images.  \n",
        "- Loaded from benign/malignant directories.  \n",
        "- Stratified train/val/test split maintained.  \n",
        "- Images preprocessed (resize to 224×224 + normalization).  \n",
        "- Model: VGG16 base + Inception block; oversampling enabled.\n"
      ],
      "metadata": {
        "id": "DapBKwBw1esJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, concatenate, AveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "from sklearn.utils import resample  # Required for oversampling\n",
        "\n",
        "# Define dataset paths\n",
        "benign_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/benign/100X\"\n",
        "malignant_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/malignant/100X\"\n",
        "\n",
        "def load_image_paths(dir_path):\n",
        "    return [os.path.join(dir_path, img) for img in os.listdir(dir_path) if img.endswith('.png')]\n",
        "\n",
        "benign_images = load_image_paths(benign_dir)\n",
        "malignant_images = load_image_paths(malignant_dir)\n",
        "\n",
        "print(f\"Total Benign Images: {len(benign_images)}\")\n",
        "print(f\"Total Malignant Images: {len(malignant_images)}\")\n",
        "\n",
        "benign_labels = [0] * len(benign_images)\n",
        "malignant_labels = [1] * len(malignant_images)\n",
        "\n",
        "all_images = np.array(benign_images + malignant_images)\n",
        "all_labels = np.array(benign_labels + malignant_labels)\n",
        "\n",
        "# Split dataset (60% train, 10% val, 30% test)\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(\n",
        "    all_images, all_labels, test_size=0.3, stratify=all_labels, random_state=42)\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(\n",
        "    train_images, train_labels, test_size=0.1429, stratify=train_labels, random_state=42)\n",
        "\n",
        "print(f\"Training samples: {len(train_images)}\")\n",
        "print(f\"Validation samples: {len(val_images)}\")\n",
        "print(f\"Testing samples: {len(test_images)}\")\n",
        "\n",
        "def process_path(file_path, label):\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_png(img, channels=3)\n",
        "    img = tf.image.resize(img, [224, 224])\n",
        "    img = img / 255.0\n",
        "    return img, label\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# ---------------------- OVERSAMPLING ----------------------\n",
        "train_images = np.array(train_images)\n",
        "train_labels = np.array(train_labels)\n",
        "\n",
        "benign_mask = train_labels == 0\n",
        "malignant_mask = train_labels == 1\n",
        "\n",
        "benign_images_train = train_images[benign_mask]\n",
        "malignant_images_train = train_images[malignant_mask]\n",
        "\n",
        "benign_labels_train = train_labels[benign_mask]\n",
        "malignant_labels_train = train_labels[malignant_mask]\n",
        "\n",
        "# Upsample benign to match malignant\n",
        "benign_images_upsampled, benign_labels_upsampled = resample(\n",
        "    benign_images_train,\n",
        "    benign_labels_train,\n",
        "    replace=True,\n",
        "    n_samples=len(malignant_images_train),\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Combine and shuffle\n",
        "oversampled_train_images = np.concatenate([malignant_images_train, benign_images_upsampled])\n",
        "oversampled_train_labels = np.concatenate([malignant_labels_train, benign_labels_upsampled])\n",
        "\n",
        "shuffle_idx = np.random.permutation(len(oversampled_train_images))\n",
        "oversampled_train_images = oversampled_train_images[shuffle_idx]\n",
        "oversampled_train_labels = oversampled_train_labels[shuffle_idx]\n",
        "\n",
        "# Create dataset pipelines\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((oversampled_train_images, oversampled_train_labels)) \\\n",
        "    .map(process_path).shuffle(1000).batch(BATCH_SIZE)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels)).map(process_path).batch(BATCH_SIZE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).map(process_path).batch(BATCH_SIZE)\n",
        "\n",
        "if sum(1 for _ in test_dataset) == 0:\n",
        "    raise ValueError(\"Testing dataset is empty. Adjust your dataset split.\")\n",
        "\n",
        "# ------------------ MODEL ------------------\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "def inception_block(x):\n",
        "    branch1 = Conv2D(64, (1, 1), activation='relu', padding='same')(x)\n",
        "\n",
        "    branch2 = Conv2D(64, (1, 1), activation='relu', padding='same')(x)\n",
        "    branch2 = Conv2D(128, (3, 3), activation='relu', padding='same')(branch2)\n",
        "\n",
        "    branch3 = Conv2D(64, (1, 1), activation='relu', padding='same')(x)\n",
        "    branch3 = Conv2D(128, (5, 5), activation='relu', padding='same')(branch3)\n",
        "\n",
        "    branch4 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "    branch4 = Conv2D(64, (1, 1), activation='relu', padding='same')(branch4)\n",
        "\n",
        "    output = concatenate([branch1, branch2, branch3, branch4], axis=-1)\n",
        "    return output\n",
        "\n",
        "# Add Inception block after VGG16\n",
        "x = inception_block(base_model.output)\n",
        "x = AveragePooling2D(pool_size=(2, 2))(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# ------------------ TRAIN ------------------\n",
        "EPOCHS = 100\n",
        "history = model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS)\n",
        "\n",
        "# ------------------ EVALUATION ------------------\n",
        "test_preds = model.predict(test_dataset)\n",
        "test_preds = (test_preds > 0.5).astype(int).flatten()\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(test_labels, test_preds).ravel()\n",
        "iba = (tp / (tp + fn)) + (tn / (tn + fp)) - 1\n",
        "\n",
        "f1 = f1_score(test_labels, test_preds)\n",
        "gmean = geometric_mean_score(test_labels, test_preds)\n",
        "\n",
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"G-Mean: {gmean:.4f}\")\n",
        "print(f\"Informedness (IBA): {iba:.4f}\")\n"
      ],
      "metadata": {
        "id": "3ceLB4f7l_T8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deff0a65-29ea-4027-83e6-6021680348ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Benign Images: 649\n",
            "Total Malignant Images: 1437\n",
            "Training samples: 1251\n",
            "Validation samples: 209\n",
            "Testing samples: 626\n",
            "Epoch 1/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 6s/step - accuracy: 0.4913 - loss: 1.0710 - val_accuracy: 0.3828 - val_loss: 0.7023\n",
            "Epoch 2/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 987ms/step - accuracy: 0.5601 - loss: 0.6648 - val_accuracy: 0.7129 - val_loss: 0.6048\n",
            "Epoch 3/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 995ms/step - accuracy: 0.7366 - loss: 0.5638 - val_accuracy: 0.8134 - val_loss: 0.4321\n",
            "Epoch 4/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1s/step - accuracy: 0.7957 - loss: 0.4651 - val_accuracy: 0.8230 - val_loss: 0.3923\n",
            "Epoch 5/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 974ms/step - accuracy: 0.8435 - loss: 0.3647 - val_accuracy: 0.7895 - val_loss: 0.4805\n",
            "Epoch 6/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 0.8890 - loss: 0.2608 - val_accuracy: 0.8421 - val_loss: 0.4127\n",
            "Epoch 7/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 0.9350 - loss: 0.1813 - val_accuracy: 0.8612 - val_loss: 0.3181\n",
            "Epoch 8/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 0.9497 - loss: 0.1387 - val_accuracy: 0.8612 - val_loss: 0.3985\n",
            "Epoch 9/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 980ms/step - accuracy: 0.9658 - loss: 0.0985 - val_accuracy: 0.8517 - val_loss: 0.3690\n",
            "Epoch 10/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 0.9838 - loss: 0.0545 - val_accuracy: 0.8852 - val_loss: 0.4047\n",
            "Epoch 11/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 986ms/step - accuracy: 0.9803 - loss: 0.0494 - val_accuracy: 0.8612 - val_loss: 0.4686\n",
            "Epoch 12/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 0.9874 - loss: 0.0443 - val_accuracy: 0.8900 - val_loss: 0.4439\n",
            "Epoch 13/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - accuracy: 0.9916 - loss: 0.0292 - val_accuracy: 0.8852 - val_loss: 0.4084\n",
            "Epoch 14/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 0.9997 - loss: 0.0133 - val_accuracy: 0.8708 - val_loss: 0.4317\n",
            "Epoch 15/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 980ms/step - accuracy: 0.9992 - loss: 0.0087 - val_accuracy: 0.8852 - val_loss: 0.4374\n",
            "Epoch 16/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 986ms/step - accuracy: 1.0000 - loss: 0.0064 - val_accuracy: 0.8708 - val_loss: 0.4658\n",
            "Epoch 17/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.8756 - val_loss: 0.4742\n",
            "Epoch 18/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 992ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.8804 - val_loss: 0.4762\n",
            "Epoch 19/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.8804 - val_loss: 0.4986\n",
            "Epoch 20/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.8756 - val_loss: 0.5072\n",
            "Epoch 21/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.8756 - val_loss: 0.5124\n",
            "Epoch 22/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.8804 - val_loss: 0.5153\n",
            "Epoch 23/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.8852 - val_loss: 0.5263\n",
            "Epoch 24/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 8.8343e-04 - val_accuracy: 0.8756 - val_loss: 0.5383\n",
            "Epoch 25/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 980ms/step - accuracy: 1.0000 - loss: 7.4642e-04 - val_accuracy: 0.8852 - val_loss: 0.5649\n",
            "Epoch 26/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 7.7292e-04 - val_accuracy: 0.8804 - val_loss: 0.5524\n",
            "Epoch 27/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.9487e-04 - val_accuracy: 0.8804 - val_loss: 0.5581\n",
            "Epoch 28/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.4605e-04 - val_accuracy: 0.8708 - val_loss: 0.5710\n",
            "Epoch 29/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.8803e-04 - val_accuracy: 0.8804 - val_loss: 0.5761\n",
            "Epoch 30/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.3874e-04 - val_accuracy: 0.8708 - val_loss: 0.5838\n",
            "Epoch 31/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 994ms/step - accuracy: 1.0000 - loss: 3.9125e-04 - val_accuracy: 0.8708 - val_loss: 0.5911\n",
            "Epoch 32/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.8674e-04 - val_accuracy: 0.8852 - val_loss: 0.5922\n",
            "Epoch 33/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.3248e-04 - val_accuracy: 0.8708 - val_loss: 0.5997\n",
            "Epoch 34/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.8334e-04 - val_accuracy: 0.8708 - val_loss: 0.6096\n",
            "Epoch 35/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.5933e-04 - val_accuracy: 0.8852 - val_loss: 0.6108\n",
            "Epoch 36/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.2166e-04 - val_accuracy: 0.8708 - val_loss: 0.6203\n",
            "Epoch 37/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.2085e-04 - val_accuracy: 0.8852 - val_loss: 0.6217\n",
            "Epoch 38/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.1794e-04 - val_accuracy: 0.8852 - val_loss: 0.6286\n",
            "Epoch 39/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.6317e-04 - val_accuracy: 0.8708 - val_loss: 0.6346\n",
            "Epoch 40/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 990ms/step - accuracy: 1.0000 - loss: 1.6128e-04 - val_accuracy: 0.8708 - val_loss: 0.6429\n",
            "Epoch 41/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.5238e-04 - val_accuracy: 0.8708 - val_loss: 0.6516\n",
            "Epoch 42/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 984ms/step - accuracy: 1.0000 - loss: 1.4624e-04 - val_accuracy: 0.8756 - val_loss: 0.6515\n",
            "Epoch 43/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 997ms/step - accuracy: 1.0000 - loss: 1.1997e-04 - val_accuracy: 0.8708 - val_loss: 0.6548\n",
            "Epoch 44/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.1714e-04 - val_accuracy: 0.8804 - val_loss: 0.6582\n",
            "Epoch 45/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.1134e-04 - val_accuracy: 0.8804 - val_loss: 0.6658\n",
            "Epoch 46/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.1994e-04 - val_accuracy: 0.8804 - val_loss: 0.6730\n",
            "Epoch 47/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.1907e-05 - val_accuracy: 0.8804 - val_loss: 0.6755\n",
            "Epoch 48/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 8.6433e-05 - val_accuracy: 0.8804 - val_loss: 0.6814\n",
            "Epoch 49/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 8.4159e-05 - val_accuracy: 0.8804 - val_loss: 0.6892\n",
            "Epoch 50/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 7.2212e-05 - val_accuracy: 0.8756 - val_loss: 0.6944\n",
            "Epoch 51/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.3044e-05 - val_accuracy: 0.8804 - val_loss: 0.6967\n",
            "Epoch 52/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.4733e-05 - val_accuracy: 0.8804 - val_loss: 0.7017\n",
            "Epoch 53/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.9695e-05 - val_accuracy: 0.8804 - val_loss: 0.7076\n",
            "Epoch 54/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 975ms/step - accuracy: 1.0000 - loss: 5.2741e-05 - val_accuracy: 0.8804 - val_loss: 0.7111\n",
            "Epoch 55/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.8713e-05 - val_accuracy: 0.8804 - val_loss: 0.7138\n",
            "Epoch 56/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.4058e-05 - val_accuracy: 0.8804 - val_loss: 0.7159\n",
            "Epoch 57/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.8269e-05 - val_accuracy: 0.8804 - val_loss: 0.7226\n",
            "Epoch 58/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.6161e-05 - val_accuracy: 0.8804 - val_loss: 0.7249\n",
            "Epoch 59/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.1725e-05 - val_accuracy: 0.8804 - val_loss: 0.7304\n",
            "Epoch 60/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.8777e-05 - val_accuracy: 0.8804 - val_loss: 0.7334\n",
            "Epoch 61/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 983ms/step - accuracy: 1.0000 - loss: 3.4623e-05 - val_accuracy: 0.8804 - val_loss: 0.7373\n",
            "Epoch 62/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.1016e-05 - val_accuracy: 0.8804 - val_loss: 0.7411\n",
            "Epoch 63/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.5306e-05 - val_accuracy: 0.8804 - val_loss: 0.7445\n",
            "Epoch 64/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.9436e-05 - val_accuracy: 0.8852 - val_loss: 0.7485\n",
            "Epoch 65/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.3526e-05 - val_accuracy: 0.8804 - val_loss: 0.7535\n",
            "Epoch 66/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.6587e-05 - val_accuracy: 0.8804 - val_loss: 0.7560\n",
            "Epoch 67/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 998ms/step - accuracy: 1.0000 - loss: 2.3038e-05 - val_accuracy: 0.8804 - val_loss: 0.7614\n",
            "Epoch 68/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.2981e-05 - val_accuracy: 0.8804 - val_loss: 0.7638\n",
            "Epoch 69/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.3660e-05 - val_accuracy: 0.8804 - val_loss: 0.7652\n",
            "Epoch 70/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.2256e-05 - val_accuracy: 0.8804 - val_loss: 0.7710\n",
            "Epoch 71/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 987ms/step - accuracy: 1.0000 - loss: 1.8445e-05 - val_accuracy: 0.8852 - val_loss: 0.7741\n",
            "Epoch 72/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.6915e-05 - val_accuracy: 0.8852 - val_loss: 0.7806\n",
            "Epoch 73/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.6332e-05 - val_accuracy: 0.8852 - val_loss: 0.7858\n",
            "Epoch 74/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.5972e-05 - val_accuracy: 0.8852 - val_loss: 0.7886\n",
            "Epoch 75/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.4261e-05 - val_accuracy: 0.8852 - val_loss: 0.7893\n",
            "Epoch 76/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.2218e-05 - val_accuracy: 0.8852 - val_loss: 0.7941\n",
            "Epoch 77/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.3200e-05 - val_accuracy: 0.8852 - val_loss: 0.7934\n",
            "Epoch 78/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.2322e-05 - val_accuracy: 0.8852 - val_loss: 0.8004\n",
            "Epoch 79/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.2395e-05 - val_accuracy: 0.8852 - val_loss: 0.8018\n",
            "Epoch 80/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.2480e-05 - val_accuracy: 0.8804 - val_loss: 0.8015\n",
            "Epoch 81/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.2494e-05 - val_accuracy: 0.8852 - val_loss: 0.8052\n",
            "Epoch 82/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.1077e-05 - val_accuracy: 0.8852 - val_loss: 0.8064\n",
            "Epoch 83/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.0601e-05 - val_accuracy: 0.8852 - val_loss: 0.8091\n",
            "Epoch 84/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.0723e-05 - val_accuracy: 0.8852 - val_loss: 0.8151\n",
            "Epoch 85/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.1576e-06 - val_accuracy: 0.8852 - val_loss: 0.8175\n",
            "Epoch 86/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.4790e-06 - val_accuracy: 0.8852 - val_loss: 0.8201\n",
            "Epoch 87/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 8.2301e-06 - val_accuracy: 0.8852 - val_loss: 0.8191\n",
            "Epoch 88/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 8.9959e-06 - val_accuracy: 0.8852 - val_loss: 0.8213\n",
            "Epoch 89/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 8.5201e-06 - val_accuracy: 0.8852 - val_loss: 0.8245\n",
            "Epoch 90/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 7.8038e-06 - val_accuracy: 0.8852 - val_loss: 0.8317\n",
            "Epoch 91/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 7.8788e-06 - val_accuracy: 0.8852 - val_loss: 0.8293\n",
            "Epoch 92/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 7.8860e-06 - val_accuracy: 0.8852 - val_loss: 0.8314\n",
            "Epoch 93/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.8372e-06 - val_accuracy: 0.8852 - val_loss: 0.8325\n",
            "Epoch 94/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 987ms/step - accuracy: 1.0000 - loss: 6.5834e-06 - val_accuracy: 0.8852 - val_loss: 0.8391\n",
            "Epoch 95/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 978ms/step - accuracy: 1.0000 - loss: 6.1563e-06 - val_accuracy: 0.8852 - val_loss: 0.8423\n",
            "Epoch 96/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.0630e-06 - val_accuracy: 0.8852 - val_loss: 0.8407\n",
            "Epoch 97/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.3241e-06 - val_accuracy: 0.8852 - val_loss: 0.8470\n",
            "Epoch 98/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.3848e-06 - val_accuracy: 0.8852 - val_loss: 0.8444\n",
            "Epoch 99/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 972ms/step - accuracy: 1.0000 - loss: 5.8282e-06 - val_accuracy: 0.8852 - val_loss: 0.8467\n",
            "Epoch 100/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.9045e-06 - val_accuracy: 0.8852 - val_loss: 0.8487\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 10s/step\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.8728 - loss: 0.8132\n",
            "Test Accuracy: 0.8738\n",
            "F1 Score: 0.9093\n",
            "G-Mean: 0.8435\n",
            "Informedness (IBA): 0.6932\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🔬 200X Magnification\n",
        "\n",
        "- Dataset: 623 benign and 1390 malignant images.  \n",
        "- Benign samples oversampled to balance class sizes.  \n",
        "- Stratified splitting into train, val, and test sets.  \n",
        "- Preprocessing includes resizing and normalization.  \n",
        "- Architecture: VGG16 + Inception block.\n",
        "\n"
      ],
      "metadata": {
        "id": "lRRjjB2t1jdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, concatenate, AveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Define dataset paths\n",
        "benign_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/benign/200X\"\n",
        "malignant_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/malignant/200X\"\n",
        "\n",
        "def load_image_paths(dir_path):\n",
        "    return [os.path.join(dir_path, img) for img in os.listdir(dir_path) if img.endswith('.png')]\n",
        "\n",
        "benign_images = load_image_paths(benign_dir)\n",
        "malignant_images = load_image_paths(malignant_dir)\n",
        "\n",
        "print(f\"Total Benign Images: {len(benign_images)}\")\n",
        "print(f\"Total Malignant Images: {len(malignant_images)}\")\n",
        "\n",
        "benign_labels = [0] * len(benign_images)\n",
        "malignant_labels = [1] * len(malignant_images)\n",
        "\n",
        "all_images = np.array(benign_images + malignant_images)\n",
        "all_labels = np.array(benign_labels + malignant_labels)\n",
        "\n",
        "# Split dataset (60% train, 10% val, 30% test)\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(\n",
        "    all_images, all_labels, test_size=0.3, stratify=all_labels, random_state=42)\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(\n",
        "    train_images, train_labels, test_size=0.1429, stratify=train_labels, random_state=42)\n",
        "\n",
        "print(f\"Training samples: {len(train_images)}\")\n",
        "print(f\"Validation samples: {len(val_images)}\")\n",
        "print(f\"Testing samples: {len(test_images)}\")\n",
        "\n",
        "def process_path(file_path, label):\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_png(img, channels=3)\n",
        "    img = tf.image.resize(img, [224, 224])\n",
        "    img = img / 255.0\n",
        "    return img, label\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# ---------------------- OVERSAMPLING ----------------------\n",
        "train_images = np.array(train_images)\n",
        "train_labels = np.array(train_labels)\n",
        "\n",
        "benign_mask = train_labels == 0\n",
        "malignant_mask = train_labels == 1\n",
        "\n",
        "benign_images_train = train_images[benign_mask]\n",
        "malignant_images_train = train_images[malignant_mask]\n",
        "\n",
        "benign_labels_train = train_labels[benign_mask]\n",
        "malignant_labels_train = train_labels[malignant_mask]\n",
        "\n",
        "# Upsample benign to match malignant\n",
        "benign_images_upsampled, benign_labels_upsampled = resample(\n",
        "    benign_images_train,\n",
        "    benign_labels_train,\n",
        "    replace=True,\n",
        "    n_samples=len(malignant_images_train),\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Combine and shuffle\n",
        "oversampled_train_images = np.concatenate([malignant_images_train, benign_images_upsampled])\n",
        "oversampled_train_labels = np.concatenate([malignant_labels_train, benign_labels_upsampled])\n",
        "\n",
        "shuffle_idx = np.random.permutation(len(oversampled_train_images))\n",
        "oversampled_train_images = oversampled_train_images[shuffle_idx]\n",
        "oversampled_train_labels = oversampled_train_labels[shuffle_idx]\n",
        "\n",
        "# Create dataset pipelines\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((oversampled_train_images, oversampled_train_labels)) \\\n",
        "    .map(process_path).shuffle(1000).batch(BATCH_SIZE)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels)).map(process_path).batch(BATCH_SIZE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).map(process_path).batch(BATCH_SIZE)\n",
        "\n",
        "if sum(1 for _ in test_dataset) == 0:\n",
        "    raise ValueError(\"Testing dataset is empty. Adjust your dataset split.\")\n",
        "\n",
        "# ------------------ MODEL ------------------\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "def inception_block(x):\n",
        "    branch1 = Conv2D(64, (1, 1), activation='relu', padding='same')(x)\n",
        "\n",
        "    branch2 = Conv2D(64, (1, 1), activation='relu', padding='same')(x)\n",
        "    branch2 = Conv2D(128, (3, 3), activation='relu', padding='same')(branch2)\n",
        "\n",
        "    branch3 = Conv2D(64, (1, 1), activation='relu', padding='same')(x)\n",
        "    branch3 = Conv2D(128, (5, 5), activation='relu', padding='same')(branch3)\n",
        "\n",
        "    branch4 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "    branch4 = Conv2D(64, (1, 1), activation='relu', padding='same')(branch4)\n",
        "\n",
        "    output = concatenate([branch1, branch2, branch3, branch4], axis=-1)\n",
        "    return output\n",
        "\n",
        "# Add Inception block after VGG16\n",
        "x = inception_block(base_model.output)\n",
        "x = AveragePooling2D(pool_size=(2, 2))(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# ------------------ TRAIN ------------------\n",
        "EPOCHS = 100\n",
        "history = model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS)\n",
        "\n",
        "# ------------------ EVALUATION ------------------\n",
        "test_preds = model.predict(test_dataset)\n",
        "test_preds = (test_preds > 0.5).astype(int).flatten()\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(test_labels, test_preds).ravel()\n",
        "iba = (tp / (tp + fn)) + (tn / (tn + fp)) - 1\n",
        "\n",
        "f1 = f1_score(test_labels, test_preds)\n",
        "gmean = geometric_mean_score(test_labels, test_preds)\n",
        "\n",
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"G-Mean: {gmean:.4f}\")\n",
        "print(f\"Informedness (IBA): {iba:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iQPIAqHxDm-",
        "outputId": "0d0ba937-1d76-4b09-edfb-eed4ad32ed86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Benign Images: 623\n",
            "Total Malignant Images: 1390\n",
            "Training samples: 1207\n",
            "Validation samples: 202\n",
            "Testing samples: 604\n",
            "Epoch 1/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 8s/step - accuracy: 0.5615 - loss: 1.0097 - val_accuracy: 0.7376 - val_loss: 0.6642\n",
            "Epoch 2/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - accuracy: 0.7050 - loss: 0.6472 - val_accuracy: 0.6188 - val_loss: 0.6436\n",
            "Epoch 3/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 992ms/step - accuracy: 0.7239 - loss: 0.5488 - val_accuracy: 0.7376 - val_loss: 0.4997\n",
            "Epoch 4/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 933ms/step - accuracy: 0.7093 - loss: 0.5470 - val_accuracy: 0.5495 - val_loss: 0.7075\n",
            "Epoch 5/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 944ms/step - accuracy: 0.7503 - loss: 0.4749 - val_accuracy: 0.8267 - val_loss: 0.4074\n",
            "Epoch 6/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 948ms/step - accuracy: 0.8566 - loss: 0.3374 - val_accuracy: 0.7574 - val_loss: 0.5169\n",
            "Epoch 7/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 930ms/step - accuracy: 0.8617 - loss: 0.3227 - val_accuracy: 0.8614 - val_loss: 0.3528\n",
            "Epoch 8/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 955ms/step - accuracy: 0.8940 - loss: 0.2635 - val_accuracy: 0.8465 - val_loss: 0.3403\n",
            "Epoch 9/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 917ms/step - accuracy: 0.9264 - loss: 0.1953 - val_accuracy: 0.8168 - val_loss: 0.4077\n",
            "Epoch 10/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 958ms/step - accuracy: 0.9577 - loss: 0.1476 - val_accuracy: 0.8515 - val_loss: 0.3418\n",
            "Epoch 11/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 966ms/step - accuracy: 0.9739 - loss: 0.0903 - val_accuracy: 0.8564 - val_loss: 0.3514\n",
            "Epoch 12/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 0.9611 - loss: 0.1155 - val_accuracy: 0.8119 - val_loss: 0.4908\n",
            "Epoch 13/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - accuracy: 0.9677 - loss: 0.0870 - val_accuracy: 0.8366 - val_loss: 0.4700\n",
            "Epoch 14/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 0.9777 - loss: 0.0643 - val_accuracy: 0.8317 - val_loss: 0.3991\n",
            "Epoch 15/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 0.9935 - loss: 0.0357 - val_accuracy: 0.8465 - val_loss: 0.4634\n",
            "Epoch 16/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - accuracy: 0.9934 - loss: 0.0271 - val_accuracy: 0.8366 - val_loss: 0.4670\n",
            "Epoch 17/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 923ms/step - accuracy: 1.0000 - loss: 0.0115 - val_accuracy: 0.8366 - val_loss: 0.5002\n",
            "Epoch 18/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 928ms/step - accuracy: 1.0000 - loss: 0.0075 - val_accuracy: 0.8267 - val_loss: 0.5188\n",
            "Epoch 19/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 952ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.8267 - val_loss: 0.5364\n",
            "Epoch 20/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 974ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.8515 - val_loss: 0.5838\n",
            "Epoch 21/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 989ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.8515 - val_loss: 0.5884\n",
            "Epoch 22/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 945ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.8515 - val_loss: 0.5916\n",
            "Epoch 23/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 970ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.8465 - val_loss: 0.6046\n",
            "Epoch 24/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 929ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.8515 - val_loss: 0.6122\n",
            "Epoch 25/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.8515 - val_loss: 0.6339\n",
            "Epoch 26/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 926ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.8515 - val_loss: 0.6419\n",
            "Epoch 27/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 992ms/step - accuracy: 1.0000 - loss: 9.3138e-04 - val_accuracy: 0.8614 - val_loss: 0.6507\n",
            "Epoch 28/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 948ms/step - accuracy: 1.0000 - loss: 7.8860e-04 - val_accuracy: 0.8564 - val_loss: 0.6705\n",
            "Epoch 29/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 7.3476e-04 - val_accuracy: 0.8663 - val_loss: 0.6636\n",
            "Epoch 30/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 923ms/step - accuracy: 1.0000 - loss: 6.2560e-04 - val_accuracy: 0.8564 - val_loss: 0.6950\n",
            "Epoch 31/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.8223e-04 - val_accuracy: 0.8564 - val_loss: 0.6986\n",
            "Epoch 32/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 924ms/step - accuracy: 1.0000 - loss: 4.6867e-04 - val_accuracy: 0.8614 - val_loss: 0.7302\n",
            "Epoch 33/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.3563e-04 - val_accuracy: 0.8564 - val_loss: 0.7154\n",
            "Epoch 34/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 946ms/step - accuracy: 1.0000 - loss: 4.4866e-04 - val_accuracy: 0.8564 - val_loss: 0.7323\n",
            "Epoch 35/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 966ms/step - accuracy: 1.0000 - loss: 3.7345e-04 - val_accuracy: 0.8564 - val_loss: 0.7351\n",
            "Epoch 36/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 958ms/step - accuracy: 1.0000 - loss: 3.1411e-04 - val_accuracy: 0.8564 - val_loss: 0.7433\n",
            "Epoch 37/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.7020e-04 - val_accuracy: 0.8564 - val_loss: 0.7492\n",
            "Epoch 38/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 961ms/step - accuracy: 1.0000 - loss: 2.9367e-04 - val_accuracy: 0.8564 - val_loss: 0.7362\n",
            "Epoch 39/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.5878e-04 - val_accuracy: 0.8564 - val_loss: 0.7511\n",
            "Epoch 40/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.9501e-04 - val_accuracy: 0.8564 - val_loss: 0.7780\n",
            "Epoch 41/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 963ms/step - accuracy: 1.0000 - loss: 2.0482e-04 - val_accuracy: 0.8614 - val_loss: 0.7922\n",
            "Epoch 42/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.9838e-04 - val_accuracy: 0.8614 - val_loss: 0.7904\n",
            "Epoch 43/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 951ms/step - accuracy: 1.0000 - loss: 1.6431e-04 - val_accuracy: 0.8614 - val_loss: 0.8028\n",
            "Epoch 44/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 991ms/step - accuracy: 1.0000 - loss: 1.5074e-04 - val_accuracy: 0.8614 - val_loss: 0.8101\n",
            "Epoch 45/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 971ms/step - accuracy: 1.0000 - loss: 1.3336e-04 - val_accuracy: 0.8663 - val_loss: 0.8104\n",
            "Epoch 46/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 960ms/step - accuracy: 1.0000 - loss: 1.3472e-04 - val_accuracy: 0.8614 - val_loss: 0.8173\n",
            "Epoch 47/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.1777e-04 - val_accuracy: 0.8663 - val_loss: 0.8180\n",
            "Epoch 48/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 954ms/step - accuracy: 1.0000 - loss: 1.0829e-04 - val_accuracy: 0.8663 - val_loss: 0.8226\n",
            "Epoch 49/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.5220e-05 - val_accuracy: 0.8614 - val_loss: 0.8287\n",
            "Epoch 50/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 929ms/step - accuracy: 1.0000 - loss: 9.3039e-05 - val_accuracy: 0.8614 - val_loss: 0.8379\n",
            "Epoch 51/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.0293e-04 - val_accuracy: 0.8663 - val_loss: 0.8296\n",
            "Epoch 52/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 938ms/step - accuracy: 1.0000 - loss: 8.6978e-05 - val_accuracy: 0.8515 - val_loss: 0.8381\n",
            "Epoch 53/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 7.8887e-05 - val_accuracy: 0.8614 - val_loss: 0.8516\n",
            "Epoch 54/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 7.2772e-05 - val_accuracy: 0.8564 - val_loss: 0.8525\n",
            "Epoch 55/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 7.4055e-05 - val_accuracy: 0.8614 - val_loss: 0.8663\n",
            "Epoch 56/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.3536e-05 - val_accuracy: 0.8614 - val_loss: 0.8718\n",
            "Epoch 57/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 999ms/step - accuracy: 1.0000 - loss: 5.8018e-05 - val_accuracy: 0.8614 - val_loss: 0.8816\n",
            "Epoch 58/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.0784e-05 - val_accuracy: 0.8614 - val_loss: 0.8805\n",
            "Epoch 59/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.0347e-05 - val_accuracy: 0.8614 - val_loss: 0.8970\n",
            "Epoch 60/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 984ms/step - accuracy: 1.0000 - loss: 4.1866e-05 - val_accuracy: 0.8614 - val_loss: 0.9072\n",
            "Epoch 61/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 948ms/step - accuracy: 1.0000 - loss: 4.1625e-05 - val_accuracy: 0.8614 - val_loss: 0.9078\n",
            "Epoch 62/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 955ms/step - accuracy: 1.0000 - loss: 3.7746e-05 - val_accuracy: 0.8614 - val_loss: 0.9141\n",
            "Epoch 63/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.8287e-05 - val_accuracy: 0.8564 - val_loss: 0.9219\n",
            "Epoch 64/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 918ms/step - accuracy: 1.0000 - loss: 3.2151e-05 - val_accuracy: 0.8564 - val_loss: 0.9378\n",
            "Epoch 65/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.8512e-05 - val_accuracy: 0.8564 - val_loss: 0.9265\n",
            "Epoch 66/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.4080e-05 - val_accuracy: 0.8564 - val_loss: 0.9591\n",
            "Epoch 67/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 953ms/step - accuracy: 1.0000 - loss: 3.1783e-05 - val_accuracy: 0.8564 - val_loss: 0.9669\n",
            "Epoch 68/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 928ms/step - accuracy: 1.0000 - loss: 2.7320e-05 - val_accuracy: 0.8614 - val_loss: 0.9610\n",
            "Epoch 69/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.5675e-05 - val_accuracy: 0.8564 - val_loss: 0.9631\n",
            "Epoch 70/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.8425e-05 - val_accuracy: 0.8614 - val_loss: 0.9610\n",
            "Epoch 71/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.2966e-05 - val_accuracy: 0.8564 - val_loss: 0.9707\n",
            "Epoch 72/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 954ms/step - accuracy: 1.0000 - loss: 1.9430e-05 - val_accuracy: 0.8614 - val_loss: 0.9776\n",
            "Epoch 73/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.1218e-05 - val_accuracy: 0.8564 - val_loss: 0.9805\n",
            "Epoch 74/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.8849e-05 - val_accuracy: 0.8614 - val_loss: 0.9829\n",
            "Epoch 75/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 952ms/step - accuracy: 1.0000 - loss: 2.0639e-05 - val_accuracy: 0.8564 - val_loss: 0.9883\n",
            "Epoch 76/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.8867e-05 - val_accuracy: 0.8614 - val_loss: 0.9902\n",
            "Epoch 77/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.8442e-05 - val_accuracy: 0.8614 - val_loss: 0.9949\n",
            "Epoch 78/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.7337e-05 - val_accuracy: 0.8614 - val_loss: 0.9983\n",
            "Epoch 79/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.4629e-05 - val_accuracy: 0.8614 - val_loss: 1.0017\n",
            "Epoch 80/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 930ms/step - accuracy: 1.0000 - loss: 1.5751e-05 - val_accuracy: 0.8614 - val_loss: 1.0054\n",
            "Epoch 81/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 956ms/step - accuracy: 1.0000 - loss: 1.5768e-05 - val_accuracy: 0.8614 - val_loss: 1.0148\n",
            "Epoch 82/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.3340e-05 - val_accuracy: 0.8614 - val_loss: 1.0181\n",
            "Epoch 83/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.4655e-05 - val_accuracy: 0.8614 - val_loss: 1.0194\n",
            "Epoch 84/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.4196e-05 - val_accuracy: 0.8614 - val_loss: 1.0202\n",
            "Epoch 85/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.3237e-05 - val_accuracy: 0.8614 - val_loss: 1.0158\n",
            "Epoch 86/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.4567e-05 - val_accuracy: 0.8614 - val_loss: 1.0272\n",
            "Epoch 87/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.0997e-05 - val_accuracy: 0.8614 - val_loss: 1.0289\n",
            "Epoch 88/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.1729e-05 - val_accuracy: 0.8614 - val_loss: 1.0335\n",
            "Epoch 89/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 934ms/step - accuracy: 1.0000 - loss: 1.0625e-05 - val_accuracy: 0.8614 - val_loss: 1.0353\n",
            "Epoch 90/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.0663e-05 - val_accuracy: 0.8614 - val_loss: 1.0373\n",
            "Epoch 91/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 994ms/step - accuracy: 1.0000 - loss: 1.0743e-05 - val_accuracy: 0.8614 - val_loss: 1.0367\n",
            "Epoch 92/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.0390e-05 - val_accuracy: 0.8614 - val_loss: 1.0403\n",
            "Epoch 93/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.9907e-06 - val_accuracy: 0.8614 - val_loss: 1.0457\n",
            "Epoch 94/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.8377e-06 - val_accuracy: 0.8564 - val_loss: 1.0460\n",
            "Epoch 95/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.1379e-06 - val_accuracy: 0.8564 - val_loss: 1.0493\n",
            "Epoch 96/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.7775e-06 - val_accuracy: 0.8564 - val_loss: 1.0545\n",
            "Epoch 97/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.3053e-06 - val_accuracy: 0.8515 - val_loss: 1.0617\n",
            "Epoch 98/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 8.2919e-06 - val_accuracy: 0.8564 - val_loss: 1.0611\n",
            "Epoch 99/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 8.3398e-06 - val_accuracy: 0.8564 - val_loss: 1.0598\n",
            "Epoch 100/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 921ms/step - accuracy: 1.0000 - loss: 8.2271e-06 - val_accuracy: 0.8564 - val_loss: 1.0639\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f2986379800> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 1s/step   "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f2986379800> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 8s/step\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.8764 - loss: 0.7680\n",
            "Test Accuracy: 0.8808\n",
            "F1 Score: 0.9149\n",
            "G-Mean: 0.8483\n",
            "Informedness (IBA): 0.7035\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🔬 400X Magnification\n",
        "\n",
        "- Dataset: 588 benign and 1232 malignant images.  \n",
        "- Oversampling balances benign class in training.  \n",
        "- Data split: 60% train, 10% val, 30% test using stratification.  \n",
        "- Images resized to 224×224, normalized.  \n",
        "- Model: Frozen VGG16 base + custom Inception block.\n"
      ],
      "metadata": {
        "id": "15LwiaDp1ok0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, concatenate, AveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Define dataset paths\n",
        "benign_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/benign/400X\"\n",
        "malignant_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/malignant/400X\"\n",
        "\n",
        "def load_image_paths(dir_path):\n",
        "    return [os.path.join(dir_path, img) for img in os.listdir(dir_path) if img.endswith('.png')]\n",
        "\n",
        "benign_images = load_image_paths(benign_dir)\n",
        "malignant_images = load_image_paths(malignant_dir)\n",
        "\n",
        "print(f\"Total Benign Images: {len(benign_images)}\")\n",
        "print(f\"Total Malignant Images: {len(malignant_images)}\")\n",
        "\n",
        "benign_labels = [0] * len(benign_images)\n",
        "malignant_labels = [1] * len(malignant_images)\n",
        "\n",
        "all_images = np.array(benign_images + malignant_images)\n",
        "all_labels = np.array(benign_labels + malignant_labels)\n",
        "\n",
        "# Split dataset (60% train, 10% val, 30% test)\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(\n",
        "    all_images, all_labels, test_size=0.3, stratify=all_labels, random_state=42)\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(\n",
        "    train_images, train_labels, test_size=0.1429, stratify=train_labels, random_state=42)\n",
        "\n",
        "print(f\"Training samples: {len(train_images)}\")\n",
        "print(f\"Validation samples: {len(val_images)}\")\n",
        "print(f\"Testing samples: {len(test_images)}\")\n",
        "\n",
        "def process_path(file_path, label):\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_png(img, channels=3)\n",
        "    img = tf.image.resize(img, [224, 224])\n",
        "    img = img / 255.0\n",
        "    return img, label\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# ---------------------- OVERSAMPLING ----------------------\n",
        "train_images = np.array(train_images)\n",
        "train_labels = np.array(train_labels)\n",
        "\n",
        "benign_mask = train_labels == 0\n",
        "malignant_mask = train_labels == 1\n",
        "\n",
        "benign_images_train = train_images[benign_mask]\n",
        "malignant_images_train = train_images[malignant_mask]\n",
        "\n",
        "benign_labels_train = train_labels[benign_mask]\n",
        "malignant_labels_train = train_labels[malignant_mask]\n",
        "\n",
        "# Upsample benign to match malignant\n",
        "benign_images_upsampled, benign_labels_upsampled = resample(\n",
        "    benign_images_train,\n",
        "    benign_labels_train,\n",
        "    replace=True,\n",
        "    n_samples=len(malignant_images_train),\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Combine and shuffle\n",
        "oversampled_train_images = np.concatenate([malignant_images_train, benign_images_upsampled])\n",
        "oversampled_train_labels = np.concatenate([malignant_labels_train, benign_labels_upsampled])\n",
        "\n",
        "shuffle_idx = np.random.permutation(len(oversampled_train_images))\n",
        "oversampled_train_images = oversampled_train_images[shuffle_idx]\n",
        "oversampled_train_labels = oversampled_train_labels[shuffle_idx]\n",
        "\n",
        "# Create dataset pipelines\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((oversampled_train_images, oversampled_train_labels)) \\\n",
        "    .map(process_path).shuffle(1000).batch(BATCH_SIZE)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels)).map(process_path).batch(BATCH_SIZE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).map(process_path).batch(BATCH_SIZE)\n",
        "\n",
        "if sum(1 for _ in test_dataset) == 0:\n",
        "    raise ValueError(\"Testing dataset is empty. Adjust your dataset split.\")\n",
        "\n",
        "# ------------------ MODEL ------------------\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "def inception_block(x):\n",
        "    branch1 = Conv2D(64, (1, 1), activation='relu', padding='same')(x)\n",
        "\n",
        "    branch2 = Conv2D(64, (1, 1), activation='relu', padding='same')(x)\n",
        "    branch2 = Conv2D(128, (3, 3), activation='relu', padding='same')(branch2)\n",
        "\n",
        "    branch3 = Conv2D(64, (1, 1), activation='relu', padding='same')(x)\n",
        "    branch3 = Conv2D(128, (5, 5), activation='relu', padding='same')(branch3)\n",
        "\n",
        "    branch4 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "    branch4 = Conv2D(64, (1, 1), activation='relu', padding='same')(branch4)\n",
        "\n",
        "    output = concatenate([branch1, branch2, branch3, branch4], axis=-1)\n",
        "    return output\n",
        "\n",
        "# Add Inception block after VGG16\n",
        "x = inception_block(base_model.output)\n",
        "x = AveragePooling2D(pool_size=(2, 2))(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# ------------------ TRAIN ------------------\n",
        "EPOCHS = 100\n",
        "history = model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS)\n",
        "\n",
        "# ------------------ EVALUATION ------------------\n",
        "test_preds = model.predict(test_dataset)\n",
        "test_preds = (test_preds > 0.5).astype(int).flatten()\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(test_labels, test_preds).ravel()\n",
        "iba = (tp / (tp + fn)) + (tn / (tn + fp)) - 1\n",
        "\n",
        "f1 = f1_score(test_labels, test_preds)\n",
        "gmean = geometric_mean_score(test_labels, test_preds)\n",
        "\n",
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"G-Mean: {gmean:.4f}\")\n",
        "print(f\"Informedness (IBA): {iba:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGg6GhMAxEPE",
        "outputId": "4dd23893-4fdb-4d7e-f00d-24edef0c6732"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Benign Images: 588\n",
            "Total Malignant Images: 1232\n",
            "Training samples: 1091\n",
            "Validation samples: 183\n",
            "Testing samples: 546\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
            "Epoch 1/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 7s/step - accuracy: 0.4984 - loss: 1.1057 - val_accuracy: 0.6776 - val_loss: 0.6253\n",
            "Epoch 2/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 965ms/step - accuracy: 0.5338 - loss: 0.6902 - val_accuracy: 0.7049 - val_loss: 0.6597\n",
            "Epoch 3/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 924ms/step - accuracy: 0.6980 - loss: 0.6476 - val_accuracy: 0.7541 - val_loss: 0.5678\n",
            "Epoch 4/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 916ms/step - accuracy: 0.7209 - loss: 0.5818 - val_accuracy: 0.7158 - val_loss: 0.5600\n",
            "Epoch 5/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 0.7660 - loss: 0.5034 - val_accuracy: 0.7760 - val_loss: 0.4286\n",
            "Epoch 6/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 920ms/step - accuracy: 0.8104 - loss: 0.4198 - val_accuracy: 0.6995 - val_loss: 0.5877\n",
            "Epoch 7/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 871ms/step - accuracy: 0.8408 - loss: 0.3574 - val_accuracy: 0.8306 - val_loss: 0.3600\n",
            "Epoch 8/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 938ms/step - accuracy: 0.8856 - loss: 0.2881 - val_accuracy: 0.8415 - val_loss: 0.3336\n",
            "Epoch 9/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 873ms/step - accuracy: 0.9249 - loss: 0.2252 - val_accuracy: 0.8743 - val_loss: 0.3084\n",
            "Epoch 10/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - accuracy: 0.9334 - loss: 0.1861 - val_accuracy: 0.8798 - val_loss: 0.3475\n",
            "Epoch 11/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 933ms/step - accuracy: 0.9537 - loss: 0.1532 - val_accuracy: 0.8798 - val_loss: 0.3136\n",
            "Epoch 12/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - accuracy: 0.9563 - loss: 0.1260 - val_accuracy: 0.8798 - val_loss: 0.3166\n",
            "Epoch 13/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 977ms/step - accuracy: 0.9795 - loss: 0.0820 - val_accuracy: 0.8852 - val_loss: 0.3123\n",
            "Epoch 14/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.9862 - loss: 0.0553 - val_accuracy: 0.8470 - val_loss: 0.4205\n",
            "Epoch 15/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 877ms/step - accuracy: 0.9652 - loss: 0.0884 - val_accuracy: 0.8907 - val_loss: 0.3255\n",
            "Epoch 16/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 903ms/step - accuracy: 0.9923 - loss: 0.0411 - val_accuracy: 0.8852 - val_loss: 0.3357\n",
            "Epoch 17/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.9980 - loss: 0.0266 - val_accuracy: 0.8579 - val_loss: 0.3693\n",
            "Epoch 18/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 934ms/step - accuracy: 0.9979 - loss: 0.0241 - val_accuracy: 0.8634 - val_loss: 0.4344\n",
            "Epoch 19/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 951ms/step - accuracy: 0.9970 - loss: 0.0205 - val_accuracy: 0.8743 - val_loss: 0.3992\n",
            "Epoch 20/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 866ms/step - accuracy: 1.0000 - loss: 0.0147 - val_accuracy: 0.8634 - val_loss: 0.3963\n",
            "Epoch 21/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 893ms/step - accuracy: 1.0000 - loss: 0.0093 - val_accuracy: 0.8525 - val_loss: 0.4989\n",
            "Epoch 22/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 919ms/step - accuracy: 1.0000 - loss: 0.0107 - val_accuracy: 0.8579 - val_loss: 0.4259\n",
            "Epoch 23/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 882ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.8470 - val_loss: 0.4500\n",
            "Epoch 24/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 959ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.8470 - val_loss: 0.4569\n",
            "Epoch 25/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 984ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.8525 - val_loss: 0.4613\n",
            "Epoch 26/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 867ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.8470 - val_loss: 0.4607\n",
            "Epoch 27/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 921ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.8470 - val_loss: 0.4663\n",
            "Epoch 28/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 915ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.8525 - val_loss: 0.4950\n",
            "Epoch 29/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 989ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.8415 - val_loss: 0.4913\n",
            "Epoch 30/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 940ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.8415 - val_loss: 0.4950\n",
            "Epoch 31/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.8470 - val_loss: 0.5075\n",
            "Epoch 32/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 925ms/step - accuracy: 1.0000 - loss: 9.7649e-04 - val_accuracy: 0.8415 - val_loss: 0.5081\n",
            "Epoch 33/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.3972e-04 - val_accuracy: 0.8415 - val_loss: 0.5152\n",
            "Epoch 34/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 882ms/step - accuracy: 1.0000 - loss: 8.7767e-04 - val_accuracy: 0.8470 - val_loss: 0.5123\n",
            "Epoch 35/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 891ms/step - accuracy: 1.0000 - loss: 7.0616e-04 - val_accuracy: 0.8415 - val_loss: 0.5354\n",
            "Epoch 36/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 926ms/step - accuracy: 1.0000 - loss: 7.5172e-04 - val_accuracy: 0.8415 - val_loss: 0.5443\n",
            "Epoch 37/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.9399e-04 - val_accuracy: 0.8415 - val_loss: 0.5345\n",
            "Epoch 38/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 928ms/step - accuracy: 1.0000 - loss: 5.8424e-04 - val_accuracy: 0.8415 - val_loss: 0.5450\n",
            "Epoch 39/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 924ms/step - accuracy: 1.0000 - loss: 4.8335e-04 - val_accuracy: 0.8525 - val_loss: 0.5340\n",
            "Epoch 40/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 977ms/step - accuracy: 1.0000 - loss: 5.2027e-04 - val_accuracy: 0.8525 - val_loss: 0.5433\n",
            "Epoch 41/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 968ms/step - accuracy: 1.0000 - loss: 4.1262e-04 - val_accuracy: 0.8525 - val_loss: 0.5454\n",
            "Epoch 42/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 989ms/step - accuracy: 1.0000 - loss: 3.7360e-04 - val_accuracy: 0.8525 - val_loss: 0.5531\n",
            "Epoch 43/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 881ms/step - accuracy: 1.0000 - loss: 3.3683e-04 - val_accuracy: 0.8579 - val_loss: 0.5543\n",
            "Epoch 44/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 959ms/step - accuracy: 1.0000 - loss: 3.4506e-04 - val_accuracy: 0.8525 - val_loss: 0.5668\n",
            "Epoch 45/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 962ms/step - accuracy: 1.0000 - loss: 3.0465e-04 - val_accuracy: 0.8525 - val_loss: 0.5710\n",
            "Epoch 46/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 908ms/step - accuracy: 1.0000 - loss: 2.8336e-04 - val_accuracy: 0.8525 - val_loss: 0.5827\n",
            "Epoch 47/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.7456e-04 - val_accuracy: 0.8525 - val_loss: 0.5882\n",
            "Epoch 48/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 948ms/step - accuracy: 1.0000 - loss: 2.2797e-04 - val_accuracy: 0.8470 - val_loss: 0.5968\n",
            "Epoch 49/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.3146e-04 - val_accuracy: 0.8470 - val_loss: 0.6071\n",
            "Epoch 50/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 947ms/step - accuracy: 1.0000 - loss: 2.1434e-04 - val_accuracy: 0.8470 - val_loss: 0.6110\n",
            "Epoch 51/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 878ms/step - accuracy: 1.0000 - loss: 2.0419e-04 - val_accuracy: 0.8470 - val_loss: 0.6192\n",
            "Epoch 52/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 904ms/step - accuracy: 1.0000 - loss: 1.8525e-04 - val_accuracy: 0.8525 - val_loss: 0.6147\n",
            "Epoch 53/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 924ms/step - accuracy: 1.0000 - loss: 1.8206e-04 - val_accuracy: 0.8525 - val_loss: 0.6164\n",
            "Epoch 54/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 918ms/step - accuracy: 1.0000 - loss: 1.5418e-04 - val_accuracy: 0.8470 - val_loss: 0.6265\n",
            "Epoch 55/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 897ms/step - accuracy: 1.0000 - loss: 1.4476e-04 - val_accuracy: 0.8470 - val_loss: 0.6329\n",
            "Epoch 56/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 952ms/step - accuracy: 1.0000 - loss: 1.2997e-04 - val_accuracy: 0.8525 - val_loss: 0.6280\n",
            "Epoch 57/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.3517e-04 - val_accuracy: 0.8525 - val_loss: 0.6342\n",
            "Epoch 58/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 922ms/step - accuracy: 1.0000 - loss: 1.2241e-04 - val_accuracy: 0.8470 - val_loss: 0.6512\n",
            "Epoch 59/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 948ms/step - accuracy: 1.0000 - loss: 1.2023e-04 - val_accuracy: 0.8470 - val_loss: 0.6503\n",
            "Epoch 60/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.0339e-04 - val_accuracy: 0.8525 - val_loss: 0.6452\n",
            "Epoch 61/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 913ms/step - accuracy: 1.0000 - loss: 1.0733e-04 - val_accuracy: 0.8470 - val_loss: 0.6555\n",
            "Epoch 62/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 921ms/step - accuracy: 1.0000 - loss: 9.4625e-05 - val_accuracy: 0.8470 - val_loss: 0.6663\n",
            "Epoch 63/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 859ms/step - accuracy: 1.0000 - loss: 8.9291e-05 - val_accuracy: 0.8470 - val_loss: 0.6706\n",
            "Epoch 64/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 973ms/step - accuracy: 1.0000 - loss: 8.8818e-05 - val_accuracy: 0.8525 - val_loss: 0.6688\n",
            "Epoch 65/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 8.2131e-05 - val_accuracy: 0.8525 - val_loss: 0.6704\n",
            "Epoch 66/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 845ms/step - accuracy: 1.0000 - loss: 8.0889e-05 - val_accuracy: 0.8470 - val_loss: 0.6844\n",
            "Epoch 67/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 918ms/step - accuracy: 1.0000 - loss: 7.1425e-05 - val_accuracy: 0.8470 - val_loss: 0.6948\n",
            "Epoch 68/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 922ms/step - accuracy: 1.0000 - loss: 6.9153e-05 - val_accuracy: 0.8470 - val_loss: 0.6936\n",
            "Epoch 69/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.5644e-05 - val_accuracy: 0.8579 - val_loss: 0.6857\n",
            "Epoch 70/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 881ms/step - accuracy: 1.0000 - loss: 6.1397e-05 - val_accuracy: 0.8470 - val_loss: 0.6958\n",
            "Epoch 71/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.8283e-05 - val_accuracy: 0.8470 - val_loss: 0.7053\n",
            "Epoch 72/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 915ms/step - accuracy: 1.0000 - loss: 5.5734e-05 - val_accuracy: 0.8470 - val_loss: 0.7095\n",
            "Epoch 73/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 927ms/step - accuracy: 1.0000 - loss: 5.5090e-05 - val_accuracy: 0.8579 - val_loss: 0.7024\n",
            "Epoch 74/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 961ms/step - accuracy: 1.0000 - loss: 4.8800e-05 - val_accuracy: 0.8470 - val_loss: 0.7111\n",
            "Epoch 75/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 909ms/step - accuracy: 1.0000 - loss: 5.0943e-05 - val_accuracy: 0.8470 - val_loss: 0.7215\n",
            "Epoch 76/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 878ms/step - accuracy: 1.0000 - loss: 4.9020e-05 - val_accuracy: 0.8470 - val_loss: 0.7155\n",
            "Epoch 77/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 925ms/step - accuracy: 1.0000 - loss: 4.3163e-05 - val_accuracy: 0.8470 - val_loss: 0.7222\n",
            "Epoch 78/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 858ms/step - accuracy: 1.0000 - loss: 4.0952e-05 - val_accuracy: 0.8579 - val_loss: 0.7198\n",
            "Epoch 79/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.9999e-05 - val_accuracy: 0.8470 - val_loss: 0.7288\n",
            "Epoch 80/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 923ms/step - accuracy: 1.0000 - loss: 4.0803e-05 - val_accuracy: 0.8470 - val_loss: 0.7399\n",
            "Epoch 81/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 994ms/step - accuracy: 1.0000 - loss: 3.6039e-05 - val_accuracy: 0.8525 - val_loss: 0.7304\n",
            "Epoch 82/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 941ms/step - accuracy: 1.0000 - loss: 3.6509e-05 - val_accuracy: 0.8470 - val_loss: 0.7445\n",
            "Epoch 83/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.6987e-05 - val_accuracy: 0.8470 - val_loss: 0.7402\n",
            "Epoch 84/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 942ms/step - accuracy: 1.0000 - loss: 3.3630e-05 - val_accuracy: 0.8470 - val_loss: 0.7475\n",
            "Epoch 85/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 907ms/step - accuracy: 1.0000 - loss: 3.1876e-05 - val_accuracy: 0.8470 - val_loss: 0.7554\n",
            "Epoch 86/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 968ms/step - accuracy: 1.0000 - loss: 3.1784e-05 - val_accuracy: 0.8470 - val_loss: 0.7506\n",
            "Epoch 87/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 932ms/step - accuracy: 1.0000 - loss: 2.8972e-05 - val_accuracy: 0.8525 - val_loss: 0.7501\n",
            "Epoch 88/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 890ms/step - accuracy: 1.0000 - loss: 2.8165e-05 - val_accuracy: 0.8470 - val_loss: 0.7614\n",
            "Epoch 89/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 983ms/step - accuracy: 1.0000 - loss: 2.6017e-05 - val_accuracy: 0.8470 - val_loss: 0.7606\n",
            "Epoch 90/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 885ms/step - accuracy: 1.0000 - loss: 2.5765e-05 - val_accuracy: 0.8470 - val_loss: 0.7681\n",
            "Epoch 91/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 913ms/step - accuracy: 1.0000 - loss: 2.4533e-05 - val_accuracy: 0.8525 - val_loss: 0.7667\n",
            "Epoch 92/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 906ms/step - accuracy: 1.0000 - loss: 2.4542e-05 - val_accuracy: 0.8470 - val_loss: 0.7753\n",
            "Epoch 93/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 923ms/step - accuracy: 1.0000 - loss: 2.4800e-05 - val_accuracy: 0.8470 - val_loss: 0.7836\n",
            "Epoch 94/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.1612e-05 - val_accuracy: 0.8470 - val_loss: 0.7855\n",
            "Epoch 95/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 868ms/step - accuracy: 1.0000 - loss: 1.8993e-05 - val_accuracy: 0.8470 - val_loss: 0.7922\n",
            "Epoch 96/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 890ms/step - accuracy: 1.0000 - loss: 1.9461e-05 - val_accuracy: 0.8470 - val_loss: 0.7978\n",
            "Epoch 97/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 984ms/step - accuracy: 1.0000 - loss: 1.8229e-05 - val_accuracy: 0.8470 - val_loss: 0.7995\n",
            "Epoch 98/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 921ms/step - accuracy: 1.0000 - loss: 1.8022e-05 - val_accuracy: 0.8525 - val_loss: 0.8025\n",
            "Epoch 99/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 999ms/step - accuracy: 1.0000 - loss: 1.6623e-05 - val_accuracy: 0.8525 - val_loss: 0.8093\n",
            "Epoch 100/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 860ms/step - accuracy: 1.0000 - loss: 1.4083e-05 - val_accuracy: 0.8525 - val_loss: 0.8126\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4s/step\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.8659 - loss: 0.9864\n",
            "Test Accuracy: 0.8571\n",
            "F1 Score: 0.8963\n",
            "G-Mean: 0.8234\n",
            "Informedness (IBA): 0.6551\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The new metric values for each magnification:"
      ],
      "metadata": {
        "id": "Gq0bAuvfyY1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Metrics from the last provided values\n",
        "data = {\n",
        "    'Magnification': ['40X', '100X', '200X', '400X'],\n",
        "    'Test Accuracy': [0.9015, 0.8738, 0.8808, 0.8571],\n",
        "    'F1 Score': [0.9287, 0.9093, 0.9149, 0.8963],\n",
        "    'G-Mean': [0.8805, 0.8435, 0.8483, 0.8234],\n",
        "    'Informedness (IBA)': [0.7641, 0.6932, 0.7035, 0.6551]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Style the DataFrame for display\n",
        "styled_df = df.style \\\n",
        "    .format({\n",
        "        'Test Accuracy': '{:.4f}',\n",
        "        'F1 Score': '{:.4f}',\n",
        "        'G-Mean': '{:.4f}',\n",
        "        'Informedness (IBA)': '{:.4f}'\n",
        "    }) \\\n",
        "    .set_properties(**{'text-align': 'center'}) \\\n",
        "    .set_table_styles([{\n",
        "        'selector': 'th',\n",
        "        'props': [('background-color', '#000000'), ('color', 'white'), ('font-weight', 'bold')]\n",
        "    }]) \\\n",
        "    .hide(axis='index')\n",
        "\n",
        "styled_df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "s_9uPL5ZyRhs",
        "outputId": "b1922d71-c546-407e-eba6-916ee666faf9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7b4f0d78b810>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_0b925 th {\n",
              "  background-color: #000000;\n",
              "  color: white;\n",
              "  font-weight: bold;\n",
              "}\n",
              "#T_0b925_row0_col0, #T_0b925_row0_col1, #T_0b925_row0_col2, #T_0b925_row0_col3, #T_0b925_row0_col4, #T_0b925_row1_col0, #T_0b925_row1_col1, #T_0b925_row1_col2, #T_0b925_row1_col3, #T_0b925_row1_col4, #T_0b925_row2_col0, #T_0b925_row2_col1, #T_0b925_row2_col2, #T_0b925_row2_col3, #T_0b925_row2_col4, #T_0b925_row3_col0, #T_0b925_row3_col1, #T_0b925_row3_col2, #T_0b925_row3_col3, #T_0b925_row3_col4 {\n",
              "  text-align: center;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_0b925\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th id=\"T_0b925_level0_col0\" class=\"col_heading level0 col0\" >Magnification</th>\n",
              "      <th id=\"T_0b925_level0_col1\" class=\"col_heading level0 col1\" >Test Accuracy</th>\n",
              "      <th id=\"T_0b925_level0_col2\" class=\"col_heading level0 col2\" >F1 Score</th>\n",
              "      <th id=\"T_0b925_level0_col3\" class=\"col_heading level0 col3\" >G-Mean</th>\n",
              "      <th id=\"T_0b925_level0_col4\" class=\"col_heading level0 col4\" >Informedness (IBA)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td id=\"T_0b925_row0_col0\" class=\"data row0 col0\" >40X</td>\n",
              "      <td id=\"T_0b925_row0_col1\" class=\"data row0 col1\" >0.9015</td>\n",
              "      <td id=\"T_0b925_row0_col2\" class=\"data row0 col2\" >0.9287</td>\n",
              "      <td id=\"T_0b925_row0_col3\" class=\"data row0 col3\" >0.8805</td>\n",
              "      <td id=\"T_0b925_row0_col4\" class=\"data row0 col4\" >0.7641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_0b925_row1_col0\" class=\"data row1 col0\" >100X</td>\n",
              "      <td id=\"T_0b925_row1_col1\" class=\"data row1 col1\" >0.8738</td>\n",
              "      <td id=\"T_0b925_row1_col2\" class=\"data row1 col2\" >0.9093</td>\n",
              "      <td id=\"T_0b925_row1_col3\" class=\"data row1 col3\" >0.8435</td>\n",
              "      <td id=\"T_0b925_row1_col4\" class=\"data row1 col4\" >0.6932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_0b925_row2_col0\" class=\"data row2 col0\" >200X</td>\n",
              "      <td id=\"T_0b925_row2_col1\" class=\"data row2 col1\" >0.8808</td>\n",
              "      <td id=\"T_0b925_row2_col2\" class=\"data row2 col2\" >0.9149</td>\n",
              "      <td id=\"T_0b925_row2_col3\" class=\"data row2 col3\" >0.8483</td>\n",
              "      <td id=\"T_0b925_row2_col4\" class=\"data row2 col4\" >0.7035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_0b925_row3_col0\" class=\"data row3 col0\" >400X</td>\n",
              "      <td id=\"T_0b925_row3_col1\" class=\"data row3 col1\" >0.8571</td>\n",
              "      <td id=\"T_0b925_row3_col2\" class=\"data row3 col2\" >0.8963</td>\n",
              "      <td id=\"T_0b925_row3_col3\" class=\"data row3 col3\" >0.8234</td>\n",
              "      <td id=\"T_0b925_row3_col4\" class=\"data row3 col4\" >0.6551</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FaQSYQhHySPU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}