{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 🔬 Multi-Magnification Breast Classification using VGG16 + Inception Block by performing Undersampling"
      ],
      "metadata": {
        "id": "1k0oLksS2MYF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 40X Magnification\n",
        "\n",
        "In this experiment, histopathology images at 40X magnification were used for binary classification (benign vs. malignant).\n",
        "Undersampling was applied to balance the classes and avoid model bias toward the malignant class.\n",
        "Despite the lower resolution, the model showed decent performance in distinguishing patterns.\n"
      ],
      "metadata": {
        "id": "xFmvvrOqzf9z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xN5Lb9BDpuuJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13b938d4-5d74-46a2-8ee1-613403353d47"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Benign Images: 626\n",
            "Original Malignant Images: 1370\n",
            "Undersampled Malignant Images: 626\n",
            "Training samples: 750\n",
            "Validation samples: 126\n",
            "Testing samples: 376\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
            "Epoch 1/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m355s\u001b[0m 23s/step - accuracy: 0.5027 - loss: 1.0843 - val_accuracy: 0.5000 - val_loss: 0.6969\n",
            "Epoch 2/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 0.5226 - loss: 0.6935 - val_accuracy: 0.5000 - val_loss: 0.6787\n",
            "Epoch 3/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.6069 - loss: 0.6621 - val_accuracy: 0.7063 - val_loss: 0.6418\n",
            "Epoch 4/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.6920 - loss: 0.6206 - val_accuracy: 0.6984 - val_loss: 0.6043\n",
            "Epoch 5/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 896ms/step - accuracy: 0.7189 - loss: 0.5830 - val_accuracy: 0.6667 - val_loss: 0.6102\n",
            "Epoch 6/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 943ms/step - accuracy: 0.6834 - loss: 0.5771 - val_accuracy: 0.6984 - val_loss: 0.5924\n",
            "Epoch 7/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.7506 - loss: 0.5317 - val_accuracy: 0.7460 - val_loss: 0.5407\n",
            "Epoch 8/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 995ms/step - accuracy: 0.7753 - loss: 0.4863 - val_accuracy: 0.7540 - val_loss: 0.5057\n",
            "Epoch 9/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.7965 - loss: 0.4650 - val_accuracy: 0.7778 - val_loss: 0.4682\n",
            "Epoch 10/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.8298 - loss: 0.3968 - val_accuracy: 0.8175 - val_loss: 0.4365\n",
            "Epoch 11/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 883ms/step - accuracy: 0.8651 - loss: 0.3372 - val_accuracy: 0.8333 - val_loss: 0.4091\n",
            "Epoch 12/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 895ms/step - accuracy: 0.8479 - loss: 0.3292 - val_accuracy: 0.8095 - val_loss: 0.4548\n",
            "Epoch 13/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.8890 - loss: 0.2900 - val_accuracy: 0.7778 - val_loss: 0.4918\n",
            "Epoch 14/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.8766 - loss: 0.3004 - val_accuracy: 0.8571 - val_loss: 0.3920\n",
            "Epoch 15/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.9322 - loss: 0.2207 - val_accuracy: 0.8730 - val_loss: 0.3623\n",
            "Epoch 16/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.9485 - loss: 0.1805 - val_accuracy: 0.8492 - val_loss: 0.3791\n",
            "Epoch 17/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 0.9680 - loss: 0.1481 - val_accuracy: 0.8571 - val_loss: 0.3528\n",
            "Epoch 18/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 884ms/step - accuracy: 0.9710 - loss: 0.1256 - val_accuracy: 0.8492 - val_loss: 0.3570\n",
            "Epoch 19/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.9839 - loss: 0.0973 - val_accuracy: 0.8651 - val_loss: 0.3604\n",
            "Epoch 20/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.9759 - loss: 0.0994 - val_accuracy: 0.8730 - val_loss: 0.3438\n",
            "Epoch 21/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.9735 - loss: 0.1012 - val_accuracy: 0.7540 - val_loss: 0.6408\n",
            "Epoch 22/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.9500 - loss: 0.1245 - val_accuracy: 0.7619 - val_loss: 0.5536\n",
            "Epoch 23/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 0.9693 - loss: 0.0978 - val_accuracy: 0.8254 - val_loss: 0.4047\n",
            "Epoch 24/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 889ms/step - accuracy: 0.9786 - loss: 0.0684 - val_accuracy: 0.8730 - val_loss: 0.3833\n",
            "Epoch 25/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 892ms/step - accuracy: 0.9907 - loss: 0.0496 - val_accuracy: 0.8571 - val_loss: 0.4105\n",
            "Epoch 26/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 898ms/step - accuracy: 0.9954 - loss: 0.0372 - val_accuracy: 0.8254 - val_loss: 0.4696\n",
            "Epoch 27/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 922ms/step - accuracy: 0.9940 - loss: 0.0351 - val_accuracy: 0.8730 - val_loss: 0.3924\n",
            "Epoch 28/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - accuracy: 0.9953 - loss: 0.0245 - val_accuracy: 0.8810 - val_loss: 0.4062\n",
            "Epoch 29/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 894ms/step - accuracy: 0.9996 - loss: 0.0208 - val_accuracy: 0.8175 - val_loss: 0.4349\n",
            "Epoch 30/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.9987 - loss: 0.0152 - val_accuracy: 0.8730 - val_loss: 0.4314\n",
            "Epoch 31/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0119 - val_accuracy: 0.8571 - val_loss: 0.4522\n",
            "Epoch 32/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0098 - val_accuracy: 0.8651 - val_loss: 0.4589\n",
            "Epoch 33/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 891ms/step - accuracy: 1.0000 - loss: 0.0095 - val_accuracy: 0.8730 - val_loss: 0.4716\n",
            "Epoch 34/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 899ms/step - accuracy: 1.0000 - loss: 0.0082 - val_accuracy: 0.8254 - val_loss: 0.5267\n",
            "Epoch 35/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 901ms/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.8651 - val_loss: 0.4913\n",
            "Epoch 36/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 884ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 0.8492 - val_loss: 0.5206\n",
            "Epoch 37/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 891ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.8651 - val_loss: 0.5170\n",
            "Epoch 38/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.8254 - val_loss: 0.5565\n",
            "Epoch 39/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.8730 - val_loss: 0.5311\n",
            "Epoch 40/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.8571 - val_loss: 0.5547\n",
            "Epoch 41/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.8571 - val_loss: 0.5598\n",
            "Epoch 42/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.8651 - val_loss: 0.5528\n",
            "Epoch 43/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.8571 - val_loss: 0.5783\n",
            "Epoch 44/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.8571 - val_loss: 0.5753\n",
            "Epoch 45/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 918ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.8254 - val_loss: 0.6194\n",
            "Epoch 46/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 987ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.8651 - val_loss: 0.5865\n",
            "Epoch 47/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 888ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.8571 - val_loss: 0.6057\n",
            "Epoch 48/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 891ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.8651 - val_loss: 0.6048\n",
            "Epoch 49/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 968ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.8492 - val_loss: 0.6368\n",
            "Epoch 50/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 896ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.8651 - val_loss: 0.6261\n",
            "Epoch 51/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 916ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.8492 - val_loss: 0.6488\n",
            "Epoch 52/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 959ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.8492 - val_loss: 0.6480\n",
            "Epoch 53/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.6051e-04 - val_accuracy: 0.8492 - val_loss: 0.6715\n",
            "Epoch 54/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.1832e-04 - val_accuracy: 0.8492 - val_loss: 0.6596\n",
            "Epoch 55/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 895ms/step - accuracy: 1.0000 - loss: 8.5656e-04 - val_accuracy: 0.8333 - val_loss: 0.6879\n",
            "Epoch 56/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.7746e-04 - val_accuracy: 0.8413 - val_loss: 0.6782\n",
            "Epoch 57/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 898ms/step - accuracy: 1.0000 - loss: 7.1181e-04 - val_accuracy: 0.8413 - val_loss: 0.7046\n",
            "Epoch 58/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.4460e-04 - val_accuracy: 0.8333 - val_loss: 0.7083\n",
            "Epoch 59/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 6.0825e-04 - val_accuracy: 0.8333 - val_loss: 0.7199\n",
            "Epoch 60/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.9580e-04 - val_accuracy: 0.8571 - val_loss: 0.7064\n",
            "Epoch 61/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 905ms/step - accuracy: 1.0000 - loss: 4.6131e-04 - val_accuracy: 0.8254 - val_loss: 0.7391\n",
            "Epoch 62/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.5872e-04 - val_accuracy: 0.8492 - val_loss: 0.7332\n",
            "Epoch 63/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 882ms/step - accuracy: 1.0000 - loss: 3.6804e-04 - val_accuracy: 0.8413 - val_loss: 0.7348\n",
            "Epoch 64/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.0587e-04 - val_accuracy: 0.8333 - val_loss: 0.7467\n",
            "Epoch 65/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.9330e-04 - val_accuracy: 0.8333 - val_loss: 0.7543\n",
            "Epoch 66/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.0759e-04 - val_accuracy: 0.8333 - val_loss: 0.7601\n",
            "Epoch 67/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 890ms/step - accuracy: 1.0000 - loss: 3.3714e-04 - val_accuracy: 0.8333 - val_loss: 0.7700\n",
            "Epoch 68/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 965ms/step - accuracy: 1.0000 - loss: 2.7821e-04 - val_accuracy: 0.8254 - val_loss: 0.7802\n",
            "Epoch 69/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.5055e-04 - val_accuracy: 0.8254 - val_loss: 0.7903\n",
            "Epoch 70/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 2.3722e-04 - val_accuracy: 0.8413 - val_loss: 0.7742\n",
            "Epoch 71/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.1785e-04 - val_accuracy: 0.8254 - val_loss: 0.7966\n",
            "Epoch 72/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 900ms/step - accuracy: 1.0000 - loss: 2.2991e-04 - val_accuracy: 0.8254 - val_loss: 0.7940\n",
            "Epoch 73/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 903ms/step - accuracy: 1.0000 - loss: 2.3161e-04 - val_accuracy: 0.8254 - val_loss: 0.8087\n",
            "Epoch 74/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 894ms/step - accuracy: 1.0000 - loss: 1.8787e-04 - val_accuracy: 0.8254 - val_loss: 0.8021\n",
            "Epoch 75/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.8530e-04 - val_accuracy: 0.8254 - val_loss: 0.8253\n",
            "Epoch 76/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.7583e-04 - val_accuracy: 0.8254 - val_loss: 0.8112\n",
            "Epoch 77/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 899ms/step - accuracy: 1.0000 - loss: 1.6112e-04 - val_accuracy: 0.8175 - val_loss: 0.8269\n",
            "Epoch 78/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.5081e-04 - val_accuracy: 0.8254 - val_loss: 0.8239\n",
            "Epoch 79/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.7413e-04 - val_accuracy: 0.8254 - val_loss: 0.8403\n",
            "Epoch 80/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.4690e-04 - val_accuracy: 0.8175 - val_loss: 0.8370\n",
            "Epoch 81/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.3411e-04 - val_accuracy: 0.8175 - val_loss: 0.8448\n",
            "Epoch 82/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.0742e-04 - val_accuracy: 0.8175 - val_loss: 0.8459\n",
            "Epoch 83/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.2668e-04 - val_accuracy: 0.8175 - val_loss: 0.8534\n",
            "Epoch 84/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.2567e-04 - val_accuracy: 0.8254 - val_loss: 0.8758\n",
            "Epoch 85/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 889ms/step - accuracy: 1.0000 - loss: 1.1534e-04 - val_accuracy: 0.8175 - val_loss: 0.8565\n",
            "Epoch 86/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 886ms/step - accuracy: 1.0000 - loss: 1.0479e-04 - val_accuracy: 0.8175 - val_loss: 0.8680\n",
            "Epoch 87/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.0334e-04 - val_accuracy: 0.8254 - val_loss: 0.8790\n",
            "Epoch 88/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 1.1263e-04 - val_accuracy: 0.8175 - val_loss: 0.8699\n",
            "Epoch 89/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.9556e-05 - val_accuracy: 0.8254 - val_loss: 0.8975\n",
            "Epoch 90/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 884ms/step - accuracy: 1.0000 - loss: 8.8219e-05 - val_accuracy: 0.8175 - val_loss: 0.8807\n",
            "Epoch 91/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 8.9426e-05 - val_accuracy: 0.8175 - val_loss: 0.8774\n",
            "Epoch 92/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 8.0377e-05 - val_accuracy: 0.8254 - val_loss: 0.9084\n",
            "Epoch 93/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 904ms/step - accuracy: 1.0000 - loss: 7.3038e-05 - val_accuracy: 0.8175 - val_loss: 0.9009\n",
            "Epoch 94/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 952ms/step - accuracy: 1.0000 - loss: 6.9701e-05 - val_accuracy: 0.8175 - val_loss: 0.8994\n",
            "Epoch 95/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 7.7731e-05 - val_accuracy: 0.8175 - val_loss: 0.9018\n",
            "Epoch 96/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.9350e-05 - val_accuracy: 0.8175 - val_loss: 0.9098\n",
            "Epoch 97/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 900ms/step - accuracy: 1.0000 - loss: 7.4418e-05 - val_accuracy: 0.8175 - val_loss: 0.9042\n",
            "Epoch 98/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.4493e-05 - val_accuracy: 0.8254 - val_loss: 0.9211\n",
            "Epoch 99/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 6.7236e-05 - val_accuracy: 0.8254 - val_loss: 0.9248\n",
            "Epoch 100/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 896ms/step - accuracy: 1.0000 - loss: 6.4327e-05 - val_accuracy: 0.8175 - val_loss: 0.9164\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 17s/step\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.8533 - loss: 0.7517\n",
            "Test Accuracy: 0.8590\n",
            "F1 Score: 0.8602\n",
            "G-Mean: 0.8590\n",
            "Informedness (IBA): 0.7181\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, concatenate, AveragePooling2D, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Define dataset paths\n",
        "benign_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/benign/40X\"\n",
        "malignant_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/malignant/40X\"\n",
        "\n",
        "def load_image_paths(dir_path):\n",
        "    return [os.path.join(dir_path, img) for img in os.listdir(dir_path) if img.endswith('.png')]\n",
        "\n",
        "# Load image paths\n",
        "benign_images = load_image_paths(benign_dir)\n",
        "malignant_images = load_image_paths(malignant_dir)\n",
        "\n",
        "print(f\"Original Benign Images: {len(benign_images)}\")\n",
        "print(f\"Original Malignant Images: {len(malignant_images)}\")\n",
        "\n",
        "# Undersample malignant images to match benign count\n",
        "malignant_images = resample(malignant_images,\n",
        "                            replace=False,\n",
        "                            n_samples=len(benign_images),\n",
        "                            random_state=42)\n",
        "\n",
        "print(f\"Undersampled Malignant Images: {len(malignant_images)}\")\n",
        "\n",
        "# Assign labels\n",
        "benign_labels = [0] * len(benign_images)\n",
        "malignant_labels = [1] * len(malignant_images)\n",
        "\n",
        "# Combine and convert to arrays\n",
        "all_images = np.array(benign_images + malignant_images)\n",
        "all_labels = np.array(benign_labels + malignant_labels)\n",
        "\n",
        "# Split dataset (60% train, 10% val, 30% test)\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(\n",
        "    all_images, all_labels, test_size=0.3, stratify=all_labels, random_state=42)\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(\n",
        "    train_images, train_labels, test_size=0.1429, stratify=train_labels, random_state=42)\n",
        "\n",
        "print(f\"Training samples: {len(train_images)}\")\n",
        "print(f\"Validation samples: {len(val_images)}\")\n",
        "print(f\"Testing samples: {len(test_images)}\")\n",
        "\n",
        "def process_path(file_path, label):\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_png(img, channels=3)\n",
        "    img = tf.image.resize(img, [224, 224])\n",
        "    img = img / 255.0\n",
        "    return img, label\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# Create tf.data.Dataset objects\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).map(process_path).shuffle(1000).batch(BATCH_SIZE)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels)).map(process_path).batch(BATCH_SIZE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).map(process_path).batch(BATCH_SIZE)\n",
        "\n",
        "if sum(1 for _ in test_dataset) == 0:\n",
        "    raise ValueError(\"Testing dataset is empty. Adjust your dataset split.\")\n",
        "\n",
        "# Load VGG16 without top layers\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Define custom Inception block\n",
        "def inception_block(x):\n",
        "    branch1 = Conv2D(64, (1, 1), activation='relu', padding='same')(x)\n",
        "\n",
        "    branch2 = Conv2D(64, (1, 1), activation='relu', padding='same')(x)\n",
        "    branch2 = Conv2D(128, (3, 3), activation='relu', padding='same')(branch2)\n",
        "\n",
        "    branch3 = Conv2D(64, (1, 1), activation='relu', padding='same')(x)\n",
        "    branch3 = Conv2D(128, (5, 5), activation='relu', padding='same')(branch3)\n",
        "\n",
        "    branch4 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "    branch4 = Conv2D(64, (1, 1), activation='relu', padding='same')(branch4)\n",
        "\n",
        "    output = concatenate([branch1, branch2, branch3, branch4], axis=-1)\n",
        "    return output\n",
        "\n",
        "# Build model\n",
        "x = inception_block(base_model.output)\n",
        "x = AveragePooling2D(pool_size=(2, 2))(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "EPOCHS = 100\n",
        "history = model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS)\n",
        "\n",
        "# Evaluate model\n",
        "test_preds = model.predict(test_dataset)\n",
        "test_preds = (test_preds > 0.5).astype(int).flatten()\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(test_labels, test_preds).ravel()\n",
        "iba = (tp / (tp + fn)) + (tn / (tn + fp)) - 1\n",
        "\n",
        "f1 = f1_score(test_labels, test_preds)\n",
        "gmean = geometric_mean_score(test_labels, test_preds)\n",
        "\n",
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"G-Mean: {gmean:.4f}\")\n",
        "print(f\"Informedness (IBA): {iba:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 100X Magnification\n",
        "\n",
        "At 100X magnification, the dataset provided slightly better structural clarity than 40X.\n",
        "Balanced class distribution was achieved via undersampling of the malignant images.\n",
        "Improved texture and cell boundary visibility contributed to better feature extraction.\n",
        "The model showed increased accuracy and F1 score compared to the 40X experiment.\n"
      ],
      "metadata": {
        "id": "oIXvoDqezjDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, concatenate, AveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Define dataset paths\n",
        "benign_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/benign/100X\"\n",
        "malignant_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/malignant/100X\"\n",
        "\n",
        "def load_image_paths(dir_path):\n",
        "    return [os.path.join(dir_path, img) for img in os.listdir(dir_path) if img.endswith('.png')]\n",
        "\n",
        "# Load image paths\n",
        "benign_images = load_image_paths(benign_dir)\n",
        "malignant_images = load_image_paths(malignant_dir)\n",
        "\n",
        "print(f\"Original Benign Images: {len(benign_images)}\")\n",
        "print(f\"Original Malignant Images: {len(malignant_images)}\")\n",
        "\n",
        "# Undersample malignant to match benign count\n",
        "malignant_images = resample(malignant_images,\n",
        "                            replace=False,\n",
        "                            n_samples=len(benign_images),\n",
        "                            random_state=42)\n",
        "\n",
        "print(f\"After Undersampling - Malignant: {len(malignant_images)}\")\n",
        "\n",
        "# Labels\n",
        "benign_labels = [0] * len(benign_images)\n",
        "malignant_labels = [1] * len(malignant_images)\n",
        "\n",
        "# Combine and convert to arrays\n",
        "all_images = np.array(benign_images + malignant_images)\n",
        "all_labels = np.array(benign_labels + malignant_labels)\n",
        "\n",
        "# Split dataset (60% train, 10% val, 30% test)\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(\n",
        "    all_images, all_labels, test_size=0.3, stratify=all_labels, random_state=42)\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(\n",
        "    train_images, train_labels, test_size=0.1429, stratify=train_labels, random_state=42)\n",
        "\n",
        "print(f\"Training samples: {len(train_images)}\")\n",
        "print(f\"Validation samples: {len(val_images)}\")\n",
        "print(f\"Testing samples: {len(test_images)}\")\n",
        "\n",
        "def process_path(file_path, label):\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_png(img, channels=3)\n",
        "    img = tf.image.resize(img, [224, 224])\n",
        "    img = img / 255.0\n",
        "    return img, label\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# Prepare datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).map(process_path).shuffle(1000).batch(BATCH_SIZE)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels)).map(process_path).batch(BATCH_SIZE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).map(process_path).batch(BATCH_SIZE)\n",
        "\n",
        "if sum(1 for _ in test_dataset) == 0:\n",
        "    raise ValueError(\"Testing dataset is empty. Adjust your dataset split.\")\n",
        "\n",
        "# Load VGG16 base\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Inception block\n",
        "def inception_block(x):\n",
        "    branch1 = Conv2D(64, (1, 1), activation='relu', padding='same')(x)\n",
        "\n",
        "    branch2 = Conv2D(64, (1, 1), activation='relu', padding='same')(x)\n",
        "    branch2 = Conv2D(128, (3, 3), activation='relu', padding='same')(branch2)\n",
        "\n",
        "    branch3 = Conv2D(64, (1, 1), activation='relu', padding='same')(x)\n",
        "    branch3 = Conv2D(128, (5, 5), activation='relu', padding='same')(branch3)\n",
        "\n",
        "    branch4 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "    branch4 = Conv2D(64, (1, 1), activation='relu', padding='same')(branch4)\n",
        "\n",
        "    return concatenate([branch1, branch2, branch3, branch4], axis=-1)\n",
        "\n",
        "# Add Inception to VGG16\n",
        "x = inception_block(base_model.output)\n",
        "x = AveragePooling2D(pool_size=(2, 2))(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Final model\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "EPOCHS = 100\n",
        "history = model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS)\n",
        "\n",
        "# Evaluation\n",
        "test_preds = model.predict(test_dataset)\n",
        "test_preds = (test_preds > 0.5).astype(int).flatten()\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(test_labels, test_preds).ravel()\n",
        "iba = (tp / (tp + fn)) + (tn / (tn + fp)) - 1\n",
        "f1 = f1_score(test_labels, test_preds)\n",
        "gmean = geometric_mean_score(test_labels, test_preds)\n",
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"G-Mean: {gmean:.4f}\")\n",
        "print(f\"Informedness (IBA): {iba:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txdjq55Ct7sx",
        "outputId": "96260683-896d-4120-e855-97dd121073a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Benign Images: 649\n",
            "Original Malignant Images: 1437\n",
            "After Undersampling - Malignant: 649\n",
            "Training samples: 778\n",
            "Validation samples: 130\n",
            "Testing samples: 390\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 4s/step - accuracy: 0.5003 - loss: 0.9872 - val_accuracy: 0.5000 - val_loss: 0.7139\n",
            "Epoch 2/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 863ms/step - accuracy: 0.5367 - loss: 0.6902 - val_accuracy: 0.5154 - val_loss: 0.6908\n",
            "Epoch 3/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 712ms/step - accuracy: 0.5647 - loss: 0.6763 - val_accuracy: 0.5000 - val_loss: 0.6706\n",
            "Epoch 4/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 867ms/step - accuracy: 0.6135 - loss: 0.6405 - val_accuracy: 0.5846 - val_loss: 0.6449\n",
            "Epoch 5/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 712ms/step - accuracy: 0.6693 - loss: 0.5932 - val_accuracy: 0.6692 - val_loss: 0.5665\n",
            "Epoch 6/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 775ms/step - accuracy: 0.7335 - loss: 0.5225 - val_accuracy: 0.7308 - val_loss: 0.5229\n",
            "Epoch 7/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 724ms/step - accuracy: 0.7885 - loss: 0.4567 - val_accuracy: 0.6615 - val_loss: 0.5862\n",
            "Epoch 8/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 734ms/step - accuracy: 0.7623 - loss: 0.4756 - val_accuracy: 0.7000 - val_loss: 0.5644\n",
            "Epoch 9/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 717ms/step - accuracy: 0.7805 - loss: 0.4535 - val_accuracy: 0.7154 - val_loss: 0.4825\n",
            "Epoch 10/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 718ms/step - accuracy: 0.8404 - loss: 0.3815 - val_accuracy: 0.7077 - val_loss: 0.5560\n",
            "Epoch 11/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 875ms/step - accuracy: 0.8276 - loss: 0.3777 - val_accuracy: 0.7692 - val_loss: 0.4368\n",
            "Epoch 12/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 722ms/step - accuracy: 0.8816 - loss: 0.3031 - val_accuracy: 0.7846 - val_loss: 0.4119\n",
            "Epoch 13/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 875ms/step - accuracy: 0.8686 - loss: 0.2865 - val_accuracy: 0.8077 - val_loss: 0.3983\n",
            "Epoch 14/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 885ms/step - accuracy: 0.8830 - loss: 0.2623 - val_accuracy: 0.8154 - val_loss: 0.4040\n",
            "Epoch 15/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 880ms/step - accuracy: 0.8907 - loss: 0.2761 - val_accuracy: 0.7385 - val_loss: 0.5470\n",
            "Epoch 16/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 732ms/step - accuracy: 0.8468 - loss: 0.3075 - val_accuracy: 0.7538 - val_loss: 0.4544\n",
            "Epoch 17/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 763ms/step - accuracy: 0.8478 - loss: 0.3178 - val_accuracy: 0.8077 - val_loss: 0.3934\n",
            "Epoch 18/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 728ms/step - accuracy: 0.9337 - loss: 0.2005 - val_accuracy: 0.7769 - val_loss: 0.4630\n",
            "Epoch 19/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 878ms/step - accuracy: 0.8832 - loss: 0.2518 - val_accuracy: 0.8385 - val_loss: 0.3490\n",
            "Epoch 20/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 725ms/step - accuracy: 0.9316 - loss: 0.1845 - val_accuracy: 0.7923 - val_loss: 0.4036\n",
            "Epoch 21/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 878ms/step - accuracy: 0.9488 - loss: 0.1429 - val_accuracy: 0.8308 - val_loss: 0.3850\n",
            "Epoch 22/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 834ms/step - accuracy: 0.9607 - loss: 0.1184 - val_accuracy: 0.8462 - val_loss: 0.3349\n",
            "Epoch 23/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 884ms/step - accuracy: 0.9665 - loss: 0.1064 - val_accuracy: 0.8462 - val_loss: 0.4028\n",
            "Epoch 24/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 730ms/step - accuracy: 0.9705 - loss: 0.1064 - val_accuracy: 0.8538 - val_loss: 0.3495\n",
            "Epoch 25/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 881ms/step - accuracy: 0.9867 - loss: 0.0637 - val_accuracy: 0.8231 - val_loss: 0.4619\n",
            "Epoch 26/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 901ms/step - accuracy: 0.9837 - loss: 0.0747 - val_accuracy: 0.8615 - val_loss: 0.3665\n",
            "Epoch 27/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 883ms/step - accuracy: 0.9909 - loss: 0.0575 - val_accuracy: 0.8385 - val_loss: 0.4215\n",
            "Epoch 28/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 722ms/step - accuracy: 0.9852 - loss: 0.0573 - val_accuracy: 0.8538 - val_loss: 0.3656\n",
            "Epoch 29/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 881ms/step - accuracy: 0.9969 - loss: 0.0306 - val_accuracy: 0.8462 - val_loss: 0.4252\n",
            "Epoch 30/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 883ms/step - accuracy: 0.9962 - loss: 0.0345 - val_accuracy: 0.8538 - val_loss: 0.3729\n",
            "Epoch 31/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 882ms/step - accuracy: 0.9970 - loss: 0.0247 - val_accuracy: 0.8538 - val_loss: 0.4652\n",
            "Epoch 32/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 737ms/step - accuracy: 0.9820 - loss: 0.0396 - val_accuracy: 0.8538 - val_loss: 0.4011\n",
            "Epoch 33/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 731ms/step - accuracy: 0.9973 - loss: 0.0218 - val_accuracy: 0.8462 - val_loss: 0.4177\n",
            "Epoch 34/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 881ms/step - accuracy: 0.9993 - loss: 0.0137 - val_accuracy: 0.8308 - val_loss: 0.4216\n",
            "Epoch 35/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 777ms/step - accuracy: 0.9983 - loss: 0.0135 - val_accuracy: 0.8538 - val_loss: 0.4597\n",
            "Epoch 36/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 881ms/step - accuracy: 1.0000 - loss: 0.0101 - val_accuracy: 0.8538 - val_loss: 0.4393\n",
            "Epoch 37/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 821ms/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 0.8692 - val_loss: 0.4294\n",
            "Epoch 38/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 888ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.8538 - val_loss: 0.4372\n",
            "Epoch 39/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 881ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.8692 - val_loss: 0.4575\n",
            "Epoch 40/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 892ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.8692 - val_loss: 0.4650\n",
            "Epoch 41/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 751ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.8692 - val_loss: 0.4705\n",
            "Epoch 42/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 886ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.8615 - val_loss: 0.4796\n",
            "Epoch 43/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 746ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.8692 - val_loss: 0.4844\n",
            "Epoch 44/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 831ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.8462 - val_loss: 0.4907\n",
            "Epoch 45/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 737ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.8615 - val_loss: 0.5012\n",
            "Epoch 46/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 735ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.8385 - val_loss: 0.5076\n",
            "Epoch 47/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 748ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.8538 - val_loss: 0.5129\n",
            "Epoch 48/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 744ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.8538 - val_loss: 0.5179\n",
            "Epoch 49/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 892ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.8538 - val_loss: 0.5277\n",
            "Epoch 50/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.8538 - val_loss: 0.5345\n",
            "Epoch 51/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 883ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.8385 - val_loss: 0.5384\n",
            "Epoch 52/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 742ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.8462 - val_loss: 0.5343\n",
            "Epoch 53/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 729ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.8385 - val_loss: 0.5366\n",
            "Epoch 54/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 735ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.8462 - val_loss: 0.5416\n",
            "Epoch 55/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 890ms/step - accuracy: 1.0000 - loss: 9.9176e-04 - val_accuracy: 0.8385 - val_loss: 0.5480\n",
            "Epoch 56/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 780ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.8538 - val_loss: 0.5502\n",
            "Epoch 57/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 734ms/step - accuracy: 1.0000 - loss: 9.7611e-04 - val_accuracy: 0.8615 - val_loss: 0.5574\n",
            "Epoch 58/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 730ms/step - accuracy: 1.0000 - loss: 8.9015e-04 - val_accuracy: 0.8385 - val_loss: 0.5546\n",
            "Epoch 59/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 876ms/step - accuracy: 1.0000 - loss: 8.6011e-04 - val_accuracy: 0.8538 - val_loss: 0.5597\n",
            "Epoch 60/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 878ms/step - accuracy: 1.0000 - loss: 7.4368e-04 - val_accuracy: 0.8385 - val_loss: 0.5645\n",
            "Epoch 61/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 886ms/step - accuracy: 1.0000 - loss: 7.4332e-04 - val_accuracy: 0.8538 - val_loss: 0.5713\n",
            "Epoch 62/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 734ms/step - accuracy: 1.0000 - loss: 6.6656e-04 - val_accuracy: 0.8385 - val_loss: 0.5733\n",
            "Epoch 63/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 731ms/step - accuracy: 1.0000 - loss: 6.2433e-04 - val_accuracy: 0.8538 - val_loss: 0.5774\n",
            "Epoch 64/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 786ms/step - accuracy: 1.0000 - loss: 6.0418e-04 - val_accuracy: 0.8462 - val_loss: 0.5807\n",
            "Epoch 65/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 886ms/step - accuracy: 1.0000 - loss: 5.2188e-04 - val_accuracy: 0.8538 - val_loss: 0.5829\n",
            "Epoch 66/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 893ms/step - accuracy: 1.0000 - loss: 5.3870e-04 - val_accuracy: 0.8538 - val_loss: 0.5834\n",
            "Epoch 67/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 892ms/step - accuracy: 1.0000 - loss: 4.9693e-04 - val_accuracy: 0.8462 - val_loss: 0.5853\n",
            "Epoch 68/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 899ms/step - accuracy: 1.0000 - loss: 5.1769e-04 - val_accuracy: 0.8462 - val_loss: 0.5896\n",
            "Epoch 69/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 725ms/step - accuracy: 1.0000 - loss: 5.1466e-04 - val_accuracy: 0.8462 - val_loss: 0.5939\n",
            "Epoch 70/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 897ms/step - accuracy: 1.0000 - loss: 4.3559e-04 - val_accuracy: 0.8462 - val_loss: 0.6004\n",
            "Epoch 71/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 737ms/step - accuracy: 1.0000 - loss: 3.9991e-04 - val_accuracy: 0.8462 - val_loss: 0.6064\n",
            "Epoch 72/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 728ms/step - accuracy: 1.0000 - loss: 3.5289e-04 - val_accuracy: 0.8462 - val_loss: 0.6123\n",
            "Epoch 73/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.6441e-04 - val_accuracy: 0.8385 - val_loss: 0.6142\n",
            "Epoch 74/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 731ms/step - accuracy: 1.0000 - loss: 3.7341e-04 - val_accuracy: 0.8462 - val_loss: 0.6165\n",
            "Epoch 75/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 744ms/step - accuracy: 1.0000 - loss: 3.2048e-04 - val_accuracy: 0.8538 - val_loss: 0.6201\n",
            "Epoch 76/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 884ms/step - accuracy: 1.0000 - loss: 3.1558e-04 - val_accuracy: 0.8538 - val_loss: 0.6244\n",
            "Epoch 77/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 886ms/step - accuracy: 1.0000 - loss: 3.0536e-04 - val_accuracy: 0.8538 - val_loss: 0.6266\n",
            "Epoch 78/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 727ms/step - accuracy: 1.0000 - loss: 2.6818e-04 - val_accuracy: 0.8538 - val_loss: 0.6303\n",
            "Epoch 79/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 890ms/step - accuracy: 1.0000 - loss: 3.0366e-04 - val_accuracy: 0.8615 - val_loss: 0.6366\n",
            "Epoch 80/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 721ms/step - accuracy: 1.0000 - loss: 2.5975e-04 - val_accuracy: 0.8615 - val_loss: 0.6385\n",
            "Epoch 81/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 730ms/step - accuracy: 1.0000 - loss: 2.4039e-04 - val_accuracy: 0.8615 - val_loss: 0.6426\n",
            "Epoch 82/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 741ms/step - accuracy: 1.0000 - loss: 2.4787e-04 - val_accuracy: 0.8615 - val_loss: 0.6437\n",
            "Epoch 83/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 728ms/step - accuracy: 1.0000 - loss: 2.1603e-04 - val_accuracy: 0.8538 - val_loss: 0.6478\n",
            "Epoch 84/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 885ms/step - accuracy: 1.0000 - loss: 2.0200e-04 - val_accuracy: 0.8538 - val_loss: 0.6518\n",
            "Epoch 85/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 725ms/step - accuracy: 1.0000 - loss: 2.0772e-04 - val_accuracy: 0.8538 - val_loss: 0.6548\n",
            "Epoch 86/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 890ms/step - accuracy: 1.0000 - loss: 1.8126e-04 - val_accuracy: 0.8538 - val_loss: 0.6609\n",
            "Epoch 87/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 891ms/step - accuracy: 1.0000 - loss: 1.8271e-04 - val_accuracy: 0.8538 - val_loss: 0.6667\n",
            "Epoch 88/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 899ms/step - accuracy: 1.0000 - loss: 1.4516e-04 - val_accuracy: 0.8538 - val_loss: 0.6737\n",
            "Epoch 89/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 891ms/step - accuracy: 1.0000 - loss: 1.6821e-04 - val_accuracy: 0.8462 - val_loss: 0.6843\n",
            "Epoch 90/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 883ms/step - accuracy: 1.0000 - loss: 1.6804e-04 - val_accuracy: 0.8538 - val_loss: 0.6927\n",
            "Epoch 91/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 730ms/step - accuracy: 1.0000 - loss: 1.6032e-04 - val_accuracy: 0.8538 - val_loss: 0.6945\n",
            "Epoch 92/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 744ms/step - accuracy: 1.0000 - loss: 1.3380e-04 - val_accuracy: 0.8538 - val_loss: 0.6980\n",
            "Epoch 93/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 744ms/step - accuracy: 1.0000 - loss: 1.1844e-04 - val_accuracy: 0.8538 - val_loss: 0.7017\n",
            "Epoch 94/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 891ms/step - accuracy: 1.0000 - loss: 1.3308e-04 - val_accuracy: 0.8615 - val_loss: 0.7043\n",
            "Epoch 95/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 847ms/step - accuracy: 1.0000 - loss: 1.2326e-04 - val_accuracy: 0.8538 - val_loss: 0.7059\n",
            "Epoch 96/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 888ms/step - accuracy: 1.0000 - loss: 1.0820e-04 - val_accuracy: 0.8538 - val_loss: 0.7064\n",
            "Epoch 97/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 902ms/step - accuracy: 1.0000 - loss: 9.5517e-05 - val_accuracy: 0.8538 - val_loss: 0.7136\n",
            "Epoch 98/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 744ms/step - accuracy: 1.0000 - loss: 1.1610e-04 - val_accuracy: 0.8615 - val_loss: 0.7146\n",
            "Epoch 99/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 740ms/step - accuracy: 1.0000 - loss: 9.6187e-05 - val_accuracy: 0.8615 - val_loss: 0.7191\n",
            "Epoch 100/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 737ms/step - accuracy: 1.0000 - loss: 8.8332e-05 - val_accuracy: 0.8615 - val_loss: 0.7256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 979ms/step - accuracy: 0.8245 - loss: 0.9312\n",
            "Test Accuracy: 0.8282\n",
            "F1 Score: 0.8232\n",
            "G-Mean: 0.8277\n",
            "Informedness (IBA): 0.6564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 200X Magnification\n",
        "\n",
        "The 200X magnification images offered finer cellular details, aiding deeper feature learning.\n",
        "Both F1 score and geometric mean significantly improved at this magnification.\n",
        "It emerged as one of the most effective magnifications for classification tasks.\n"
      ],
      "metadata": {
        "id": "Ic_7mfgVzn0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, concatenate, AveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Define dataset paths\n",
        "benign_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/benign/200X\"\n",
        "malignant_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/malignant/200X\"\n",
        "\n",
        "def load_image_paths(dir_path):\n",
        "    return [os.path.join(dir_path, img) for img in os.listdir(dir_path) if img.endswith('.png')]\n",
        "\n",
        "benign_images = load_image_paths(benign_dir)\n",
        "malignant_images = load_image_paths(malignant_dir)\n",
        "\n",
        "print(f\"Original Benign Images: {len(benign_images)}\")\n",
        "print(f\"Original Malignant Images: {len(malignant_images)}\")\n",
        "\n",
        "# Undersample malignant to match benign count\n",
        "malignant_images = resample(malignant_images,\n",
        "                            replace=False,\n",
        "                            n_samples=len(benign_images),\n",
        "                            random_state=42)\n",
        "\n",
        "print(f\"After Undersampling - Malignant: {len(malignant_images)}\")\n",
        "\n",
        "# Labels\n",
        "benign_labels = [0] * len(benign_images)\n",
        "malignant_labels = [1] * len(malignant_images)\n",
        "\n",
        "# Combine\n",
        "all_images = np.array(benign_images + malignant_images)\n",
        "all_labels = np.array(benign_labels + malignant_labels)\n",
        "\n",
        "# Split dataset (60% train, 10% val, 30% test)\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(\n",
        "    all_images, all_labels, test_size=0.3, stratify=all_labels, random_state=42)\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(\n",
        "    train_images, train_labels, test_size=0.1429, stratify=train_labels, random_state=42)\n",
        "\n",
        "print(f\"Training samples: {len(train_images)}\")\n",
        "print(f\"Validation samples: {len(val_images)}\")\n",
        "print(f\"Testing samples: {len(test_images)}\")\n",
        "\n",
        "def process_path(file_path, label):\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_png(img, channels=3)\n",
        "    img = tf.image.resize(img, [224, 224])\n",
        "    img = img / 255.0\n",
        "    return img, label\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).map(process_path).shuffle(1000).batch(BATCH_SIZE)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels)).map(process_path).batch(BATCH_SIZE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).map(process_path).batch(BATCH_SIZE)\n",
        "\n",
        "if sum(1 for _ in test_dataset) == 0:\n",
        "    raise ValueError(\"Testing dataset is empty. Adjust your dataset split.\")\n",
        "\n",
        "# Load VGG16 without top layers\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "def inception_block(x):\n",
        "    branch1 = Conv2D(64, (1, 1), activation='relu', padding='same')(x)\n",
        "\n",
        "    branch2 = Conv2D(64, (1, 1), activation='relu', padding='same')(x)\n",
        "    branch2 = Conv2D(128, (3, 3), activation='relu', padding='same')(branch2)\n",
        "\n",
        "    branch3 = Conv2D(64, (1, 1), activation='relu', padding='same')(x)\n",
        "    branch3 = Conv2D(128, (5, 5), activation='relu', padding='same')(branch3)\n",
        "\n",
        "    branch4 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "    branch4 = Conv2D(64, (1, 1), activation='relu', padding='same')(branch4)\n",
        "\n",
        "    output = concatenate([branch1, branch2, branch3, branch4], axis=-1)\n",
        "    return output\n",
        "\n",
        "# Add Inception block after VGG16\n",
        "x = inception_block(base_model.output)\n",
        "x = AveragePooling2D(pool_size=(2, 2))(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "EPOCHS = 100\n",
        "history = model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS)\n",
        "\n",
        "# Predict\n",
        "test_preds = model.predict(test_dataset)\n",
        "test_preds = (test_preds > 0.5).astype(int).flatten()\n",
        "\n",
        "# Metrics\n",
        "tn, fp, fn, tp = confusion_matrix(test_labels, test_preds).ravel()\n",
        "iba = (tp / (tp + fn)) + (tn / (tn + fp)) - 1\n",
        "f1 = f1_score(test_labels, test_preds)\n",
        "gmean = geometric_mean_score(test_labels, test_preds)\n",
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "\n",
        "# Print results\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"G-Mean: {gmean:.4f}\")\n",
        "print(f\"Informedness (IBA): {iba:.4f}\")\n"
      ],
      "metadata": {
        "id": "fNBpJ5V2veoz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c64f458b-016d-409e-9d49-6a4d14d51a7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Benign Images: 623\n",
            "Original Malignant Images: 1390\n",
            "After Undersampling - Malignant: 623\n",
            "Training samples: 747\n",
            "Validation samples: 125\n",
            "Testing samples: 374\n",
            "Epoch 1/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 14s/step - accuracy: 0.4770 - loss: 1.2523 - val_accuracy: 0.4960 - val_loss: 0.7532\n",
            "Epoch 2/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 840ms/step - accuracy: 0.4913 - loss: 0.7243 - val_accuracy: 0.5040 - val_loss: 0.6997\n",
            "Epoch 3/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.5278 - loss: 0.6874 - val_accuracy: 0.5120 - val_loss: 0.6803\n",
            "Epoch 4/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.5875 - loss: 0.6667 - val_accuracy: 0.6400 - val_loss: 0.6589\n",
            "Epoch 5/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.6665 - loss: 0.6395 - val_accuracy: 0.6240 - val_loss: 0.6323\n",
            "Epoch 6/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 842ms/step - accuracy: 0.7142 - loss: 0.5987 - val_accuracy: 0.7120 - val_loss: 0.5927\n",
            "Epoch 7/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.6986 - loss: 0.5648 - val_accuracy: 0.6960 - val_loss: 0.5934\n",
            "Epoch 8/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.7293 - loss: 0.5418 - val_accuracy: 0.6800 - val_loss: 0.6129\n",
            "Epoch 9/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.7429 - loss: 0.5145 - val_accuracy: 0.6560 - val_loss: 0.5634\n",
            "Epoch 10/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.7283 - loss: 0.4969 - val_accuracy: 0.7200 - val_loss: 0.5345\n",
            "Epoch 11/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.7849 - loss: 0.4431 - val_accuracy: 0.7680 - val_loss: 0.5366\n",
            "Epoch 12/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.8240 - loss: 0.3981 - val_accuracy: 0.7760 - val_loss: 0.5030\n",
            "Epoch 13/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 842ms/step - accuracy: 0.8410 - loss: 0.3682 - val_accuracy: 0.7680 - val_loss: 0.4922\n",
            "Epoch 14/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.8649 - loss: 0.3240 - val_accuracy: 0.7600 - val_loss: 0.5000\n",
            "Epoch 15/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.8401 - loss: 0.3448 - val_accuracy: 0.8160 - val_loss: 0.4836\n",
            "Epoch 16/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 854ms/step - accuracy: 0.8505 - loss: 0.3112 - val_accuracy: 0.7920 - val_loss: 0.4614\n",
            "Epoch 17/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.8935 - loss: 0.2827 - val_accuracy: 0.7600 - val_loss: 0.5031\n",
            "Epoch 18/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.9115 - loss: 0.2592 - val_accuracy: 0.7520 - val_loss: 0.5162\n",
            "Epoch 19/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 837ms/step - accuracy: 0.9018 - loss: 0.2406 - val_accuracy: 0.7920 - val_loss: 0.4728\n",
            "Epoch 20/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.9428 - loss: 0.1880 - val_accuracy: 0.8240 - val_loss: 0.5254\n",
            "Epoch 21/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.9514 - loss: 0.1630 - val_accuracy: 0.7840 - val_loss: 0.5552\n",
            "Epoch 22/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.9557 - loss: 0.1433 - val_accuracy: 0.7760 - val_loss: 0.4995\n",
            "Epoch 23/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 0.9687 - loss: 0.1059 - val_accuracy: 0.7920 - val_loss: 0.4928\n",
            "Epoch 24/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 993ms/step - accuracy: 0.9810 - loss: 0.0814 - val_accuracy: 0.8240 - val_loss: 0.6007\n",
            "Epoch 25/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.9744 - loss: 0.0924 - val_accuracy: 0.7040 - val_loss: 0.8306\n",
            "Epoch 26/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 955ms/step - accuracy: 0.9664 - loss: 0.1031 - val_accuracy: 0.7120 - val_loss: 0.6936\n",
            "Epoch 27/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 848ms/step - accuracy: 0.9707 - loss: 0.0938 - val_accuracy: 0.7760 - val_loss: 0.6247\n",
            "Epoch 28/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.9811 - loss: 0.0743 - val_accuracy: 0.8000 - val_loss: 0.5294\n",
            "Epoch 29/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 850ms/step - accuracy: 0.9927 - loss: 0.0380 - val_accuracy: 0.7760 - val_loss: 0.5466\n",
            "Epoch 30/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 860ms/step - accuracy: 1.0000 - loss: 0.0295 - val_accuracy: 0.7760 - val_loss: 0.5756\n",
            "Epoch 31/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 845ms/step - accuracy: 1.0000 - loss: 0.0262 - val_accuracy: 0.7840 - val_loss: 0.5967\n",
            "Epoch 32/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 856ms/step - accuracy: 1.0000 - loss: 0.0189 - val_accuracy: 0.7840 - val_loss: 0.6060\n",
            "Epoch 33/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0144 - val_accuracy: 0.7840 - val_loss: 0.6369\n",
            "Epoch 34/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 862ms/step - accuracy: 1.0000 - loss: 0.0123 - val_accuracy: 0.7920 - val_loss: 0.6661\n",
            "Epoch 35/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 843ms/step - accuracy: 1.0000 - loss: 0.0091 - val_accuracy: 0.7920 - val_loss: 0.6764\n",
            "Epoch 36/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 982ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.7760 - val_loss: 0.6884\n",
            "Epoch 37/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 841ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.7840 - val_loss: 0.7284\n",
            "Epoch 38/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.7840 - val_loss: 0.7119\n",
            "Epoch 39/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.7840 - val_loss: 0.7243\n",
            "Epoch 40/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.7920 - val_loss: 0.7329\n",
            "Epoch 41/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.7840 - val_loss: 0.7547\n",
            "Epoch 42/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 998ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.7920 - val_loss: 0.7687\n",
            "Epoch 43/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 843ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.7920 - val_loss: 0.7741\n",
            "Epoch 44/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 853ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.7920 - val_loss: 0.8022\n",
            "Epoch 45/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.7920 - val_loss: 0.7971\n",
            "Epoch 46/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.7920 - val_loss: 0.8146\n",
            "Epoch 47/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 848ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.7840 - val_loss: 0.8252\n",
            "Epoch 48/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.7840 - val_loss: 0.8339\n",
            "Epoch 49/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.7840 - val_loss: 0.8498\n",
            "Epoch 50/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.8000 - val_loss: 0.8771\n",
            "Epoch 51/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 843ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.7840 - val_loss: 0.8676\n",
            "Epoch 52/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 839ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.7840 - val_loss: 0.8908\n",
            "Epoch 53/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 843ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.7920 - val_loss: 0.9066\n",
            "Epoch 54/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 860ms/step - accuracy: 1.0000 - loss: 9.6800e-04 - val_accuracy: 0.7920 - val_loss: 0.9075\n",
            "Epoch 55/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.9317e-04 - val_accuracy: 0.7840 - val_loss: 0.9228\n",
            "Epoch 56/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 8.3105e-04 - val_accuracy: 0.7840 - val_loss: 0.9387\n",
            "Epoch 57/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 849ms/step - accuracy: 1.0000 - loss: 6.5311e-04 - val_accuracy: 0.7840 - val_loss: 0.9364\n",
            "Epoch 58/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 7.2549e-04 - val_accuracy: 0.7920 - val_loss: 0.9748\n",
            "Epoch 59/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 862ms/step - accuracy: 1.0000 - loss: 6.2140e-04 - val_accuracy: 0.7840 - val_loss: 0.9556\n",
            "Epoch 60/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.6117e-04 - val_accuracy: 0.7840 - val_loss: 0.9729\n",
            "Epoch 61/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.1587e-04 - val_accuracy: 0.7840 - val_loss: 0.9797\n",
            "Epoch 62/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.1239e-04 - val_accuracy: 0.7840 - val_loss: 0.9921\n",
            "Epoch 63/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 847ms/step - accuracy: 1.0000 - loss: 4.5805e-04 - val_accuracy: 0.7840 - val_loss: 1.0007\n",
            "Epoch 64/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.1425e-04 - val_accuracy: 0.7840 - val_loss: 1.0071\n",
            "Epoch 65/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 837ms/step - accuracy: 1.0000 - loss: 4.2023e-04 - val_accuracy: 0.7840 - val_loss: 1.0208\n",
            "Epoch 66/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.2931e-04 - val_accuracy: 0.7840 - val_loss: 1.0263\n",
            "Epoch 67/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 836ms/step - accuracy: 1.0000 - loss: 3.1387e-04 - val_accuracy: 0.7920 - val_loss: 1.0426\n",
            "Epoch 68/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.0697e-04 - val_accuracy: 0.7840 - val_loss: 1.0440\n",
            "Epoch 69/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 846ms/step - accuracy: 1.0000 - loss: 2.5006e-04 - val_accuracy: 0.7840 - val_loss: 1.0551\n",
            "Epoch 70/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 980ms/step - accuracy: 1.0000 - loss: 2.7670e-04 - val_accuracy: 0.7840 - val_loss: 1.0602\n",
            "Epoch 71/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.6961e-04 - val_accuracy: 0.7840 - val_loss: 1.0680\n",
            "Epoch 72/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 907ms/step - accuracy: 1.0000 - loss: 2.4154e-04 - val_accuracy: 0.7840 - val_loss: 1.0802\n",
            "Epoch 73/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 842ms/step - accuracy: 1.0000 - loss: 2.0637e-04 - val_accuracy: 0.7840 - val_loss: 1.0827\n",
            "Epoch 74/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 913ms/step - accuracy: 1.0000 - loss: 1.9822e-04 - val_accuracy: 0.8000 - val_loss: 1.0967\n",
            "Epoch 75/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.0139e-04 - val_accuracy: 0.7840 - val_loss: 1.0974\n",
            "Epoch 76/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 850ms/step - accuracy: 1.0000 - loss: 1.8911e-04 - val_accuracy: 0.8000 - val_loss: 1.1110\n",
            "Epoch 77/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 855ms/step - accuracy: 1.0000 - loss: 1.6480e-04 - val_accuracy: 0.7840 - val_loss: 1.1112\n",
            "Epoch 78/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.5044e-04 - val_accuracy: 0.7920 - val_loss: 1.1190\n",
            "Epoch 79/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 834ms/step - accuracy: 1.0000 - loss: 1.4456e-04 - val_accuracy: 0.7920 - val_loss: 1.1257\n",
            "Epoch 80/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.5516e-04 - val_accuracy: 0.7920 - val_loss: 1.1335\n",
            "Epoch 81/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 842ms/step - accuracy: 1.0000 - loss: 1.4079e-04 - val_accuracy: 0.7920 - val_loss: 1.1396\n",
            "Epoch 82/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.3721e-04 - val_accuracy: 0.7840 - val_loss: 1.1430\n",
            "Epoch 83/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 944ms/step - accuracy: 1.0000 - loss: 1.2819e-04 - val_accuracy: 0.8000 - val_loss: 1.1533\n",
            "Epoch 84/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 843ms/step - accuracy: 1.0000 - loss: 1.1857e-04 - val_accuracy: 0.7920 - val_loss: 1.1567\n",
            "Epoch 85/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 843ms/step - accuracy: 1.0000 - loss: 1.2141e-04 - val_accuracy: 0.7920 - val_loss: 1.1629\n",
            "Epoch 86/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.1238e-04 - val_accuracy: 0.7920 - val_loss: 1.1654\n",
            "Epoch 87/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.0493e-04 - val_accuracy: 0.7920 - val_loss: 1.1744\n",
            "Epoch 88/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 851ms/step - accuracy: 1.0000 - loss: 1.0018e-04 - val_accuracy: 0.7920 - val_loss: 1.1764\n",
            "Epoch 89/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 949ms/step - accuracy: 1.0000 - loss: 9.9519e-05 - val_accuracy: 0.7920 - val_loss: 1.1821\n",
            "Epoch 90/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 921ms/step - accuracy: 1.0000 - loss: 8.7239e-05 - val_accuracy: 0.7920 - val_loss: 1.1926\n",
            "Epoch 91/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.6650e-05 - val_accuracy: 0.7920 - val_loss: 1.1912\n",
            "Epoch 92/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 978ms/step - accuracy: 1.0000 - loss: 8.5422e-05 - val_accuracy: 0.7920 - val_loss: 1.2009\n",
            "Epoch 93/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 855ms/step - accuracy: 1.0000 - loss: 7.4586e-05 - val_accuracy: 0.7920 - val_loss: 1.2024\n",
            "Epoch 94/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 833ms/step - accuracy: 1.0000 - loss: 7.4558e-05 - val_accuracy: 0.7920 - val_loss: 1.2070\n",
            "Epoch 95/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 848ms/step - accuracy: 1.0000 - loss: 7.6753e-05 - val_accuracy: 0.7920 - val_loss: 1.2140\n",
            "Epoch 96/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 7.1603e-05 - val_accuracy: 0.7920 - val_loss: 1.2134\n",
            "Epoch 97/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 836ms/step - accuracy: 1.0000 - loss: 8.0121e-05 - val_accuracy: 0.7920 - val_loss: 1.2259\n",
            "Epoch 98/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 990ms/step - accuracy: 1.0000 - loss: 6.8080e-05 - val_accuracy: 0.7920 - val_loss: 1.2202\n",
            "Epoch 99/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 864ms/step - accuracy: 1.0000 - loss: 6.6283e-05 - val_accuracy: 0.7920 - val_loss: 1.2308\n",
            "Epoch 100/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.7660e-05 - val_accuracy: 0.7920 - val_loss: 1.2288\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 16s/step\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.8316 - loss: 1.0286\n",
            "Test Accuracy: 0.8449\n",
            "F1 Score: 0.8449\n",
            "G-Mean: 0.8449\n",
            "Informedness (IBA): 0.6898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 400X Magnification\n",
        "\n",
        "At 400X magnification, the images offered high-resolution details of cell morphology.\n",
        "Despite the richness of features, performance slightly plateaued compared to 200X.\n",
        "Careful preprocessing was crucial to avoid overfitting on very localized structures.\n"
      ],
      "metadata": {
        "id": "CkpTmg8czqi7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, concatenate, AveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Dataset paths\n",
        "benign_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/benign/400X\"\n",
        "malignant_dir = \"/content/drive/MyDrive/Datasets/BreaKHis_v1/histology_slides/malignant/400X\"\n",
        "\n",
        "# Load image paths\n",
        "def load_image_paths(dir_path):\n",
        "    return [os.path.join(dir_path, img) for img in os.listdir(dir_path) if img.endswith('.png')]\n",
        "\n",
        "benign_images = load_image_paths(benign_dir)\n",
        "malignant_images = load_image_paths(malignant_dir)\n",
        "\n",
        "print(f\"Original Benign: {len(benign_images)}\")\n",
        "print(f\"Original Malignant: {len(malignant_images)}\")\n",
        "\n",
        "# Undersample malignant to match benign\n",
        "malignant_images = resample(malignant_images,\n",
        "                            replace=False,\n",
        "                            n_samples=len(benign_images),\n",
        "                            random_state=42)\n",
        "\n",
        "print(f\"After Undersampling - Malignant: {len(malignant_images)}\")\n",
        "\n",
        "# Labels\n",
        "benign_labels = [0] * len(benign_images)\n",
        "malignant_labels = [1] * len(malignant_images)\n",
        "\n",
        "# Combine\n",
        "all_images = np.array(benign_images + malignant_images)\n",
        "all_labels = np.array(benign_labels + malignant_labels)\n",
        "\n",
        "# Split dataset (60% train, 10% val, 30% test)\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(\n",
        "    all_images, all_labels, test_size=0.3, stratify=all_labels, random_state=42)\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(\n",
        "    train_images, train_labels, test_size=0.1429, stratify=train_labels, random_state=42)\n",
        "\n",
        "print(f\"Training samples: {len(train_images)}\")\n",
        "print(f\"Validation samples: {len(val_images)}\")\n",
        "print(f\"Testing samples: {len(test_images)}\")\n",
        "\n",
        "# Image preprocessing\n",
        "def process_path(file_path, label):\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_png(img, channels=3)\n",
        "    img = tf.image.resize(img, [224, 224])\n",
        "    img = img / 255.0\n",
        "    return img, label\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).map(process_path).shuffle(1000).batch(BATCH_SIZE)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels)).map(process_path).batch(BATCH_SIZE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).map(process_path).batch(BATCH_SIZE)\n",
        "\n",
        "if sum(1 for _ in test_dataset) == 0:\n",
        "    raise ValueError(\"Testing dataset is empty. Adjust your dataset split.\")\n",
        "\n",
        "# Load VGG16 base\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Inception block\n",
        "def inception_block(x):\n",
        "    branch1 = Conv2D(64, (1, 1), activation='relu', padding='same')(x)\n",
        "\n",
        "    branch2 = Conv2D(64, (1, 1), activation='relu', padding='same')(x)\n",
        "    branch2 = Conv2D(128, (3, 3), activation='relu', padding='same')(branch2)\n",
        "\n",
        "    branch3 = Conv2D(64, (1, 1), activation='relu', padding='same')(x)\n",
        "    branch3 = Conv2D(128, (5, 5), activation='relu', padding='same')(branch3)\n",
        "\n",
        "    branch4 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "    branch4 = Conv2D(64, (1, 1), activation='relu', padding='same')(branch4)\n",
        "\n",
        "    output = concatenate([branch1, branch2, branch3, branch4], axis=-1)\n",
        "    return output\n",
        "\n",
        "# Build model\n",
        "x = inception_block(base_model.output)\n",
        "x = AveragePooling2D(pool_size=(2, 2))(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "EPOCHS = 100\n",
        "history = model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS)\n",
        "\n",
        "# Evaluate\n",
        "test_preds = model.predict(test_dataset)\n",
        "test_preds = (test_preds > 0.5).astype(int).flatten()\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(test_labels, test_preds).ravel()\n",
        "iba = (tp / (tp + fn)) + (tn / (tn + fp)) - 1\n",
        "\n",
        "f1 = f1_score(test_labels, test_preds)\n",
        "gmean = geometric_mean_score(test_labels, test_preds)\n",
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"G-Mean: {gmean:.4f}\")\n",
        "print(f\"Informedness (IBA): {iba:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwkCeDn0w9lA",
        "outputId": "444cc773-6894-4a0b-fe27-df8293db45fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Benign: 588\n",
            "Original Malignant: 1232\n",
            "After Undersampling - Malignant: 588\n",
            "Training samples: 705\n",
            "Validation samples: 118\n",
            "Testing samples: 353\n",
            "Epoch 1/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 9s/step - accuracy: 0.4892 - loss: 1.3178 - val_accuracy: 0.5000 - val_loss: 0.7236\n",
            "Epoch 2/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 774ms/step - accuracy: 0.4970 - loss: 0.7091 - val_accuracy: 0.5000 - val_loss: 0.7005\n",
            "Epoch 3/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 782ms/step - accuracy: 0.5190 - loss: 0.6915 - val_accuracy: 0.5000 - val_loss: 0.6823\n",
            "Epoch 4/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 790ms/step - accuracy: 0.5479 - loss: 0.6766 - val_accuracy: 0.7119 - val_loss: 0.6684\n",
            "Epoch 5/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 996ms/step - accuracy: 0.6913 - loss: 0.6604 - val_accuracy: 0.7542 - val_loss: 0.6451\n",
            "Epoch 6/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 780ms/step - accuracy: 0.7347 - loss: 0.6235 - val_accuracy: 0.7119 - val_loss: 0.6172\n",
            "Epoch 7/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 941ms/step - accuracy: 0.6980 - loss: 0.5969 - val_accuracy: 0.7288 - val_loss: 0.5871\n",
            "Epoch 8/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 859ms/step - accuracy: 0.7516 - loss: 0.5374 - val_accuracy: 0.7881 - val_loss: 0.5421\n",
            "Epoch 9/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 786ms/step - accuracy: 0.7675 - loss: 0.4927 - val_accuracy: 0.7966 - val_loss: 0.5059\n",
            "Epoch 10/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 784ms/step - accuracy: 0.8166 - loss: 0.4358 - val_accuracy: 0.7797 - val_loss: 0.5425\n",
            "Epoch 11/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1000ms/step - accuracy: 0.7908 - loss: 0.4615 - val_accuracy: 0.7119 - val_loss: 0.5868\n",
            "Epoch 12/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 782ms/step - accuracy: 0.7618 - loss: 0.4628 - val_accuracy: 0.8136 - val_loss: 0.4538\n",
            "Epoch 13/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 807ms/step - accuracy: 0.8293 - loss: 0.3888 - val_accuracy: 0.7458 - val_loss: 0.5089\n",
            "Epoch 14/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 874ms/step - accuracy: 0.8525 - loss: 0.3737 - val_accuracy: 0.8136 - val_loss: 0.4330\n",
            "Epoch 15/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 788ms/step - accuracy: 0.8936 - loss: 0.3122 - val_accuracy: 0.8136 - val_loss: 0.4267\n",
            "Epoch 16/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 790ms/step - accuracy: 0.8867 - loss: 0.2918 - val_accuracy: 0.8305 - val_loss: 0.4132\n",
            "Epoch 17/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 832ms/step - accuracy: 0.8989 - loss: 0.2653 - val_accuracy: 0.8220 - val_loss: 0.4025\n",
            "Epoch 18/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 998ms/step - accuracy: 0.9307 - loss: 0.2269 - val_accuracy: 0.8644 - val_loss: 0.4131\n",
            "Epoch 19/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 784ms/step - accuracy: 0.9411 - loss: 0.1920 - val_accuracy: 0.8644 - val_loss: 0.4258\n",
            "Epoch 20/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.9268 - loss: 0.1943 - val_accuracy: 0.8559 - val_loss: 0.3850\n",
            "Epoch 21/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 835ms/step - accuracy: 0.9533 - loss: 0.1418 - val_accuracy: 0.7881 - val_loss: 0.4282\n",
            "Epoch 22/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.9608 - loss: 0.1407 - val_accuracy: 0.7966 - val_loss: 0.4205\n",
            "Epoch 23/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.9696 - loss: 0.1183 - val_accuracy: 0.8644 - val_loss: 0.4110\n",
            "Epoch 24/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 800ms/step - accuracy: 0.9676 - loss: 0.1070 - val_accuracy: 0.8390 - val_loss: 0.4644\n",
            "Epoch 25/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.9868 - loss: 0.0806 - val_accuracy: 0.8729 - val_loss: 0.4245\n",
            "Epoch 26/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 810ms/step - accuracy: 0.9974 - loss: 0.0553 - val_accuracy: 0.8644 - val_loss: 0.4317\n",
            "Epoch 27/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 804ms/step - accuracy: 0.9963 - loss: 0.0483 - val_accuracy: 0.8644 - val_loss: 0.4419\n",
            "Epoch 28/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 793ms/step - accuracy: 0.9996 - loss: 0.0327 - val_accuracy: 0.8559 - val_loss: 0.4514\n",
            "Epoch 29/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0272 - val_accuracy: 0.8644 - val_loss: 0.4860\n",
            "Epoch 30/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 881ms/step - accuracy: 1.0000 - loss: 0.0207 - val_accuracy: 0.8644 - val_loss: 0.5017\n",
            "Epoch 31/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0184 - val_accuracy: 0.8559 - val_loss: 0.5111\n",
            "Epoch 32/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 794ms/step - accuracy: 1.0000 - loss: 0.0129 - val_accuracy: 0.8729 - val_loss: 0.5213\n",
            "Epoch 33/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 785ms/step - accuracy: 1.0000 - loss: 0.0106 - val_accuracy: 0.8729 - val_loss: 0.5301\n",
            "Epoch 34/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 941ms/step - accuracy: 1.0000 - loss: 0.0086 - val_accuracy: 0.8644 - val_loss: 0.5396\n",
            "Epoch 35/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.8644 - val_loss: 0.5625\n",
            "Epoch 36/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 812ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.8559 - val_loss: 0.5633\n",
            "Epoch 37/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.8644 - val_loss: 0.5812\n",
            "Epoch 38/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 800ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.8559 - val_loss: 0.5883\n",
            "Epoch 39/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.8559 - val_loss: 0.5948\n",
            "Epoch 40/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 810ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.8559 - val_loss: 0.6072\n",
            "Epoch 41/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 798ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.8644 - val_loss: 0.6183\n",
            "Epoch 42/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.8644 - val_loss: 0.6334\n",
            "Epoch 43/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.8559 - val_loss: 0.6378\n",
            "Epoch 44/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 800ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.8559 - val_loss: 0.6544\n",
            "Epoch 45/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 999ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.8475 - val_loss: 0.6571\n",
            "Epoch 46/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 798ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.8644 - val_loss: 0.6602\n",
            "Epoch 47/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.8559 - val_loss: 0.6638\n",
            "Epoch 48/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 936ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.8644 - val_loss: 0.6692\n",
            "Epoch 49/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.8559 - val_loss: 0.6782\n",
            "Epoch 50/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.8644 - val_loss: 0.6807\n",
            "Epoch 51/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 940ms/step - accuracy: 1.0000 - loss: 9.6604e-04 - val_accuracy: 0.8644 - val_loss: 0.6880\n",
            "Epoch 52/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.1449e-04 - val_accuracy: 0.8559 - val_loss: 0.6967\n",
            "Epoch 53/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 806ms/step - accuracy: 1.0000 - loss: 8.4644e-04 - val_accuracy: 0.8559 - val_loss: 0.7038\n",
            "Epoch 54/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 8.0905e-04 - val_accuracy: 0.8475 - val_loss: 0.7101\n",
            "Epoch 55/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 7.6266e-04 - val_accuracy: 0.8559 - val_loss: 0.7174\n",
            "Epoch 56/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 7.1890e-04 - val_accuracy: 0.8559 - val_loss: 0.7242\n",
            "Epoch 57/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 801ms/step - accuracy: 1.0000 - loss: 6.9499e-04 - val_accuracy: 0.8475 - val_loss: 0.7276\n",
            "Epoch 58/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 795ms/step - accuracy: 1.0000 - loss: 6.3746e-04 - val_accuracy: 0.8475 - val_loss: 0.7327\n",
            "Epoch 59/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 945ms/step - accuracy: 1.0000 - loss: 4.6645e-04 - val_accuracy: 0.8475 - val_loss: 0.7381\n",
            "Epoch 60/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.9637e-04 - val_accuracy: 0.8475 - val_loss: 0.7434\n",
            "Epoch 61/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.6136e-04 - val_accuracy: 0.8475 - val_loss: 0.7500\n",
            "Epoch 62/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.2520e-04 - val_accuracy: 0.8475 - val_loss: 0.7553\n",
            "Epoch 63/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 793ms/step - accuracy: 1.0000 - loss: 4.2220e-04 - val_accuracy: 0.8390 - val_loss: 0.7621\n",
            "Epoch 64/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 798ms/step - accuracy: 1.0000 - loss: 3.9169e-04 - val_accuracy: 0.8475 - val_loss: 0.7678\n",
            "Epoch 65/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 927ms/step - accuracy: 1.0000 - loss: 3.5145e-04 - val_accuracy: 0.8475 - val_loss: 0.7753\n",
            "Epoch 66/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.3562e-04 - val_accuracy: 0.8390 - val_loss: 0.7819\n",
            "Epoch 67/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.6732e-04 - val_accuracy: 0.8559 - val_loss: 0.7907\n",
            "Epoch 68/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.0804e-04 - val_accuracy: 0.8475 - val_loss: 0.7925\n",
            "Epoch 69/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 791ms/step - accuracy: 1.0000 - loss: 2.8126e-04 - val_accuracy: 0.8559 - val_loss: 0.8034\n",
            "Epoch 70/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 793ms/step - accuracy: 1.0000 - loss: 2.7138e-04 - val_accuracy: 0.8390 - val_loss: 0.8048\n",
            "Epoch 71/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 850ms/step - accuracy: 1.0000 - loss: 2.4395e-04 - val_accuracy: 0.8475 - val_loss: 0.8167\n",
            "Epoch 72/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.6944e-04 - val_accuracy: 0.8475 - val_loss: 0.8159\n",
            "Epoch 73/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.0812e-04 - val_accuracy: 0.8475 - val_loss: 0.8233\n",
            "Epoch 74/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 1.9076e-04 - val_accuracy: 0.8390 - val_loss: 0.8266\n",
            "Epoch 75/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.9674e-04 - val_accuracy: 0.8475 - val_loss: 0.8331\n",
            "Epoch 76/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 973ms/step - accuracy: 1.0000 - loss: 1.7138e-04 - val_accuracy: 0.8390 - val_loss: 0.8366\n",
            "Epoch 77/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 801ms/step - accuracy: 1.0000 - loss: 1.6244e-04 - val_accuracy: 0.8475 - val_loss: 0.8428\n",
            "Epoch 78/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 800ms/step - accuracy: 1.0000 - loss: 1.7639e-04 - val_accuracy: 0.8559 - val_loss: 0.8498\n",
            "Epoch 79/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.6939e-04 - val_accuracy: 0.8305 - val_loss: 0.8517\n",
            "Epoch 80/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 796ms/step - accuracy: 1.0000 - loss: 1.6174e-04 - val_accuracy: 0.8475 - val_loss: 0.8582\n",
            "Epoch 81/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.3331e-04 - val_accuracy: 0.8305 - val_loss: 0.8622\n",
            "Epoch 82/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 795ms/step - accuracy: 1.0000 - loss: 1.3837e-04 - val_accuracy: 0.8559 - val_loss: 0.8695\n",
            "Epoch 83/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 793ms/step - accuracy: 1.0000 - loss: 1.3236e-04 - val_accuracy: 0.8305 - val_loss: 0.8721\n",
            "Epoch 84/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 949ms/step - accuracy: 1.0000 - loss: 1.1953e-04 - val_accuracy: 0.8559 - val_loss: 0.8802\n",
            "Epoch 85/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.1709e-04 - val_accuracy: 0.8305 - val_loss: 0.8822\n",
            "Epoch 86/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 808ms/step - accuracy: 1.0000 - loss: 1.0327e-04 - val_accuracy: 0.8559 - val_loss: 0.8899\n",
            "Epoch 87/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.4896e-05 - val_accuracy: 0.8305 - val_loss: 0.8920\n",
            "Epoch 88/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.0603e-04 - val_accuracy: 0.8559 - val_loss: 0.8993\n",
            "Epoch 89/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 898ms/step - accuracy: 1.0000 - loss: 9.7709e-05 - val_accuracy: 0.8305 - val_loss: 0.9021\n",
            "Epoch 90/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 795ms/step - accuracy: 1.0000 - loss: 9.1349e-05 - val_accuracy: 0.8475 - val_loss: 0.9089\n",
            "Epoch 91/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 790ms/step - accuracy: 1.0000 - loss: 9.4543e-05 - val_accuracy: 0.8390 - val_loss: 0.9120\n",
            "Epoch 92/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 811ms/step - accuracy: 1.0000 - loss: 8.4887e-05 - val_accuracy: 0.8390 - val_loss: 0.9159\n",
            "Epoch 93/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 7.9358e-05 - val_accuracy: 0.8390 - val_loss: 0.9197\n",
            "Epoch 94/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 792ms/step - accuracy: 1.0000 - loss: 7.3948e-05 - val_accuracy: 0.8390 - val_loss: 0.9244\n",
            "Epoch 95/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 804ms/step - accuracy: 1.0000 - loss: 7.4993e-05 - val_accuracy: 0.8390 - val_loss: 0.9295\n",
            "Epoch 96/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 821ms/step - accuracy: 1.0000 - loss: 7.1525e-05 - val_accuracy: 0.8390 - val_loss: 0.9328\n",
            "Epoch 97/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.4582e-05 - val_accuracy: 0.8305 - val_loss: 0.9358\n",
            "Epoch 98/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.4623e-05 - val_accuracy: 0.8390 - val_loss: 0.9408\n",
            "Epoch 99/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 960ms/step - accuracy: 1.0000 - loss: 5.6364e-05 - val_accuracy: 0.8305 - val_loss: 0.9443\n",
            "Epoch 100/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.0396e-05 - val_accuracy: 0.8390 - val_loss: 0.9490\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 8 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7d272371ef20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 536ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 10 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7d272371ef20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 13s/step\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 979ms/step - accuracy: 0.8518 - loss: 0.7656\n",
            "Test Accuracy: 0.8442\n",
            "F1 Score: 0.8433\n",
            "G-Mean: 0.8442\n",
            "Informedness (IBA): 0.6884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame with the updated metrics\n",
        "data = {\n",
        "    'Magnification': ['40X', '100X', '200X', '400X'],\n",
        "    'Test Accuracy': [0.8590, 0.8282, 0.8449, 0.8449],\n",
        "    'F1 Score': [0.8602, 0.8232, 0.8449, 0.8449],\n",
        "    'G-Mean': [0.8590, 0.8277, 0.8449, 0.8449],\n",
        "    'Informedness (IBA)': [0.7181, 0.6564, 0.6898, 0.6898]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display the table with formatting\n",
        "styled_df = df.style \\\n",
        "    .format({\n",
        "        'Test Accuracy': '{:.4f}',\n",
        "        'F1 Score': '{:.4f}',\n",
        "        'G-Mean': '{:.4f}',\n",
        "        'Informedness (IBA)': '{:.4f}'\n",
        "    }) \\\n",
        "    .set_properties(**{'text-align': 'center'}) \\\n",
        "    .set_table_styles([{\n",
        "        'selector': 'th',\n",
        "        'props': [('background-color', '#000000'), ('font-weight', 'bold')]\n",
        "    }]) \\\n",
        "    .hide(axis='index')\n",
        "\n",
        "styled_df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "2fRspTmuDw_C",
        "outputId": "54fb0ada-c13a-4a63-ee06-f72e98f47cfa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7be948cf9490>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_b338c th {\n",
              "  background-color: #000000;\n",
              "  font-weight: bold;\n",
              "}\n",
              "#T_b338c_row0_col0, #T_b338c_row0_col1, #T_b338c_row0_col2, #T_b338c_row0_col3, #T_b338c_row0_col4, #T_b338c_row1_col0, #T_b338c_row1_col1, #T_b338c_row1_col2, #T_b338c_row1_col3, #T_b338c_row1_col4, #T_b338c_row2_col0, #T_b338c_row2_col1, #T_b338c_row2_col2, #T_b338c_row2_col3, #T_b338c_row2_col4, #T_b338c_row3_col0, #T_b338c_row3_col1, #T_b338c_row3_col2, #T_b338c_row3_col3, #T_b338c_row3_col4 {\n",
              "  text-align: center;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_b338c\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th id=\"T_b338c_level0_col0\" class=\"col_heading level0 col0\" >Magnification</th>\n",
              "      <th id=\"T_b338c_level0_col1\" class=\"col_heading level0 col1\" >Test Accuracy</th>\n",
              "      <th id=\"T_b338c_level0_col2\" class=\"col_heading level0 col2\" >F1 Score</th>\n",
              "      <th id=\"T_b338c_level0_col3\" class=\"col_heading level0 col3\" >G-Mean</th>\n",
              "      <th id=\"T_b338c_level0_col4\" class=\"col_heading level0 col4\" >Informedness (IBA)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td id=\"T_b338c_row0_col0\" class=\"data row0 col0\" >40X</td>\n",
              "      <td id=\"T_b338c_row0_col1\" class=\"data row0 col1\" >0.8590</td>\n",
              "      <td id=\"T_b338c_row0_col2\" class=\"data row0 col2\" >0.8602</td>\n",
              "      <td id=\"T_b338c_row0_col3\" class=\"data row0 col3\" >0.8590</td>\n",
              "      <td id=\"T_b338c_row0_col4\" class=\"data row0 col4\" >0.7181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_b338c_row1_col0\" class=\"data row1 col0\" >100X</td>\n",
              "      <td id=\"T_b338c_row1_col1\" class=\"data row1 col1\" >0.8282</td>\n",
              "      <td id=\"T_b338c_row1_col2\" class=\"data row1 col2\" >0.8232</td>\n",
              "      <td id=\"T_b338c_row1_col3\" class=\"data row1 col3\" >0.8277</td>\n",
              "      <td id=\"T_b338c_row1_col4\" class=\"data row1 col4\" >0.6564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_b338c_row2_col0\" class=\"data row2 col0\" >200X</td>\n",
              "      <td id=\"T_b338c_row2_col1\" class=\"data row2 col1\" >0.8449</td>\n",
              "      <td id=\"T_b338c_row2_col2\" class=\"data row2 col2\" >0.8449</td>\n",
              "      <td id=\"T_b338c_row2_col3\" class=\"data row2 col3\" >0.8449</td>\n",
              "      <td id=\"T_b338c_row2_col4\" class=\"data row2 col4\" >0.6898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_b338c_row3_col0\" class=\"data row3 col0\" >400X</td>\n",
              "      <td id=\"T_b338c_row3_col1\" class=\"data row3 col1\" >0.8449</td>\n",
              "      <td id=\"T_b338c_row3_col2\" class=\"data row3 col2\" >0.8449</td>\n",
              "      <td id=\"T_b338c_row3_col3\" class=\"data row3 col3\" >0.8449</td>\n",
              "      <td id=\"T_b338c_row3_col4\" class=\"data row3 col4\" >0.6898</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-8W_CLb8OU3S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}